[{"title":"C++主要的六种类型语句","url":"/2024/03/05/C++%E4%B8%BB%E8%A6%81%E7%9A%84%E5%85%AD%E7%A7%8D%E7%B1%BB%E5%9E%8B%E8%AF%AD%E5%8F%A5/","content":"在 C++ 编程语言中，语句（statements）是构成程序的基本单位。C++ 类型的语句主要包括以下六种：\n\n表达式语句（Expression Statements）：\n\n这是最常见的语句类型，通常用于计算一个值或调用一个函数。例如：\ncpp复制代码x = 5;y = x + 2;foo();\n\n\n复合语句（Compound Statements）：\n\n复合语句也称为块（block），由大括号 \n&#123;&#125;\n\n 包围的一组语句构成，通常用于定义函数体或控制结构中的代码块。例如：\ncpp复制代码&#123;    int x = 10;    x++;&#125;\n\n\n选择语句（Selection Statements）：\n\n选择语句用于根据条件执行不同的代码段，主要包括 \nif\n\n、\nelse\n\n、和 \nswitch\n\n 语句。例如：\ncpp复制代码if (x &gt; 0) &#123;    std::cout &lt;&lt; &quot;Positive&quot;;&#125; else &#123;    std::cout &lt;&lt; &quot;Non-positive&quot;;&#125;switch (x) &#123;    case 1:        std::cout &lt;&lt; &quot;One&quot;;        break;    case 2:        std::cout &lt;&lt; &quot;Two&quot;;        break;    default:        std::cout &lt;&lt; &quot;Other&quot;;        break;&#125;\n\n\n迭代语句（Iteration Statements）：\n\n迭代语句用于重复执行一段代码，主要包括 \nfor\n\n、\nwhile\n\n、和 \ndo-while\n\n 语句。例如：\ncpp复制代码for (int i = 0; i &lt; 10; i++) &#123;    std::cout &lt;&lt; i;&#125;while (x &gt; 0) &#123;    x--;&#125;do &#123;    x++;&#125; while (x &lt; 10);\n\n\n跳转语句（Jump Statements）：\n\n跳转语句用于改变程序的执行顺序，主要包括 \nbreak\n\n、\ncontinue\n\n、\nreturn\n\n、和 \ngoto\n\n 语句。例如：\ncpp复制代码for (int i = 0; i &lt; 10; i++) &#123;    if (i == 5) &#123;        break;    &#125;    if (i % 2 == 0) &#123;        continue;    &#125;    std::cout &lt;&lt; i;&#125;return 0;goto label;label:std::cout &lt;&lt; &quot;Jumped to label&quot;;\n\n\n声明语句（Declaration Statements）：\n\n声明语句用于声明变量、函数、类等，通常包括类型说明符和变量名。例如：\ncpp复制代码int x;double y = 5.5;void foo();class MyClass &#123;&#125;;\n\n\n\n这些语句类型构成了 C++ 编程语言的基本语法结构，允许程序员编写灵活且功能强大的程序。\n","tags":["cpp"]},{"title":"Hexo+Netlify搭建个人博客","url":"/2023/01/13/Hexo-Netlify2createblog/","content":"系统环境：ubuntu22.04LTS(笔者采用的是在vmware16虚拟机里面装了ubuntu22.04LTS版本)\n一、准备工作\n在ubuntu系统文件的home&#x2F;用户名 目录下创建hexo 文件夹，并在hexo文件夹下面创建blog文件夹（我这里的用户名是：bigfly）\n\n\n\n在hexo文件夹下面右击鼠标，打开终端\n\n\n\n在终端中执行以下命令\nsudo su  #进入超级用户模式apt-get update apt-get install git -ygit clone https://github.com/creationix/nvm.git nvm #安装nvmsource /home/bigfly/hexo/nvm/nvm.sh #注意将bigfly改为自己的用户名cat  /home/bigfly/hexo/nvm/nvm.sh &gt;&gt; ~/.bashrcsource ~/.bashrc #添加环境变量nvm install nodenpm install -g hexo-cli #安装一些依赖\n\n所有准备已经完成可以查看一下安装的版本\nnvm -vnpm -vnode -vhexo -v\n\n二、初始化博客\n切换目录到blog \ncd blog\n\n初始化hexo博客\nhexo init\n\n结果如下图所示在blog文件夹下生成博客的初始化文件\n \n \n\n在终端中执行以下命令生成博客\nhexo ghexo s\n\n\n\n在浏览器中打开以下地址，浏览自己的博客\nhttp://localhost:4000/\n\n\n\n效果如下图所示 \n\n\n三、将博客部署至Github\n访问Github官网并登录自己的账号（没有账号先注册再登陆）\n\n创建一个新仓库步骤如下\n\n\n点击右上角加号，并选择New repository\n\n在弹出的新建页面中需要注意Repository name的填写，具体细节点击参考1\n\n\n\n\n\n回到终端安装deploy包并进行相关配置\nnpm install hexo-deployer-git –save #安装部署文件vim _config.yml  #用vim修改博客配置文件config.yml\n\n\n_config.yml按“i键 ”进入插入inset模式\n\n在_config.yml的末尾修改内容如下：\ndeploy:  type: git  repository: https://&#123;你的token&#125;@github.com/&#123;git用户名&#125;/&#123;git用户名&#125;.github.io.git  #你的仓库地址  branch: master\n\n笔者这个改后的内容如下\n\n修改完成后 按shift+: 键 进入cmd 模式 ，并输入 wq 回车\n\n&#x3D;&#x3D;token的获取&#x3D;&#x3D;：\n\n打开自己的github点击设置—&gt;点击Developer settings—&gt;在Personal access tokens 下面的列表中选择Tokens(classic),进行设置，在设置菜单中的复选框中全部点上对勾给足权限。\n点击最下面的Generate token 生成token \n\n\n\n\n设置git 邮箱和用户名\ngit config --global user.name Your Namegit config --global user.email you@example.com\n\n部署博客\nhexo clean   #清除缓存文件 db.json 和已生成的静态文件 publichexo g       #生成网站静态文件到默认设置的 public 文件夹(hexo generate 的缩写)hexo d       #自动生成网站静态文件，并部署到设定的仓库(hexo deploy 的缩写)\n\n部署完成后你就可以在浏览器中打开   “你的github用户名.github.io”  来访问自己的博客了\n\n\n四、更换主题等待后续更新\n","categories":["经验分享"],"tags":["Hexo","Netlify"]},{"title":"IOU在不同阶段的作用","url":"/2024/05/05/IOU/","content":"IOUIOU（Intersection over Union）是目标检测中常用的一个指标，用于衡量两个边界框之间的重叠程度。它是通过计算两个边界框的交集面积与它们的并集面积之比来确定的。\n具体地，IOU可以用以下公式表示：\n\n其中，Area of Overlap表示两个边界框的交集面积，而Area of Union表示两个边界框的并集面积。\n1、IOU在模型训练中的作用在目标检测模型的训练中，IOU（Intersection over Union）通常用作损失函数的一部分，主要用于衡量模型预测框（bounding box）与真实目标框之间的重叠程度。IOU被广泛用于目标检测任务的训练和评估中，其作用包括：\n\n损失函数计算： IOU常被用于计算目标检测模型的损失函数，尤其是在两个框之间进行匹配时。通过计算模型预测框与真实目标框之间的IOU，可以量化模型预测的准确性，并据此调整模型参数，使预测结果更接近真实目标。\nAnchor框选择： 在一些目标检测模型中，需要预先定义一些Anchor框（候选框）来辅助目标检测。IOU可以帮助选择最适合的Anchor框，即与真实目标框具有最高IOU的Anchor框，从而提高模型的训练效果和检测性能。\n正负样本筛选： 在训练过程中，IOU还常被用于筛选正负样本。通常情况下，IOU大于某个阈值的预测框被视为正样本（表示与真实目标框重叠较高），而IOU低于另一个阈值的预测框则被视为负样本（表示与真实目标框重叠较低），从而帮助模型更好地学习目标检测任务。\n\n2、IOU在模型应用时的作用在使用模型进行实际检测时，设定IOU（Intersection over Union）阈值可以用于控制检测结果的质量和数量。具体来说，设定IOU阈值可以帮助筛选检测结果，过滤掉那些与已知目标重叠度较高的检测结果，从而得到更可靠的检测结果，常见的有模型推理阶段后处理的NMS中使用，当然有些算法例如RT-DETR和YOLOv10已经通过一些方法去掉NMS。\n下面是设定IOU阈值的一些常见用途：\n\n过滤重叠检测结果： 当目标之间存在重叠时，设定较高的IOU阈值可以帮助排除其中一个目标，避免重复计数。\n控制检测结果的数量： 调节IOU阈值可以影响最终的检测结果数量。较低的阈值会保留更多的检测结果，而较高的阈值则会过滤掉一些重叠度较高的检测结果，从而减少最终的检测结果数量。\n*调整检测结果的精度[1]和召回率[2]：* 通过调节IOU阈值，可以在精确度（precision）和召回率（recall）之间进行权衡。较高的IOU阈值会提高检测结果的精确度，但可能会降低召回率，反之亦然。\n适应特定场景的需求： 不同的应用场景可能对检测结果的质量有不同的要求，因此可以根据实际情况调整IOU阈值，以满足特定场景的需求。\n\n概念补充：1.Precision：精度、准确率，表示检测结果中真正为fish的数量 占检测总数things的百分比。 ↩2.Recall：召回率、查全率，表示检测结果中things中fish的数量，占所有fishs数量的百分比，大话解析：如果用渔网在池塘中捕鱼的例子看，召回率表示用网捕到的所有东西things(鱼和塑料瓶、石头、垃圾)中的鱼fish占池子中鱼总数fishs（未捕鱼之前的总数）的百分比，而精准度则可表示为，渔网中鱼fish占所有捕获东西总数things的百分比，若用足够密的网将池子里所有东西捞出，召回率将是1，而精准度将大大降低（因为网密就会捕捞大量的塑料瓶石头垃圾），召回率和准确率的计算公式中分子是一样的都是渔网中真正是鱼的个数即fish，区别是召回率的分母是所有的鱼即fishs，而准确率的分母是渔网中的所有东西things，如果想提高召回率就得用密度更大的网捕鱼*（降低检测的iou和置信度）*，但于此同时也会捕到更多的其他东西，即降低了精准度。有没有一种可能用一种渔网捕捞到鱼塘所有的鱼而没有一个其他东西，这样召回率就是1准确率也是1？从第一性原理看是不现实的， ↩3.R-P曲线：精准率和召回率绘制出来的曲线， ↩4.Accuracy：准确率，所有预测正确的样本数比上总预测样本数 ↩","categories":["目标检测"]},{"title":"Mahalanobis距离","url":"/2023/08/25/Mahalanobis%E8%B7%9D%E7%A6%BB/","content":"知识储备：\n协方差概念\n欧几里得距离（欧氏距离）\n线性代数\nPCA算法\n\n一、前言：在学习deepsort相关内容，提到了马氏距离，之前也有所耳闻，但没有深入了解，只是知道它是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间相似度的一种指标。查阅了很多博主写的相关文章，似乎没有讲到本质的地方且对新手不太友好，借此机会对其原理以及方法进行了详细了解，并用笔者的思路来为大家进行讲解。\n二、概念：\n三、解释以上是维基百科给出的解释，看到这你是不是懵逼了，没关系且听我细说。\n大话概念：马氏距离是一种测量两个点之间距离的方法，不同于欧几里得距离，它考虑了数据的协方差。这使得马氏距离能有效得度量在多维空间中的距离，尤其是对用不同维度之间存在相关性的数据。\n四、欧氏距离与马氏距离4.1 单变量欧氏距离如下图，假设圆圈表示数据样本，数据的均值为0，那么欧式距离就是圆圈离0的远近。\n\n图1\n\n4.2 多变量欧氏距离图2为高维空间中数据点在平面上的投影图中的红色➕表示数据点的均值点，点i（任意数据点）与均值点之间的欧氏距离可通过如下公式计算得到。\n\n图2\n\n4.3欧氏距离的局限性如图3所示若数据样本之间存在协方差，那么欧式距离就不太适用。例如图中的红色方块和蓝色方块距离均值点 ➕的欧式距离是相等的。直观的看红色方块是一个异常点（离群点），此时若用欧几里得距离作为度量距离的指标显然不太适合。\n\n图3\n\n4.4马氏距离协方差：\n$$Cov(X,Y) &#x3D; E((X-E[X])(Y-E[Y]))         &#x3D; E(XY)-2E(X)E(Y)-E(X)E(Y)         &#x3D; E(XY)-E(X)E(Y)$$\n\n对于上述公式中E表示求均值，对于第一行若有Y&#x3D;X则Cov(X,Y) &#x3D; E((X-E[X])(Y-E[Y]))&#x3D;(X-E[X])(X-E[X])&#x3D;var(X),即一个变量与自身的协方差等于方差，记住这一点后面会用到。\n\n所有变量对的协方差矩阵如下图所示：\n\n协方差矩阵是一个方阵，这里展示的是一个3x3的协方差矩阵，它包含所有变量对之间的协方差。\n基于以下两点我们可以对上面的协方差矩阵进行变形,变形结果如下所示。\n\n一个变量X与自身的协方差也就是方差，这一点在前面推导有提到过，在此不再赘述。\n协方差满足交换律即cov(x1,x2)&#x3D;cov(x2,x1)\n\n\n上述矩阵是一个实对称矩阵。且在主斜对角线上面的值都是方差，这也就是协方差矩阵名称的来源。\n回到欧几里得距离的问题，如果我们能以某种方式，重新缩放图4，使得变量之间不再具有其协方差，它会鲁棒性更强，这就是马氏距离要解决的问题，了解这一点我认为是至关重要的，很多很多博主都讲马氏距离、协方差、讲的没错，但没有刨根问题，究其本质。后面笔者将讲述如何对其进行Rescaling to Remove Covariance,也就是去协方差。\n\n图4\n\n\n\nRescaling to Remove Covariance：\n首先讲这个问题之前我们先来回顾一个表达式Ax&#x3D;λx,也就是特征值与特征向量之间的关系。举一个简单的例子：\n这是一个2x2的矩阵：\nN维矩阵有N个特征向量，且不同特征向量相互正交，这里笔者举例的特征向量是二维的，所以其有两个相互正交的特征向量，我们找到其一个特征向量，通过Ax&#x3D;λx构造如下表达式：\n\n所以我们就可以根据线性代数的知识求出特征值I和特征向量x（也就是Ax&#x3D;λx中的λ和x）。对图3中的数据求其协方差矩阵对应特征向量、特征值，结果如图5所示。\n\n图5","tags":["原理"]},{"title":"RCNN代码复现","url":"/2023/04/21/RCNN%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/","content":"一、工程结构\n二、源码解读py&#x2F;bbox_regression.pyimport osimport copyimport timeimport torchimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import DataLoaderimport torchvision.transforms as transformsfrom torchvision.models import AlexNetfrom visdom import Visdomfrom utils.data.custom_bbox_regression_dataset import BBoxRegressionDatasetimport utils.util as utildef load_data(data_root_dir):    transform = transforms.Compose([        transforms.ToPILImage(),        transforms.Resize((227, 227)),        transforms.RandomHorizontalFlip(),        transforms.ToTensor(),        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))    ])    data_set = BBoxRegressionDataset(data_root_dir, transform=transform)    data_loader = DataLoader(data_set, batch_size=128, shuffle=True, num_workers=8)    return data_loaderdef train_model(data_loader, feature_model, model, criterion, optimizer, lr_scheduler, num_epochs=25, device=None):    since = time.time()    model.train()  # Set model to training mode    loss_list = list()    for epoch in range(num_epochs):        print(&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;.format(epoch, num_epochs - 1))        print(&#x27;-&#x27; * 10)        viz = Visdom()  # 初始化visdom类        viz.line(Y=[0.], X=[0.], win=&quot;train loss&quot;,opts=dict(title=&#x27;train loss&#x27;, xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss&#x27;))        running_loss = 0.0        batch_i = 0        # Iterate over data.        for inputs, targets in data_loader:            inputs = inputs.to(device)            targets = targets.float().to(device)            features = feature_model.features(inputs)            features = torch.flatten(features, 1)            # zero the parameter gradients            optimizer.zero_grad()            # forward            outputs = model(features)            loss = criterion(outputs, targets)            loss.backward()            optimizer.step()            # statistics            running_loss += loss.item() * inputs.size(0)            lr_scheduler.step()            batch_i += 1            print(&quot;batch&quot;, batch_i, &quot;running_loss_adds=&quot;, running_loss)        epoch_loss = running_loss / data_loader.dataset.__len__()        loss_list.append(epoch_loss)        print(&#x27;&#123;&#125; Loss: &#123;:.4f&#125;&#x27;.format(epoch, epoch_loss))        # 绘制回归损失图        viz.line(Y=[epoch_loss], X=[epoch + 1],win=&quot;train loss&quot;,opts=dict(title=&#x27;train loss&#x27;, xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss&#x27;, update=&quot;append&quot;))        # 每训练一轮就保存        util.save_model(model, &#x27;./models/bbox_regression_%d.pth&#x27; % epoch)    print()    time_elapsed = time.time() - since    print(&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(time_elapsed // 60, time_elapsed % 60))    return loss_listdef get_model(device=None):    # 加载CNN模型    model = AlexNet(num_classes=2)    model.load_state_dict(torch.load(&#x27;./models/best_linear_svm_alexnet_car.pth&#x27;))    model.eval()    # 取消梯度追踪    for param in model.parameters():        param.requires_grad = False    if device:        model = model.to(device)    return modelif __name__ == &#x27;__main__&#x27;:    data_loader = load_data(&#x27;./data/bbox_regression&#x27;)    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)    feature_model = get_model(device)    # AlexNet最后一个池化层计算得到256*6*6输出    in_features = 256 * 6 * 6    out_features = 4    model = nn.Linear(in_features, out_features)    model.to(device)    criterion = nn.MSELoss()    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)    loss_list = train_model(data_loader, feature_model, model, criterion, optimizer, lr_scheduler, device=device,                            num_epochs=5)    util.plot_loss(loss_list)\n\n\n\ncar_detector.pyimport timeimport copyimport cv2import numpy as npimport torchimport torch.nn as nnfrom torchvision.models import alexnetimport torchvision.transforms as transformsimport selectivesearchimport utils.util as utildef get_device():    return torch.device(&#x27;cuda:0&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)def get_transform():    # 数据转换    transform = transforms.Compose([        transforms.ToPILImage(),        transforms.Resize((227, 227)),        transforms.RandomHorizontalFlip(),        transforms.ToTensor(),        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))    ])    return transformdef get_model(device=None):    # 加载CNN模型    model = alexnet()    num_classes = 2    num_features = model.classifier[6].in_features    model.classifier[6] = nn.Linear(num_features, num_classes)    model.load_state_dict(torch.load(&#x27;./models/best_linear_svm_alexnet_car.pth&#x27;))    model.eval()    # 取消梯度追踪    for param in model.parameters():        param.requires_grad = False    if device:        model = model.to(device)    return modeldef draw_box_with_text(img, rect_list, score_list):    &quot;&quot;&quot;    绘制边框及其分类概率    :param img:    :param rect_list:    :param score_list:    :return:    &quot;&quot;&quot;    for i in range(len(rect_list)):        xmin, ymin, xmax, ymax = rect_list[i]        score = score_list[i]        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color=(0, 0, 255), thickness=1)        cv2.putText(img, &quot;&#123;:.3f&#125;&quot;.format(score), (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)def nms(rect_list, score_list):    &quot;&quot;&quot;    非最大抑制    :param rect_list: list，大小为[N, 4]    :param score_list： list，大小为[N]    &quot;&quot;&quot;    nms_rects = list()    nms_scores = list()    rect_array = np.array(rect_list)    score_array = np.array(score_list)    # 一次排序后即可    # 按分类概率从大到小排序    idxs = np.argsort(score_array)[::-1]    rect_array = rect_array[idxs]    score_array = score_array[idxs]    thresh = 0.15    while len(score_array) &gt; 0:        # 添加分类概率最大的边界框        nms_rects.append(rect_array[0])        nms_scores.append(score_array[0])        rect_array = rect_array[1:]        score_array = score_array[1:]        length = len(score_array)        if length &lt;= 0:            break        # 计算IoU        iou_scores = util.iou(np.array(nms_rects[len(nms_rects) - 1]), rect_array)        # print(iou_scores)        # 去除重叠率大于等于thresh的边界框        idxs = np.where(iou_scores &lt; thresh)[0]        rect_array = rect_array[idxs]        score_array = score_array[idxs]    return nms_rects, nms_scoresif __name__ == &#x27;__main__&#x27;:    device = get_device()    transform = get_transform()    model = get_model(device=device)    # 创建selectivesearch对象    gs = selectivesearch.get_selective_search()    #test_img_path = &#x27;../imgs/000007.jpg&#x27;    # test_xml_path = &#x27;../imgs/000007.xml&#x27;    test_img_path = &#x27;../imgs/456.jpg&#x27;    #test_xml_path = &#x27;../imgs/000012.xml&#x27;    img = cv2.imread(test_img_path)    dst = copy.deepcopy(img)    # bndboxs = util.parse_xml(test_xml_path)    # for bndbox in bndboxs:    #    xmin, ymin, xmax, ymax = bndbox    #    cv2.rectangle(dst, (xmin, ymin), (xmax, ymax), color=(0, 255, 0), thickness=1)    # 候选区域建议    selectivesearch.config(gs, img, strategy=&#x27;f&#x27;)    rects = selectivesearch.get_rects(gs)    print(&#x27;候选区域建议数目： %d&#x27; % len(rects))    # softmax = torch.softmax()    svm_thresh = 0.55    # 保存正样本边界框以及    score_list = list()    positive_list = list()    tmp_score_list = list()    tmp_positive_list = list()    start = time.time()    for rect in rects:        xmin, ymin, xmax, ymax = rect        rect_img = img[ymin:ymax, xmin:xmax]        rect_transform = transform(rect_img).to(device)        output = model(rect_transform.unsqueeze(0))[0]        if torch.argmax(output).item() == 1:            &quot;&quot;&quot;            预测为汽车            &quot;&quot;&quot;            probs = torch.softmax(output, dim=0).cpu().numpy()            tmp_score_list.append(probs[1])            tmp_positive_list.append(rect)            if probs[1] &gt;= svm_thresh:                score_list.append(probs[1])                positive_list.append(rect)                # cv2.rectangle(dst, (xmin, ymin), (xmax, ymax), color=(0, 0, 255), thickness=2)                print(rect, output, probs)    end = time.time()    print(&#x27;detect time: %d s&#x27; % (end - start))    tmp_img2 = copy.deepcopy(dst)    draw_box_with_text(tmp_img2, tmp_positive_list, tmp_score_list)    cv2.imshow(&#x27;1&#x27;, tmp_img2)    tmp_img = copy.deepcopy(dst)    draw_box_with_text(tmp_img, positive_list, score_list)    cv2.imshow(&#x27;2&#x27;, tmp_img)    nms_rects, nms_scores = nms(positive_list, score_list)    print(nms_rects)    print(nms_scores)    draw_box_with_text(dst, nms_rects, nms_scores)    cv2.imshow(&#x27;3&#x27;, dst)    cv2.waitKey(0)\n\n\n\nfinetune.pyimport numpy as npimport osimport copyimport timeimport torchimport torch.nn as nnimport torch.optim as optimfrom visdom import Visdomfrom torch.utils.data import DataLoaderimport torchvision.transforms as transformsimport torchvision.models as modelsfrom utils.data.custom_finetune_dataset import CustomFinetuneDatasetfrom utils.data.custom_batch_sampler import CustomBatchSamplerfrom utils.util import check_dirfrom image_handler_show import show_imagedef load_data(data_root_dir):    transform = transforms.Compose([        transforms.ToPILImage(),        transforms.Resize((227, 227)),        transforms.RandomHorizontalFlip(),        transforms.ToTensor(),        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))    ])    data_loaders = &#123;&#125;    data_sizes = &#123;&#125;    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        data_dir = os.path.join(data_root_dir, name)        data_set = CustomFinetuneDataset(data_dir, transform=transform)        data_sampler = CustomBatchSampler(data_set.get_positive_num(), data_set.get_negative_num(), 32, 96)        data_loader = DataLoader(data_set, batch_size=128, sampler=data_sampler, num_workers=8, drop_last=True)        data_loaders[name] = data_loader        data_sizes[name] = data_sampler.__len__()    return data_loaders, data_sizesdef train_model(data_loaders, model, criterion, optimizer, lr_scheduler, num_epochs=25, device=None):    since = time.time()    best_model_weights = copy.deepcopy(model.state_dict())    best_acc = 0.0    viz = Visdom(env=&#x27;loss and val of trainval&#x27;)  # 初始化visdom    viz.line(Y=np.column_stack((0., 0.)), X=np.column_stack((0., 0.)), win=&quot;&#123;&#125; loss/acc&quot;.format(&#x27;train&#x27;),             opts=dict(title=&#x27;&#123;&#125; loss&amp;acc&#x27;.format(&#x27;train&#x27;), xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss/acc&#x27;,                       legend=[&quot;loss&quot;, &quot;acc&quot;]))    viz.line(Y=np.column_stack((0., 0.)), X=np.column_stack((0., 0.)), win=&quot;&#123;&#125; loss/acc&quot;.format(&#x27;val&#x27;),             opts=dict(title=&#x27;&#123;&#125; loss&amp;acc&#x27;.format(&#x27;val&#x27;), xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss/acc&#x27;,                       legend=[&quot;loss&quot;, &quot;acc&quot;]))  # 初始化起点    for epoch in range(num_epochs):        print(&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;.format(epoch, num_epochs))        print(&#x27;-&#x27; * 10)        # Each epoch has a training and validation phase        for phase in [&#x27;train&#x27;, &#x27;val&#x27;]:            if phase == &#x27;train&#x27;:                model.train()  # Set model to training mode            else:                model.eval()  # Set model to evaluate mode            running_loss = 0.0            running_corrects = 0            batch_i = 0            # Iterate over data.            for inputs, labels in data_loaders[phase]:                inputs = inputs.to(device)                labels = labels.to(device)                # zero the parameter gradients                optimizer.zero_grad()                # forward                # track history if only in train                with torch.set_grad_enabled(phase == &#x27;train&#x27;):                    outputs = model(inputs)                    _, preds = torch.max(outputs, 1)                    loss = criterion(outputs, labels)                    # backward + optimize only if in training phase                    if phase == &#x27;train&#x27;:                        loss.backward()                        optimizer.step()                # statistics                running_loss += loss.item() * inputs.size(0)                running_corrects += torch.sum(preds == labels.data)                batch_i += 1                print(&quot;batch&quot;, batch_i, &quot;running_loss_adds=&quot;, running_loss)            if phase == &#x27;train&#x27;:                lr_scheduler.step()            epoch_loss = running_loss / data_sizes[phase]            epoch_acc = running_corrects.double() / data_sizes[phase]            print(&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;.format(                phase, epoch_loss, epoch_acc))            viz.line(Y=np.column_stack((epoch_loss, epoch_acc)), X=np.column_stack((epoch + 1, epoch + 1)),                     win=&quot;&#123;&#125; loss/acc&quot;.format(phase),                     opts=dict(title=&#x27;&#123;&#125; loss&amp;acc&#x27;.format(phase), xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss/acc&#x27;,                               legend=[&quot;loss&quot;, &quot;acc&quot;]), update=&#x27;append&#x27;)            # deep copy the model            if phase == &#x27;val&#x27; and epoch_acc &gt; best_acc:                best_acc = epoch_acc                best_model_weights = copy.deepcopy(model.state_dict())    time_elapsed = time.time() - since    print(&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(        time_elapsed // 60, time_elapsed % 60))    print(&#x27;Best val Acc: &#123;:4f&#125;&#x27;.format(best_acc))    # load best model weights    model.load_state_dict(best_model_weights)    return modeldef show():    # 打印显示    data_loader = data_loaders[&#x27;train&#x27;]    inputs, targets = next(data_loader.__iter__())    print(inputs[0].size(), type(inputs[0]))    trans = transforms.ToPILImage()    print(type(trans(inputs[0])))    print(targets)    print(inputs.shape)    titles = [&quot;TRUE&quot; if i.item() else &quot;FALSE&quot; for i in targets[0:60]]    images = [np.array(trans(i)) for i in inputs[0:60]]    show_image(images, titles=titles, num_cols=12)if __name__ == &#x27;__main__&#x27;:    device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)    data_loaders, data_sizes = load_data(&#x27;./data/finetune_car&#x27;)    model = models.alexnet(pretrained=True)  # 加载前辈们预训练的模型参数    print(model)    # show() # title显示有点问题，只能显示最后一张图片的title    # 把alexnet 变成二分类模型，在最后一层改为2分类    num_features = model.classifier[6].in_features    model.classifier[6] = nn.Linear(num_features, 2)    # print(model)    model = model.to(device)    criterion = nn.CrossEntropyLoss()    optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)    best_model = train_model(data_loaders, model, criterion, optimizer, lr_scheduler, device=device, num_epochs=5)    # 保存最好的模型参数    check_dir(&#x27;./models&#x27;)    torch.save(best_model.state_dict(), &#x27;models/alexnet_car.pth&#x27;)    print(&#x27;done&#x27;)\n\n\n\nlinear_svm.pyimport timeimport copyimport osimport randomimport numpy as npimport torchimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import DataLoaderimport torchvision.transforms as transformsfrom torchvision.models import alexnetfrom visdom import Visdomfrom utils.data.custom_classifier_dataset import CustomClassifierDatasetfrom utils.data.custom_hard_negative_mining_dataset import CustomHardNegativeMiningDatasetfrom utils.data.custom_batch_sampler import CustomBatchSamplerfrom utils.util import check_dirfrom utils.util import save_modelbatch_positive = 32batch_negative = 96batch_total = 128def load_data(data_root_dir):    transform = transforms.Compose([        transforms.ToPILImage(),        transforms.Resize((227, 227)),        transforms.RandomHorizontalFlip(),        transforms.ToTensor(),        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))    ])    data_loaders = &#123;&#125;    data_sizes = &#123;&#125;    remain_negative_list = list()    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        data_dir = os.path.join(data_root_dir, name)        data_set = CustomClassifierDataset(data_dir, transform=transform)        if name is &#x27;train&#x27;:            &quot;&quot;&quot;            使用hard negative mining方式            初始正负样本比例为1:1。由于正样本数远小于负样本，所以以正样本数为基准，在负样本集中随机提取同样数目负样本作为初始负样本集            &quot;&quot;&quot;            positive_list = data_set.get_positives()            negative_list = data_set.get_negatives()            init_negative_idxs = random.sample(range(len(negative_list)), len(positive_list))            init_negative_list = [negative_list[idx] for idx in range(len(negative_list)) if idx in init_negative_idxs]            remain_negative_list = [negative_list[idx] for idx in range(len(negative_list))                                    if idx not in init_negative_idxs]            data_set.set_negative_list(init_negative_list)            data_loaders[&#x27;remain&#x27;] = remain_negative_list        sampler = CustomBatchSampler(data_set.get_positive_num(), data_set.get_negative_num(),                                     batch_positive, batch_negative)        data_loader = DataLoader(data_set, batch_size=batch_total, sampler=sampler, num_workers=8, drop_last=True)        data_loaders[name] = data_loader        data_sizes[name] = len(sampler)    return data_loaders, data_sizesdef hinge_loss(outputs, labels):    &quot;&quot;&quot;    折页损失计算    :param outputs: 大小为(N, num_classes)    :param labels: 大小为(N)    :return: 损失值    &quot;&quot;&quot;    num_labels = len(labels)    corrects = outputs[range(num_labels), labels].unsqueeze(0).T    # 最大间隔    margin = 1.0    margins = outputs - corrects + margin    loss = torch.sum(torch.max(margins, 1)[0]) / len(labels)    # # 正则化强度    # reg = 1e-3    # loss += reg * torch.sum(weight ** 2)    return lossdef add_hard_negatives(hard_negative_list, negative_list, add_negative_list):    for item in hard_negative_list:        if len(add_negative_list) == 0:            # 第一次添加负样本            negative_list.append(item)            add_negative_list.append(list(item[&#x27;rect&#x27;]))        if list(item[&#x27;rect&#x27;]) not in add_negative_list:            negative_list.append(item)            add_negative_list.append(list(item[&#x27;rect&#x27;]))def get_hard_negatives(preds, cache_dicts):    fp_mask = preds == 1    tn_mask = preds == 0    fp_rects = cache_dicts[&#x27;rect&#x27;][fp_mask].numpy()    fp_image_ids = cache_dicts[&#x27;image_id&#x27;][fp_mask].numpy()    tn_rects = cache_dicts[&#x27;rect&#x27;][tn_mask].numpy()    tn_image_ids = cache_dicts[&#x27;image_id&#x27;][tn_mask].numpy()    hard_negative_list = [&#123;&#x27;rect&#x27;: fp_rects[idx], &#x27;image_id&#x27;: fp_image_ids[idx]&#125; for idx in range(len(fp_rects))]    easy_negatie_list = [&#123;&#x27;rect&#x27;: tn_rects[idx], &#x27;image_id&#x27;: tn_image_ids[idx]&#125; for idx in range(len(tn_rects))]    return hard_negative_list, easy_negatie_listdef train_model(data_loaders, model, criterion, optimizer, lr_scheduler, num_epochs=25, device=None):    since = time.time()    best_model_weights = copy.deepcopy(model.state_dict())    best_acc = 0.0    viz = Visdom(env=&#x27;loss and val svm&#x27;)  # 初始化visdom    viz.line(Y=np.column_stack((0., 0.)), X=np.column_stack((0., 0.)), win=&quot;&#123;&#125; loss/acc&quot;.format(&#x27;train&#x27;),             opts=dict(title=&#x27;&#123;&#125; loss&amp;acc&#x27;.format(&#x27;train&#x27;), xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss/acc&#x27;,                       legend=[&quot;loss&quot;, &quot;acc&quot;]))    viz.line(Y=np.column_stack((0., 0.)), X=np.column_stack((0., 0.)), win=&quot;&#123;&#125; loss/acc&quot;.format(&#x27;val&#x27;),             opts=dict(title=&#x27;&#123;&#125; loss&amp;acc&#x27;.format(&#x27;val&#x27;), xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss/acc&#x27;,                       legend=[&quot;loss&quot;, &quot;acc&quot;]))  # 初始化起点    for epoch in range(num_epochs):        print(&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;.format(epoch, num_epochs ))        print(&#x27;-&#x27; * 10)        # Each epoch has a training and validation phase        for phase in [&#x27;train&#x27;, &#x27;val&#x27;]:            if phase == &#x27;train&#x27;:                model.train()  # Set model to training mode            else:                model.eval()  # Set model to evaluate mode            running_loss = 0.0            running_corrects = 0            batch_i = 0            # 输出正负样本数            data_set = data_loaders[phase].dataset            print(&#x27;&#123;&#125; - positive_num: &#123;&#125; - negative_num: &#123;&#125; - data size: &#123;&#125;&#x27;.format(                phase, data_set.get_positive_num(), data_set.get_negative_num(), data_sizes[phase]))            # Iterate over data.            for inputs, labels, cache_dicts in data_loaders[phase]:                inputs = inputs.to(device)                labels = labels.to(device)                # zero the parameter gradients                optimizer.zero_grad()                # forward                # track history if only in train                with torch.set_grad_enabled(phase == &#x27;train&#x27;):                    outputs = model(inputs)                    # print(outputs.shape)                    _, preds = torch.max(outputs, 1)                    loss = criterion(outputs, labels)                    # backward + optimize only if in training phase                    if phase == &#x27;train&#x27;:                        loss.backward()                        optimizer.step()                # statistics                running_loss += loss.item() * inputs.size(0)                running_corrects += torch.sum(preds == labels.data)                batch_i += 1                print(&quot;batch&quot;, batch_i, &quot;running_loss_adds=&quot;, running_loss)            if phase == &#x27;train&#x27;:                lr_scheduler.step()            epoch_loss = running_loss / data_sizes[phase]            epoch_acc = running_corrects.double() / data_sizes[phase]            print(&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;.format(                phase, epoch_loss, epoch_acc))            viz.line(Y=np.column_stack(([epoch_loss], [epoch_acc])), X=np.column_stack(([epoch + 1], [epoch + 1])),                     win=&quot;&#123;&#125; loss/acc&quot;.format(phase),                     opts=dict(title=&#x27;&#123;&#125; loss&amp;acc&#x27;.format(phase), xlabel=&#x27;epoch&#x27;, ylabel=&#x27;loss/acc&#x27;,                               legend=[&quot;loss&quot;, &quot;acc&quot;]), update=&quot;append&quot;)            # deep copy the model            if phase == &#x27;val&#x27; and epoch_acc &gt; best_acc:                best_acc = epoch_acc                best_model_weights = copy.deepcopy(model.state_dict())        # 每一轮训练完成后，测试剩余负样本集，进行hard negative mining        train_dataset = data_loaders[&#x27;train&#x27;].dataset        remain_negative_list = data_loaders[&#x27;remain&#x27;]        jpeg_images = train_dataset.get_jpeg_images()        transform = train_dataset.get_transform()        with torch.set_grad_enabled(False):            remain_dataset = CustomHardNegativeMiningDataset(remain_negative_list, jpeg_images, transform=transform)            remain_data_loader = DataLoader(remain_dataset, batch_size=batch_total, num_workers=8, drop_last=True)            # 获取训练数据集的负样本集            negative_list = train_dataset.get_negatives()            # 记录后续增加的负样本            add_negative_list = data_loaders.get(&#x27;add_negative&#x27;, [])            running_corrects = 0            # Iterate over data.            for inputs, labels, cache_dicts in remain_data_loader:                inputs = inputs.to(device)                labels = labels.to(device)                # zero the parameter gradients                optimizer.zero_grad()                outputs = model(inputs)                # print(outputs.shape)                _, preds = torch.max(outputs, 1)                running_corrects += torch.sum(preds == labels.data)                hard_negative_list, easy_neagtive_list = get_hard_negatives(preds.cpu().numpy(), cache_dicts)                add_hard_negatives(hard_negative_list, negative_list, add_negative_list)            remain_acc = running_corrects.double() / len(remain_negative_list)            print(&#x27;remiam negative size: &#123;&#125;, acc: &#123;:.4f&#125;&#x27;.format(len(remain_negative_list), remain_acc))            # 训练完成后，重置负样本，进行hard negatives mining            train_dataset.set_negative_list(negative_list)            tmp_sampler = CustomBatchSampler(train_dataset.get_positive_num(), train_dataset.get_negative_num(),                                             batch_positive, batch_negative)            data_loaders[&#x27;train&#x27;] = DataLoader(train_dataset, batch_size=batch_total, sampler=tmp_sampler,                                               num_workers=8, drop_last=True)            data_loaders[&#x27;add_negative&#x27;] = add_negative_list            # 重置数据集大小            data_sizes[&#x27;train&#x27;] = len(tmp_sampler)        # 每训练一轮就保存        save_model(model, &#x27;models/linear_svm_alexnet_car_%d.pth&#x27; % epoch)    time_elapsed = time.time() - since    print(&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(        time_elapsed // 60, time_elapsed % 60))    print(&#x27;Best val Acc: &#123;:4f&#125;&#x27;.format(best_acc))    # load best model weights    model.load_state_dict(best_model_weights)    return modelif __name__ == &#x27;__main__&#x27;:    device = torch.device(&#x27;cuda:0&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)    # device = &#x27;cpu&#x27;    data_loaders, data_sizes = load_data(&#x27;./data/classifier_car&#x27;)    # 加载CNN模型    model_path = &#x27;./models/alexnet_car.pth&#x27;    model = alexnet()    num_classes = 2    num_features = model.classifier[6].in_features    model.classifier[6] = nn.Linear(num_features, num_classes)    model.load_state_dict(torch.load(model_path))    model.eval()    # 固定特征提取    for param in model.parameters():        param.requires_grad = False    # 创建SVM分类器    model.classifier[6] = nn.Linear(num_features, num_classes)    # print(model)    model = model.to(device)    criterion = hinge_loss    # 由于初始训练集数量很少，所以降低学习率    optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)    # 共训练25轮，每隔4论减少一次学习率    lr_schduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)    best_model = train_model(data_loaders, model, criterion, optimizer, lr_schduler, num_epochs=25, device=device)    # 保存最好的模型参数    save_model(best_model, &#x27;models/best_linear_svm_alexnet_car.pth&#x27;)    print(&#x27;done&#x27;)\n\n\n\nselectivesearch.pyimport sysimport cv2def get_selective_search():    gs = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()    return gsdef config(gs, img, strategy=&#x27;q&#x27;):    gs.setBaseImage(img)    if (strategy == &#x27;s&#x27;):        gs.switchToSingleStrategy()    elif (strategy == &#x27;f&#x27;):        gs.switchToSelectiveSearchFast()    elif (strategy == &#x27;q&#x27;):        gs.switchToSelectiveSearchQuality()    else:        print(__doc__)        sys.exit(1)def get_rects(gs):    rects = gs.process()    rects[:, 2] += rects[:, 0]    rects[:, 3] += rects[:, 1]    return rectsdef show_rect_in_img(img,rects):    for x1,y1,x2,y2 in rects[0:1000]:        cv2.rectangle(img,(x1,y1),(x2,y2),color=(0,0,255),thickness=2)    return imgif __name__ == &#x27;__main__&#x27;:    &quot;&quot;&quot;    选择性搜索算法操作    &quot;&quot;&quot;    gs = get_selective_search() #实例化,生成对象    img = cv2.imread(&#x27;../imgs/456.jpg&#x27;, cv2.IMREAD_COLOR)    config(gs, img, strategy=&#x27;f&#x27;) #配置对象    rects = get_rects(gs) #根据对象取框    print(&quot;框的位置坐标：\\n&quot;,rects,&quot;\\n框的个数:&quot;,len(rects))    get_img = show_rect_in_img(img,rects)    cv2.imwrite(&#x27;../imgs/777ss.jpg&#x27;,get_img)  #39-42  and 56-58 lines codes  is a demo to show    print(&quot;down&quot;)\n\n\n\nutils&#x2F;datacreate_bbox_regression_data.pyimport osimport shutilimport numpy as npimport utils.util as util# 正样本边界框数目：4035if __name__ == &#x27;__main__&#x27;:    &quot;&quot;&quot;    从voc_car/train目录中提取标注边界框坐标    从finetune_car/train目录中提取训练集正样本坐标（IoU&gt;=0.5），进一步提取IoU&gt;0.6的边界框    数据集保存在bbox_car目录下    &quot;&quot;&quot;    voc_car_train_dir = &#x27;../../data/voc_car/train&#x27;    # ground truth    gt_annotation_dir = os.path.join(voc_car_train_dir, &#x27;Annotations&#x27;)    jpeg_dir = os.path.join(voc_car_train_dir, &#x27;JPEGImages&#x27;)    classifier_car_train_dir = &#x27;../../data/finetune_car/train&#x27;    # positive    positive_annotation_dir = os.path.join(classifier_car_train_dir, &#x27;Annotations&#x27;)    dst_root_dir = &#x27;../../data/bbox_regression/&#x27;    dst_jpeg_dir = os.path.join(dst_root_dir, &#x27;JPEGImages&#x27;)    dst_bndbox_dir = os.path.join(dst_root_dir, &#x27;bndboxs&#x27;)    dst_positive_dir = os.path.join(dst_root_dir, &#x27;positive&#x27;)    util.check_dir(dst_root_dir)    util.check_dir(dst_jpeg_dir)    util.check_dir(dst_bndbox_dir)    util.check_dir(dst_positive_dir)    samples = util.parse_car_csv(voc_car_train_dir)    res_samples = list()    total_positive_num = 0    for sample_name in samples:        # 提取正样本边界框坐标（IoU&gt;=0.5）        positive_annotation_path = os.path.join(positive_annotation_dir, sample_name + &#x27;_1.csv&#x27;)        positive_bndboxes = np.loadtxt(positive_annotation_path, dtype=np.int, delimiter=&#x27; &#x27;)        # 提取标注边界框        gt_annotation_path = os.path.join(gt_annotation_dir, sample_name + &#x27;.xml&#x27;)        bndboxs = util.parse_xml(gt_annotation_path)        # 计算符合条件（IoU&gt;0.6）的候选建议        positive_list = list()        if len(positive_bndboxes.shape) == 1 and len(positive_bndboxes) != 0:            scores = util.iou(positive_bndboxes, bndboxs)            if np.max(scores) &gt; 0.6:                positive_list.append(positive_bndboxes)        elif len(positive_bndboxes.shape) == 2:            for positive_bndboxe in positive_bndboxes:                scores = util.iou(positive_bndboxe, bndboxs)                if np.max(scores) &gt; 0.6:                    positive_list.append(positive_bndboxe)        else:            pass        # 如果存在正样本边界框（IoU&gt;0.6），那么保存相应的图片以及标注边界框        if len(positive_list) &gt; 0:            # 保存图片            jpeg_path = os.path.join(jpeg_dir, sample_name + &quot;.jpg&quot;)            dst_jpeg_path = os.path.join(dst_jpeg_dir, sample_name + &quot;.jpg&quot;)            shutil.copyfile(jpeg_path, dst_jpeg_path)            # 保存标注边界框            dst_bndbox_path = os.path.join(dst_bndbox_dir, sample_name + &quot;.csv&quot;)            np.savetxt(dst_bndbox_path, bndboxs, fmt=&#x27;%s&#x27;, delimiter=&#x27; &#x27;)            # 保存正样本边界框            dst_positive_path = os.path.join(dst_positive_dir, sample_name + &quot;.csv&quot;)            np.savetxt(dst_positive_path, np.array(positive_list), fmt=&#x27;%s&#x27;, delimiter=&#x27; &#x27;)            total_positive_num += len(positive_list)            res_samples.append(sample_name)            print(&#x27;save &#123;&#125; done&#x27;.format(sample_name))        else:            print(&#x27;-------- &#123;&#125; 不符合条件&#x27;.format(sample_name))    dst_csv_path = os.path.join(dst_root_dir, &#x27;car.csv&#x27;)    np.savetxt(dst_csv_path, res_samples, fmt=&#x27;%s&#x27;, delimiter=&#x27; &#x27;)    print(&#x27;total positive num: &#123;&#125;&#x27;.format(total_positive_num))    print(&#x27;done&#x27;)\n\n\n\ncreate_classifier_data.pyimport randomimport numpy as npimport shutilimport timeimport cv2import osimport xmltodictimport selectivesearchfrom utils.util import check_dirfrom utils.util import parse_car_csvfrom utils.util import parse_xmlfrom utils.util import ioufrom utils.util import compute_ious# train# positive num: 67# negative num: 34674# val# positive num: 75# negative num: 26277def parse_annotation_jpeg(annotation_path, jpeg_path, gs):    &quot;&quot;&quot;    获取正负样本（注：忽略属性difficult为True的标注边界框）    正样本：标注边界框    负样本：IoU大于0，小于等于0.3。为了进一步限制负样本数目，其大小必须大于最大标注框的1/5    &quot;&quot;&quot;    img = cv2.imread(jpeg_path)    selectivesearch.config(gs, img, strategy=&#x27;q&#x27;)    # 计算候选建议    rects = selectivesearch.get_rects(gs)    # 获取标注边界框    bndboxs = parse_xml(annotation_path)    # 标注框大小    maximum_bndbox_size = 0    for bndbox in bndboxs:        xmin, ymin, xmax, ymax = bndbox        bndbox_size = (ymax - ymin) * (xmax - xmin)        if bndbox_size &gt; maximum_bndbox_size:            maximum_bndbox_size = bndbox_size    # 获取候选建议和标注边界框的IoU    iou_list = compute_ious(rects, bndboxs)    positive_list = list()    negative_list = list()    for i in range(len(iou_list)):        xmin, ymin, xmax, ymax = rects[i]        rect_size = (ymax - ymin) * (xmax - xmin)        iou_score = iou_list[i]        if 0 &lt; iou_score &lt;= 0.3 and rect_size &gt; maximum_bndbox_size / 5.0:            # 负样本            negative_list.append(rects[i])        else:            pass    return bndboxs, negative_listif __name__ == &#x27;__main__&#x27;:    car_root_dir = &#x27;../../data/voc_car/&#x27;    classifier_root_dir = &#x27;../../data/classifier_car/&#x27;    check_dir(classifier_root_dir)    gs = selectivesearch.get_selective_search()  # 实例化,生成ｇｓ对象    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        src_root_dir = os.path.join(car_root_dir, name)        src_annotation_dir = os.path.join(src_root_dir, &#x27;Annotations&#x27;)        src_jpeg_dir = os.path.join(src_root_dir, &#x27;JPEGImages&#x27;)        dst_root_dir = os.path.join(classifier_root_dir, name)        dst_annotation_dir = os.path.join(dst_root_dir, &#x27;Annotations&#x27;)        dst_jpeg_dir = os.path.join(dst_root_dir, &#x27;JPEGImages&#x27;)        check_dir(dst_root_dir)        check_dir(dst_annotation_dir)        check_dir(dst_jpeg_dir)        total_num_positive = 0        total_num_negative = 0        samples = parse_car_csv(src_root_dir)  # 在src_root_dir目录下加载ｃｓｖ文件        # 复制csv文件        src_csv_path = os.path.join(src_root_dir, &#x27;car.csv&#x27;)        dst_csv_path = os.path.join(dst_root_dir, &#x27;car.csv&#x27;)        shutil.copyfile(src_csv_path, dst_csv_path)        for sample_name in samples:            try:                since = time.time()                src_annotation_path = os.path.join(src_annotation_dir, sample_name + &#x27;.xml&#x27;)                src_jpeg_path = os.path.join(src_jpeg_dir, sample_name + &#x27;.jpg&#x27;)                # 获取正负样本                positive_list, negative_list = parse_annotation_jpeg(src_annotation_path, src_jpeg_path, gs)                total_num_positive += len(positive_list)                total_num_negative += len(negative_list)                dst_annotation_positive_path = os.path.join(dst_annotation_dir, sample_name + &#x27;_1&#x27; + &#x27;.csv&#x27;)                dst_annotation_negative_path = os.path.join(dst_annotation_dir, sample_name + &#x27;_0&#x27; + &#x27;.csv&#x27;)                dst_jpeg_path = os.path.join(dst_jpeg_dir, sample_name + &#x27;.jpg&#x27;)                # 保存图片                shutil.copyfile(src_jpeg_path, dst_jpeg_path)                # 保存正负样本标注                np.savetxt(dst_annotation_positive_path, np.array(positive_list), fmt=&#x27;%d&#x27;, delimiter=&#x27; &#x27;)                np.savetxt(dst_annotation_negative_path, np.array(negative_list), fmt=&#x27;%d&#x27;, delimiter=&#x27; &#x27;)                time_elapsed = time.time() - since                print(&#x27;parse &#123;&#125;.png in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(sample_name, time_elapsed // 60, time_elapsed % 60))            except Exception as err:                print(err)                continue        print(&#x27;%s positive num: %d&#x27; % (name, total_num_positive))        print(&#x27;%s negative num: %d&#x27; % (name, total_num_negative))    print(&#x27;done&#x27;)\n\n\n\ncreate_finetune_data.pyimport timeimport shutilimport numpy as npimport cv2import osimport selectivesearchfrom utils.util import check_dirfrom utils.util import parse_car_csvfrom utils.util import parse_xmlfrom utils.util import compute_ious# train# positive num: 7278　　这是对数据集进行下采样缩到原数据集的10%得到的数据# negative num: 44706# val# positive num: 7951# negative num: 36277def parse_annotation_jpeg(annotation_path, jpeg_path, gs):    &quot;&quot;&quot;    获取正负样本（注：忽略属性difficult为True的标注边界框）    正样本：候选建议与标注边界框IoU大于等于0.5    负样本：IoU大于0,小于0.5。为了进一步限制负样本数目，其大小必须大于标注框的1/5    &quot;&quot;&quot;    img = cv2.imread(jpeg_path)    selectivesearch.config(gs, img, strategy=&#x27;q&#x27;)    # 计算候选建议    rects = selectivesearch.get_rects(gs)    # 获取标注边界框    bndboxs = parse_xml(annotation_path)    # 标注框大小    maximum_bndbox_size = 0    for bndbox in bndboxs:        xmin, ymin, xmax, ymax = bndbox        bndbox_size = (ymax - ymin) * (xmax - xmin)        if bndbox_size &gt; maximum_bndbox_size:            maximum_bndbox_size = bndbox_size    # 获取候选建议和标注边界框的IoU    iou_list = compute_ious(rects, bndboxs)    positive_list = list()    negative_list = list()    for i in range(len(iou_list)):        xmin, ymin, xmax, ymax = rects[i]        rect_size = (ymax - ymin) * (xmax - xmin)        iou_score = iou_list[i]        if iou_list[i] &gt;= 0.5:            # 正样本            positive_list.append(rects[i])        if 0 &lt; iou_list[i] &lt; 0.5 and rect_size &gt; maximum_bndbox_size / 5.0:            # 负样本            negative_list.append(rects[i])        else:            pass    return positive_list, negative_listif __name__ == &#x27;__main__&#x27;:    car_root_dir = &#x27;../../data/voc_car/&#x27;    finetune_root_dir = &#x27;../../data/finetune_car/&#x27;    check_dir(finetune_root_dir)    gs = selectivesearch.get_selective_search()    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        src_root_dir = os.path.join(car_root_dir, name)        src_annotation_dir = os.path.join(src_root_dir, &#x27;Annotations&#x27;)        src_jpeg_dir = os.path.join(src_root_dir, &#x27;JPEGImages&#x27;)        dst_root_dir = os.path.join(finetune_root_dir, name)        dst_annotation_dir = os.path.join(dst_root_dir, &#x27;Annotations&#x27;)        dst_jpeg_dir = os.path.join(dst_root_dir, &#x27;JPEGImages&#x27;)        check_dir(dst_root_dir)        check_dir(dst_annotation_dir)        check_dir(dst_jpeg_dir)        total_num_positive = 0        total_num_negative = 0        samples = parse_car_csv(src_root_dir)  # 拿到根目录下的csv 文件        # 复制csv文件        src_csv_path = os.path.join(src_root_dir, &#x27;car.csv&#x27;)        dst_csv_path = os.path.join(dst_root_dir, &#x27;car.csv&#x27;)        shutil.copyfile(src_csv_path, dst_csv_path)        for sample_name in samples:            since = time.time()            src_annotation_path = os.path.join(src_annotation_dir, sample_name + &#x27;.xml&#x27;)            src_jpeg_path = os.path.join(src_jpeg_dir, sample_name + &#x27;.jpg&#x27;)            # 获取正负样本            positive_list, negative_list = parse_annotation_jpeg(src_annotation_path, src_jpeg_path, gs)            total_num_positive += len(positive_list)            total_num_negative += len(negative_list)            dst_annotation_positive_path = os.path.join(dst_annotation_dir, sample_name + &#x27;_1&#x27; + &#x27;.csv&#x27;)            dst_annotation_negative_path = os.path.join(dst_annotation_dir, sample_name + &#x27;_0&#x27; + &#x27;.csv&#x27;)            dst_jpeg_path = os.path.join(dst_jpeg_dir, sample_name + &#x27;.jpg&#x27;)            # 保存图片            shutil.copyfile(src_jpeg_path, dst_jpeg_path)            # 保存正负样本标注            np.savetxt(dst_annotation_positive_path, np.array(positive_list), fmt=&#x27;%d&#x27;, delimiter=&#x27; &#x27;)            np.savetxt(dst_annotation_negative_path, np.array(negative_list), fmt=&#x27;%d&#x27;, delimiter=&#x27; &#x27;)            time_elapsed = time.time() - since            print(&#x27;parse &#123;&#125;.png in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(sample_name, time_elapsed // 60, time_elapsed % 60))        print(&#x27;%s positive num: %d&#x27; % (name, total_num_positive))        print(&#x27;%s negative num: %d&#x27; % (name, total_num_negative))    print(&#x27;done&#x27;)\n\n\n\ncustom_batch_sampler.pyimport numpy  as npimport randomfrom torch.utils.data import Samplerfrom torch.utils.data import DataLoaderimport torchvision.transforms as transformsfrom utils.data.custom_finetune_dataset import CustomFinetuneDatasetclass CustomBatchSampler(Sampler):    def __init__(self, num_positive, num_negative, batch_positive, batch_negative) -&gt; None:        &quot;&quot;&quot;        2分类数据集        每次批量处理，其中batch_positive个正样本，batch_negative个负样本        @param num_positive: 正样本数目        @param num_negative: 负样本数目        @param batch_positive: 单次正样本数        @param batch_negative: 单次负样本数        &quot;&quot;&quot;        self.num_positive = num_positive        self.num_negative = num_negative        self.batch_positive = batch_positive        self.batch_negative = batch_negative        length = num_positive + num_negative        self.idx_list = list(range(length))        self.batch = batch_negative + batch_positive        self.num_iter = length // self.batch    def __iter__(self):        sampler_list = list()        for i in range(self.num_iter):            tmp = np.concatenate(                (random.sample(self.idx_list[:self.num_positive], self.batch_positive),                 random.sample(self.idx_list[self.num_positive:], self.batch_negative))            )            random.shuffle(tmp)            sampler_list.extend(tmp)        return iter(sampler_list)    def __len__(self) -&gt; int:        return self.num_iter * self.batch    def get_num_batch(self) -&gt; int:        return self.num_iter\n\n\n\ncustom_bbox_regression_dataset.pyimport osimport cv2import numpy as npimport torchimport torchvision.transforms as transformsfrom torch.utils.data import Datasetfrom torch.utils.data import DataLoaderimport utils.util as utilclass BBoxRegressionDataset(Dataset):    def __init__(self, root_dir, transform=None):        super(BBoxRegressionDataset, self).__init__()        self.transform = transform        samples = util.parse_car_csv(root_dir)        jpeg_list = list()        # 保存&#123;&#x27;image_id&#x27;: ?, &#x27;positive&#x27;: ?, &#x27;bndbox&#x27;: ?&#125;        box_list = list()        for i in range(len(samples)):            sample_name = samples[i]            jpeg_path = os.path.join(root_dir, &#x27;JPEGImages&#x27;, sample_name + &#x27;.jpg&#x27;)            bndbox_path = os.path.join(root_dir, &#x27;bndboxs&#x27;, sample_name + &#x27;.csv&#x27;)            positive_path = os.path.join(root_dir, &#x27;positive&#x27;, sample_name + &#x27;.csv&#x27;)            jpeg_list.append(cv2.imread(jpeg_path))            bndboxes = np.loadtxt(bndbox_path, dtype=np.int, delimiter=&#x27; &#x27;)            positives = np.loadtxt(positive_path, dtype=np.int, delimiter=&#x27; &#x27;)            if len(positives.shape) == 1:                bndbox = self.get_bndbox(bndboxes, positives)                box_list.append(&#123;&#x27;image_id&#x27;: i, &#x27;positive&#x27;: positives, &#x27;bndbox&#x27;: bndbox&#125;)            else:                for positive in positives:                    bndbox = self.get_bndbox(bndboxes, positive)                    box_list.append(&#123;&#x27;image_id&#x27;: i, &#x27;positive&#x27;: positive, &#x27;bndbox&#x27;: bndbox&#125;)        self.jpeg_list = jpeg_list        self.box_list = box_list    def __getitem__(self, index: int):        assert index &lt; self.__len__(), &#x27;数据集大小为%d，当前输入下标为%d&#x27; % (self.__len__(), index)        box_dict = self.box_list[index]        image_id = box_dict[&#x27;image_id&#x27;]        positive = box_dict[&#x27;positive&#x27;]        bndbox = box_dict[&#x27;bndbox&#x27;]        # 获取预测图像        jpeg_img = self.jpeg_list[image_id]        xmin, ymin, xmax, ymax = positive        image = jpeg_img[ymin:ymax, xmin:xmax]        if self.transform:            image = self.transform(image)        # 计算P/G的x/y/w/h        target = dict()        p_w = xmax - xmin        p_h = ymax - ymin        p_x = xmin + p_w / 2        p_y = ymin + p_h / 2        xmin, ymin, xmax, ymax = bndbox        g_w = xmax - xmin        g_h = ymax - ymin        g_x = xmin + g_w / 2        g_y = ymin + g_h / 2        # 计算t        t_x = (g_x - p_x) / p_w        t_y = (g_y - p_y) / p_h        t_w = np.log(g_w / p_w)        t_h = np.log(g_h / p_h)        return image, np.array((t_x, t_y, t_w, t_h))    def __len__(self):        return len(self.box_list)    def get_bndbox(self, bndboxes, positive):        &quot;&quot;&quot;        返回和positive的IoU最大的标注边界框        :param bndboxes: 大小为[N, 4]或者[4]        :param positive: 大小为[4]        :return: [4]        &quot;&quot;&quot;        if len(bndboxes.shape) == 1:            # 只有一个标注边界框，直接返回即可            return bndboxes        else:            scores = util.iou(positive, bndboxes)            return bndboxes[np.argmax(scores)]\n\n\n\ncustom_classifier_dataset.pyimport numpy  as npimport osimport cv2from PIL import Imagefrom torch.utils.data import Datasetfrom torch.utils.data import DataLoaderimport torchvision.transforms as transformsfrom utils.util import parse_car_csvclass CustomClassifierDataset(Dataset):    def __init__(self, root_dir, transform=None):        samples = parse_car_csv(root_dir)        jpeg_images = list()        positive_list = list()        negative_list = list()        for idx in range(len(samples)):            sample_name = samples[idx]            jpeg_images.append(cv2.imread(os.path.join(root_dir, &#x27;JPEGImages&#x27;, sample_name + &quot;.jpg&quot;)))            positive_annotation_path = os.path.join(root_dir, &#x27;Annotations&#x27;, sample_name + &#x27;_1.csv&#x27;)            positive_annotations = np.loadtxt(positive_annotation_path, dtype=np.int, delimiter=&#x27; &#x27;)            # 考虑csv文件为空或者仅包含单个标注框            if len(positive_annotations.shape) == 1:                # 单个标注框坐标                if positive_annotations.shape[0] == 4:                    positive_dict = dict()                    positive_dict[&#x27;rect&#x27;] = positive_annotations                    positive_dict[&#x27;image_id&#x27;] = idx                    # positive_dict[&#x27;image_name&#x27;] = sample_name                    positive_list.append(positive_dict)            else:                for positive_annotation in positive_annotations:                    positive_dict = dict()                    positive_dict[&#x27;rect&#x27;] = positive_annotation                    positive_dict[&#x27;image_id&#x27;] = idx                    # positive_dict[&#x27;image_name&#x27;] = sample_name                    positive_list.append(positive_dict)            negative_annotation_path = os.path.join(root_dir, &#x27;Annotations&#x27;, sample_name + &#x27;_0.csv&#x27;)            negative_annotations = np.loadtxt(negative_annotation_path, dtype=np.int, delimiter=&#x27; &#x27;)            # 考虑csv文件为空或者仅包含单个标注框            if len(negative_annotations.shape) == 1:                # 单个标注框坐标                if negative_annotations.shape[0] == 4:                    negative_dict = dict()                    negative_dict[&#x27;rect&#x27;] = negative_annotations                    negative_dict[&#x27;image_id&#x27;] = idx                    # negative_dict[&#x27;image_name&#x27;] = sample_name                    negative_list.append(negative_dict)            else:                for negative_annotation in negative_annotations:                    negative_dict = dict()                    negative_dict[&#x27;rect&#x27;] = negative_annotation                    negative_dict[&#x27;image_id&#x27;] = idx                    # negative_dict[&#x27;image_name&#x27;] = sample_name                    negative_list.append(negative_dict)        self.transform = transform        self.jpeg_images = jpeg_images        self.positive_list = positive_list        self.negative_list = negative_list    def __getitem__(self, index: int):        # 定位下标所属图像        if index &lt; len(self.positive_list):            # 正样本            target = 1            positive_dict = self.positive_list[index]            xmin, ymin, xmax, ymax = positive_dict[&#x27;rect&#x27;]            image_id = positive_dict[&#x27;image_id&#x27;]            image = self.jpeg_images[image_id][ymin:ymax, xmin:xmax]            cache_dict = positive_dict        else:            # 负样本            target = 0            idx = index - len(self.positive_list)            negative_dict = self.negative_list[idx]            xmin, ymin, xmax, ymax = negative_dict[&#x27;rect&#x27;]            image_id = negative_dict[&#x27;image_id&#x27;]            image = self.jpeg_images[image_id][ymin:ymax, xmin:xmax]            cache_dict = negative_dict        # print(&#x27;index: %d image_id: %d target: %d image.shape: %s [xmin, ymin, xmax, ymax]: [%d, %d, %d, %d]&#x27; %        #       (index, image_id, target, str(image.shape), xmin, ymin, xmax, ymax))        if self.transform:            image = self.transform(image)        return image, target, cache_dict    def __len__(self) -&gt; int:        return len(self.positive_list) + len(self.negative_list)    def get_transform(self):        return self.transform    def get_jpeg_images(self) -&gt; list:        return self.jpeg_images    def get_positive_num(self) -&gt; int:        return len(self.positive_list)    def get_negative_num(self) -&gt; int:        return len(self.negative_list)    def get_positives(self) -&gt; list:        return self.positive_list    def get_negatives(self) -&gt; list:        return self.negative_list    # 用于hard negative mining    # 替换负样本    def set_negative_list(self, negative_list):        self.negative_list = negative_list\n\n\n\ncustom_finetune_dataset.pyimport numpy  as npimport osimport cv2from PIL import Imagefrom torch.utils.data import Datasetfrom torch.utils.data import DataLoaderimport torchvision.transforms as transformsfrom utils.util import parse_car_csvclass CustomFinetuneDataset(Dataset):    def __init__(self, root_dir, transform=None):        samples = parse_car_csv(root_dir)        jpeg_images = [cv2.imread(os.path.join(root_dir, &#x27;JPEGImages&#x27;, sample_name + &quot;.jpg&quot;))                       for sample_name in samples]        positive_annotations = [os.path.join(root_dir, &#x27;Annotations&#x27;, sample_name + &#x27;_1.csv&#x27;)                                for sample_name in samples]        negative_annotations = [os.path.join(root_dir, &#x27;Annotations&#x27;, sample_name + &#x27;_0.csv&#x27;)                                for sample_name in samples]        # 边界　　计数        positive_sizes = list()        negative_sizes = list()        # 边界框坐标,抽取出 边界值放到 下面的列表里面        positive_rects = list()        negative_rects = list()        for annotation_path in positive_annotations:            rects = np.loadtxt(annotation_path, dtype=np.int, delimiter=&#x27; &#x27;)            # 存在文件为空或者文件中仅有单行数据            if len(rects.shape) == 1:                # 是否为单行                if rects.shape[0] == 4:                    positive_rects.append(rects)                    positive_sizes.append(1)                else:                    positive_sizes.append(0)            else:                positive_rects.extend(rects)                positive_sizes.append(len(rects))        for annotation_path in negative_annotations:            rects = np.loadtxt(annotation_path, dtype=np.int, delimiter=&#x27; &#x27;)            # 和正样本规则一样            if len(rects.shape) == 1:                if rects.shape[0] == 4:                    negative_rects.append(rects)                    negative_sizes.append(1)                else:                    positive_sizes.append(0)            else:                negative_rects.extend(rects)                negative_sizes.append(len(rects))        self.transform = transform        self.jpeg_images = jpeg_images        self.positive_sizes = positive_sizes        self.negative_sizes = negative_sizes        self.positive_rects = positive_rects        self.negative_rects = negative_rects        self.total_positive_num = int(np.sum(positive_sizes))        self.total_negative_num = int(np.sum(negative_sizes))    def __getitem__(self, index: int):        # 定位下标所属图像        image_id = len(self.jpeg_images) - 1        if index &lt; self.total_positive_num:            # 正样本            target = 1            xmin, ymin, xmax, ymax = self.positive_rects[index]            # 寻找所属图像            for i in range(len(self.positive_sizes) - 1):                if np.sum(self.positive_sizes[:i]) &lt;= index &lt; np.sum(self.positive_sizes[:(i + 1)]):                    image_id = i                    break            image = self.jpeg_images[image_id][ymin:ymax, xmin:xmax]        else:            # 负样本            target = 0            idx = index - self.total_positive_num            xmin, ymin, xmax, ymax = self.negative_rects[idx]            # 寻找所属图像            for i in range(len(self.negative_sizes) - 1):                if np.sum(self.negative_sizes[:i]) &lt;= idx &lt; np.sum(self.negative_sizes[:(i + 1)]):                    image_id = i                    break            image = self.jpeg_images[image_id][ymin:ymax, xmin:xmax]        # print(&#x27;index: %d image_id: %d target: %d image.shape: %s [xmin, ymin, xmax, ymax]: [%d, %d, %d, %d]&#x27; %        #       (index, image_id, target, str(image.shape), xmin, ymin, xmax, ymax))        if self.transform:            image = self.transform(image)        return image, target    def __len__(self) -&gt; int:        return self.total_positive_num + self.total_negative_num    def get_positive_num(self) -&gt; int:        return self.total_positive_num    def get_negative_num(self) -&gt; int:        return self.total_negative_num\n\n\n\ncustom_hard_negative_mining_dataset.pyimport torch.nn as nnfrom torch.utils.data import Datasetfrom utils.data.custom_classifier_dataset import CustomClassifierDatasetclass CustomHardNegativeMiningDataset(Dataset):    def __init__(self, negative_list, jpeg_images, transform=None):        self.negative_list = negative_list        self.jpeg_images = jpeg_images        self.transform = transform    def __getitem__(self, index: int):        target = 0        negative_dict = self.negative_list[index]        xmin, ymin, xmax, ymax = negative_dict[&#x27;rect&#x27;]        image_id = negative_dict[&#x27;image_id&#x27;]        image = self.jpeg_images[image_id][ymin:ymax, xmin:xmax]        if self.transform:            image = self.transform(image)        return image, target, negative_dict    def __len__(self) -&gt; int:        return len(self.negative_list)if __name__ == &#x27;__main__&#x27;:    root_dir = &#x27;../../data/classifier_car/train&#x27;    data_set = CustomClassifierDataset(root_dir)    negative_list = data_set.get_negatives()    jpeg_images = data_set.get_jpeg_images()    transform = data_set.get_transform()    hard_negative_dataset = CustomHardNegativeMiningDataset(negative_list, jpeg_images, transform=transform)    image, target, negative_dict = hard_negative_dataset.__getitem__(100)    print(image.shape)    print(target)    print(negative_dict)\n\n\n\npascal_voc.pyimport cv2import numpy as npfrom torchvision.datasets import VOCDetectionif __name__ == &#x27;__main__&#x27;:    &quot;&quot;&quot;    下载PASCAL VOC数据集    &quot;&quot;&quot;    dataset = VOCDetection(&#x27;../../data&#x27;, year=&#x27;2007&#x27;, image_set=&#x27;trainval&#x27;, download=True)    print(&quot;数据集数目&quot;, len(dataset))    img, target = dataset.__getitem__(1000)    img = np.array(img)    print(&quot;目标检测数据集的目标&quot;,target)    print(&quot;图片尺寸&quot;,img.shape)    cv2.imshow(&#x27;img&#x27;, img)    cv2.waitKey(0)\n\n\n\npascal_voc_car.pyimport osimport shutil  # 用copyfile这个函数import randomimport numpy as npimport xmltodictfrom utils.util import check_dirsuffix_xml = &#x27;.xml&#x27;suffix_jpeg = &#x27;.jpg&#x27;car_train_path = &#x27;../../data/VOCdevkit/VOC2007/ImageSets/Main/car_train.txt&#x27;car_val_path = &#x27;../../data/VOCdevkit/VOC2007/ImageSets/Main/car_val.txt&#x27;voc_annotation_dir = &#x27;../../data/VOCdevkit/VOC2007/Annotations/&#x27;voc_jpeg_dir = &#x27;../../data/VOCdevkit/VOC2007/JPEGImages/&#x27;car_root_dir = &#x27;../../data/voc_car/&#x27;def parse_train_val(data_path):    &quot;&quot;&quot;    提取指定类别图像，这里取的是含汽车（int(res[2]) == 1）图片的编号    &quot;&quot;&quot;    samples = []    with open(data_path, mode=&#x27;r&#x27;) as file:        lines = file.readlines()        for line in lines:            res = line.strip().split(&#x27; &#x27;)            if len(res) == 3 and int(res[2]) == 1:  # 选出正样本，res[2]＝＝０是标注者给出难分辨的样本的标签                samples.append(res[0])    return np.array(samples)def sample_train_val(samples):    &quot;&quot;&quot;    随机采样样本，减少数据集个数（留下1/7）    &quot;&quot;&quot;    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        dataset = samples[name]        length = len(dataset)        random_samples = random.sample(range(length), int(length / 7))        new_dataset = dataset[random_samples]        samples[name] = new_dataset    return samplesdef parse_car(sample_list):    &quot;&quot;&quot;    遍历所有的标注文件，筛选包含car的样本    &quot;&quot;&quot;    car_samples = list()    for sample_name in sample_list:        annotation_path = os.path.join(voc_annotation_dir, sample_name + suffix_xml)        with open(annotation_path, &#x27;rb&#x27;) as f:            xml_dict = xmltodict.parse(f)            # print(xml_dict)            bndboxs = list()            objects = xml_dict[&#x27;annotation&#x27;][&#x27;object&#x27;]            if isinstance(objects, list):                for obj in objects:                    obj_name = obj[&#x27;name&#x27;]                    difficult = int(obj[&#x27;difficult&#x27;])                    if &#x27;car&#x27;.__eq__(obj_name) and difficult != 1:                        car_samples.append(sample_name)            elif isinstance(objects, dict):                obj_name = objects[&#x27;name&#x27;]                difficult = int(objects[&#x27;difficult&#x27;])                if &#x27;car&#x27;.__eq__(obj_name) and difficult != 1:                    car_samples.append(sample_name)            else:                pass    return car_samplesdef save_car(car_samples, data_root_dir, data_annotation_dir, data_jpeg_dir):    &quot;&quot;&quot;    保存类别Car的样本图片和标注文件    &quot;&quot;&quot;    for sample_name in car_samples:        src_annotation_path = os.path.join(voc_annotation_dir, sample_name + suffix_xml)        dst_annotation_path = os.path.join(data_annotation_dir, sample_name + suffix_xml)        shutil.copyfile(src_annotation_path, dst_annotation_path)        src_jpeg_path = os.path.join(voc_jpeg_dir, sample_name + suffix_jpeg)        dst_jpeg_path = os.path.join(data_jpeg_dir, sample_name + suffix_jpeg)        shutil.copyfile(src_jpeg_path, dst_jpeg_path)    csv_path = os.path.join(data_root_dir, &#x27;car.csv&#x27;)    np.savetxt(csv_path, np.array(car_samples), fmt=&#x27;%s&#x27;)if __name__ == &#x27;__main__&#x27;:    samples = &#123;&#x27;train&#x27;: parse_train_val(car_train_path), &#x27;val&#x27;: parse_train_val(car_val_path)&#125;  # 定义一个字典    print(&quot;source total&quot;,len(samples[&#x27;train&#x27;])+len(samples[&#x27;val&#x27;]))    samples = sample_train_val(samples)  # 随机下采样,减少数据量    print(&quot;1/7倍&quot;, len(samples[&#x27;train&#x27;])+len(samples[&#x27;val&#x27;]))    check_dir(car_root_dir)    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        data_root_dir = os.path.join(car_root_dir, name)        data_annotation_dir = os.path.join(data_root_dir, &#x27;Annotations&#x27;)        data_jpeg_dir = os.path.join(data_root_dir, &#x27;JPEGImages&#x27;)        check_dir(data_root_dir)        check_dir(data_annotation_dir)        check_dir(data_jpeg_dir)        save_car(samples[name], data_root_dir, data_annotation_dir, data_jpeg_dir)    print(&#x27;done&#x27;)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1、 .&#x2F;py&#x2F;utils&#x2F;data&#x2F;pascal_voc.pyimport cv2import numpy as npfrom torchvision.datasets import VOCDetectionif __name__ == &#x27;__main__&#x27;:    &quot;&quot;&quot;    下载PASCAL VOC数据集    &quot;&quot;&quot;    dataset = VOCDetection(&#x27;../../data&#x27;, year=&#x27;2007&#x27;, image_set=&#x27;trainval&#x27;, download=True)    print(&quot;数据集数目&quot;, len(dataset))    img, target = dataset.__getitem__(1000)    img = np.array(img)    print(&quot;目标检测数据集的目标&quot;,target)    print(&quot;图片尺寸&quot;,img.shape)    cv2.imshow(&#x27;img&#x27;, img)    cv2.waitKey(0)\n\n\n\n\n\n2.2、 .&#x2F;py&#x2F;utils&#x2F;data&#x2F;pascal_voc_car.pyimport osimport shutil  # 用copyfile这个函数import randomimport numpy as npimport xmltodictfrom utils.util import check_dirsuffix_xml = &#x27;.xml&#x27;suffix_jpeg = &#x27;.jpg&#x27;car_train_path = &#x27;../../data/VOCdevkit/VOC2007/ImageSets/Main/car_train.txt&#x27;car_val_path = &#x27;../../data/VOCdevkit/VOC2007/ImageSets/Main/car_val.txt&#x27;voc_annotation_dir = &#x27;../../data/VOCdevkit/VOC2007/Annotations/&#x27;voc_jpeg_dir = &#x27;../../data/VOCdevkit/VOC2007/JPEGImages/&#x27;car_root_dir = &#x27;../../data/voc_car/&#x27;def parse_train_val(data_path):    &quot;&quot;&quot;    提取指定类别图像，这里取的是含汽车（int(res[2]) == 1）图片的编号    &quot;&quot;&quot;    samples = []    with open(data_path, mode=&#x27;r&#x27;) as file:        lines = file.readlines()        for line in lines:            res = line.strip().split(&#x27; &#x27;)            if len(res) == 3 and int(res[2]) == 1:  # 选出正样本，res[2]＝＝０是标注者给出难分辨的样本的标签                samples.append(res[0])    return np.array(samples)def sample_train_val(samples):    &quot;&quot;&quot;    随机采样样本，减少数据集个数（留下1/7）    &quot;&quot;&quot;    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        dataset = samples[name]        length = len(dataset)        random_samples = random.sample(range(length), int(length / 7))        new_dataset = dataset[random_samples]        samples[name] = new_dataset    return samplesdef parse_car(sample_list):    &quot;&quot;&quot;    遍历所有的标注文件，筛选包含car的样本    &quot;&quot;&quot;    car_samples = list()    for sample_name in sample_list:        annotation_path = os.path.join(voc_annotation_dir, sample_name + suffix_xml)        with open(annotation_path, &#x27;rb&#x27;) as f:            xml_dict = xmltodict.parse(f)            # print(xml_dict)            bndboxs = list()            objects = xml_dict[&#x27;annotation&#x27;][&#x27;object&#x27;]            if isinstance(objects, list):                for obj in objects:                    obj_name = obj[&#x27;name&#x27;]                    difficult = int(obj[&#x27;difficult&#x27;])                    if &#x27;car&#x27;.__eq__(obj_name) and difficult != 1:                        car_samples.append(sample_name)            elif isinstance(objects, dict):                obj_name = objects[&#x27;name&#x27;]                difficult = int(objects[&#x27;difficult&#x27;])                if &#x27;car&#x27;.__eq__(obj_name) and difficult != 1:                    car_samples.append(sample_name)            else:                pass    return car_samplesdef save_car(car_samples, data_root_dir, data_annotation_dir, data_jpeg_dir):    &quot;&quot;&quot;    保存类别Car的样本图片和标注文件    &quot;&quot;&quot;    for sample_name in car_samples:        src_annotation_path = os.path.join(voc_annotation_dir, sample_name + suffix_xml)        dst_annotation_path = os.path.join(data_annotation_dir, sample_name + suffix_xml)        shutil.copyfile(src_annotation_path, dst_annotation_path)        src_jpeg_path = os.path.join(voc_jpeg_dir, sample_name + suffix_jpeg)        dst_jpeg_path = os.path.join(data_jpeg_dir, sample_name + suffix_jpeg)        shutil.copyfile(src_jpeg_path, dst_jpeg_path)    csv_path = os.path.join(data_root_dir, &#x27;car.csv&#x27;)    np.savetxt(csv_path, np.array(car_samples), fmt=&#x27;%s&#x27;)if __name__ == &#x27;__main__&#x27;:    samples = &#123;&#x27;train&#x27;: parse_train_val(car_train_path), &#x27;val&#x27;: parse_train_val(car_val_path)&#125;  # 定义一个字典    print(&quot;source total&quot;,len(samples[&#x27;train&#x27;])+len(samples[&#x27;val&#x27;]))    samples = sample_train_val(samples)  # 随机下采样,减少数据量    print(&quot;1/7倍&quot;, len(samples[&#x27;train&#x27;])+len(samples[&#x27;val&#x27;]))    check_dir(car_root_dir)    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        data_root_dir = os.path.join(car_root_dir, name)        data_annotation_dir = os.path.join(data_root_dir, &#x27;Annotations&#x27;)        data_jpeg_dir = os.path.join(data_root_dir, &#x27;JPEGImages&#x27;)        check_dir(data_root_dir)        check_dir(data_annotation_dir)        check_dir(data_jpeg_dir)        save_car(samples[name], data_root_dir, data_annotation_dir, data_jpeg_dir)    print(&#x27;done&#x27;)\n\n\n\n2.3、 .&#x2F;py&#x2F;utils&#x2F;data&#x2F;create_finetune_data.pyimport timeimport shutilimport numpy as npimport cv2import osimport selectivesearchfrom utils.util import check_dirfrom utils.util import parse_car_csvfrom utils.util import parse_xmlfrom utils.util import compute_iousdef parse_annotation_jpeg(annotation_path, jpeg_path, gs):    &quot;&quot;&quot;    获取正负样本（注：忽略属性difficult为True的标注边界框）    正样本：候选建议与标注边界框IoU大于等于0.5    负样本：IoU大于0,小于0.5。为了进一步限制负样本数目，其大小必须大于标注框的1/5    &quot;&quot;&quot;    img = cv2.imread(jpeg_path)    selectivesearch.config(gs, img, strategy=&#x27;q&#x27;)    # 计算候选建议    rects = selectivesearch.get_rects(gs)    # 获取标注边界框    bndboxs = parse_xml(annotation_path)    # 标注框大小    maximum_bndbox_size = 0    for bndbox in bndboxs:        xmin, ymin, xmax, ymax = bndbox        bndbox_size = (ymax - ymin) * (xmax - xmin)        if bndbox_size &gt; maximum_bndbox_size:            maximum_bndbox_size = bndbox_size    # 获取候选建议和标注边界框的IoU    iou_list = compute_ious(rects, bndboxs)    positive_list = list()    negative_list = list()    for i in range(len(iou_list)):        xmin, ymin, xmax, ymax = rects[i]        rect_size = (ymax - ymin) * (xmax - xmin)        iou_score = iou_list[i]        if iou_list[i] &gt;= 0.5:            # 正样本            positive_list.append(rects[i])        if 0 &lt; iou_list[i] &lt; 0.5 and rect_size &gt; maximum_bndbox_size / 5.0:            # 负样本            negative_list.append(rects[i])        else:            pass    return positive_list, negative_listif __name__ == &#x27;__main__&#x27;:    car_root_dir = &#x27;../../data/voc_car/&#x27;    finetune_root_dir = &#x27;../../data/finetune_car/&#x27;    check_dir(finetune_root_dir)    gs = selectivesearch.get_selective_search()    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        src_root_dir = os.path.join(car_root_dir, name)        src_annotation_dir = os.path.join(src_root_dir, &#x27;Annotations&#x27;)        src_jpeg_dir = os.path.join(src_root_dir, &#x27;JPEGImages&#x27;)        dst_root_dir = os.path.join(finetune_root_dir, name)        dst_annotation_dir = os.path.join(dst_root_dir, &#x27;Annotations&#x27;)        dst_jpeg_dir = os.path.join(dst_root_dir, &#x27;JPEGImages&#x27;)        check_dir(dst_root_dir)        check_dir(dst_annotation_dir)        check_dir(dst_jpeg_dir)        total_num_positive = 0        total_num_negative = 0        samples = parse_car_csv(src_root_dir)  # 拿到根目录下的csv 文件        # 复制csv文件        src_csv_path = os.path.join(src_root_dir, &#x27;car.csv&#x27;)        dst_csv_path = os.path.join(dst_root_dir, &#x27;car.csv&#x27;)        shutil.copyfile(src_csv_path, dst_csv_path)        for sample_name in samples:            since = time.time()            src_annotation_path = os.path.join(src_annotation_dir, sample_name + &#x27;.xml&#x27;)            src_jpeg_path = os.path.join(src_jpeg_dir, sample_name + &#x27;.jpg&#x27;)            # 获取正负样本            positive_list, negative_list = parse_annotation_jpeg(src_annotation_path, src_jpeg_path, gs)            total_num_positive += len(positive_list)            total_num_negative += len(negative_list)            dst_annotation_positive_path = os.path.join(dst_annotation_dir, sample_name + &#x27;_1&#x27; + &#x27;.csv&#x27;)            dst_annotation_negative_path = os.path.join(dst_annotation_dir, sample_name + &#x27;_0&#x27; + &#x27;.csv&#x27;)            dst_jpeg_path = os.path.join(dst_jpeg_dir, sample_name + &#x27;.jpg&#x27;)            # 保存图片            shutil.copyfile(src_jpeg_path, dst_jpeg_path)            # 保存正负样本标注            np.savetxt(dst_annotation_positive_path, np.array(positive_list), fmt=&#x27;%d&#x27;, delimiter=&#x27; &#x27;)            np.savetxt(dst_annotation_negative_path, np.array(negative_list), fmt=&#x27;%d&#x27;, delimiter=&#x27; &#x27;)            time_elapsed = time.time() - since            print(&#x27;parse &#123;&#125;.png in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(sample_name, time_elapsed // 60, time_elapsed % 60))        print(&#x27;%s positive num: %d&#x27; % (name, total_num_positive))        print(&#x27;%s negative num: %d&#x27; % (name, total_num_negative))    print(&#x27;done&#x27;)\n\n\n\n\n\n\n\n2.4、 .&#x2F;py&#x2F;utils&#x2F;data&#x2F;create_classifier_data.pyimport randomimport numpy as npimport shutilimport timeimport cv2import osimport xmltodictimport selectivesearchfrom utils.util import check_dirfrom utils.util import parse_car_csvfrom utils.util import parse_xmlfrom utils.util import ioufrom utils.util import compute_ious# train# positive num: 67# negative num: 34674# val# positive num: 75# negative num: 26277def parse_annotation_jpeg(annotation_path, jpeg_path, gs):    &quot;&quot;&quot;    获取正负样本（注：忽略属性difficult为True的标注边界框）    正样本：标注边界框    负样本：IoU大于0，小于等于0.3。为了进一步限制负样本数目，其大小必须大于最大标注框的1/5    &quot;&quot;&quot;    img = cv2.imread(jpeg_path)    selectivesearch.config(gs, img, strategy=&#x27;q&#x27;)    # 计算候选建议    rects = selectivesearch.get_rects(gs)    # 获取标注边界框    bndboxs = parse_xml(annotation_path)    # 标注框大小    maximum_bndbox_size = 0    for bndbox in bndboxs:        xmin, ymin, xmax, ymax = bndbox        bndbox_size = (ymax - ymin) * (xmax - xmin)        if bndbox_size &gt; maximum_bndbox_size:            maximum_bndbox_size = bndbox_size    # 获取候选建议和标注边界框的IoU    iou_list = compute_ious(rects, bndboxs)    positive_list = list()    negative_list = list()    for i in range(len(iou_list)):        xmin, ymin, xmax, ymax = rects[i]        rect_size = (ymax - ymin) * (xmax - xmin)        iou_score = iou_list[i]        if 0 &lt; iou_score &lt;= 0.3 and rect_size &gt; maximum_bndbox_size / 5.0:            # 负样本            negative_list.append(rects[i])        else:            pass    return bndboxs, negative_listif __name__ == &#x27;__main__&#x27;:    car_root_dir = &#x27;../../data/voc_car/&#x27;    classifier_root_dir = &#x27;../../data/classifier_car/&#x27;    check_dir(classifier_root_dir)    gs = selectivesearch.get_selective_search()  # 实例化,生成ｇｓ对象    for name in [&#x27;train&#x27;, &#x27;val&#x27;]:        src_root_dir = os.path.join(car_root_dir, name)        src_annotation_dir = os.path.join(src_root_dir, &#x27;Annotations&#x27;)        src_jpeg_dir = os.path.join(src_root_dir, &#x27;JPEGImages&#x27;)        dst_root_dir = os.path.join(classifier_root_dir, name)        dst_annotation_dir = os.path.join(dst_root_dir, &#x27;Annotations&#x27;)        dst_jpeg_dir = os.path.join(dst_root_dir, &#x27;JPEGImages&#x27;)        check_dir(dst_root_dir)        check_dir(dst_annotation_dir)        check_dir(dst_jpeg_dir)        total_num_positive = 0        total_num_negative = 0        samples = parse_car_csv(src_root_dir)  # 在src_root_dir目录下加载ｃｓｖ文件        # 复制csv文件        src_csv_path = os.path.join(src_root_dir, &#x27;car.csv&#x27;)        dst_csv_path = os.path.join(dst_root_dir, &#x27;car.csv&#x27;)        shutil.copyfile(src_csv_path, dst_csv_path)        for sample_name in samples:            try:                since = time.time()                src_annotation_path = os.path.join(src_annotation_dir, sample_name + &#x27;.xml&#x27;)                src_jpeg_path = os.path.join(src_jpeg_dir, sample_name + &#x27;.jpg&#x27;)                # 获取正负样本                positive_list, negative_list = parse_annotation_jpeg(src_annotation_path, src_jpeg_path, gs)                total_num_positive += len(positive_list)                total_num_negative += len(negative_list)                dst_annotation_positive_path = os.path.join(dst_annotation_dir, sample_name + &#x27;_1&#x27; + &#x27;.csv&#x27;)                dst_annotation_negative_path = os.path.join(dst_annotation_dir, sample_name + &#x27;_0&#x27; + &#x27;.csv&#x27;)                dst_jpeg_path = os.path.join(dst_jpeg_dir, sample_name + &#x27;.jpg&#x27;)                # 保存图片                shutil.copyfile(src_jpeg_path, dst_jpeg_path)                # 保存正负样本标注                np.savetxt(dst_annotation_positive_path, np.array(positive_list), fmt=&#x27;%d&#x27;, delimiter=&#x27; &#x27;)                np.savetxt(dst_annotation_negative_path, np.array(negative_list), fmt=&#x27;%d&#x27;, delimiter=&#x27; &#x27;)                time_elapsed = time.time() - since                print(&#x27;parse &#123;&#125;.png in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;.format(sample_name, time_elapsed // 60, time_elapsed % 60))            except Exception as err:                print(err)                continue        print(&#x27;%s positive num: %d&#x27; % (name, total_num_positive))        print(&#x27;%s negative num: %d&#x27; % (name, total_num_negative))    print(&#x27;done&#x27;)\n\n\n\n2.5、 &#x2F;py&#x2F;utils&#x2F;data&#x2F;create_bbox_regression_data.pyimport osimport shutilimport numpy as npimport utils.util as utilif __name__ == &#x27;__main__&#x27;:    &quot;&quot;&quot;    从voc_car/train目录中提取标注边界框坐标    从finetune_car/train目录中提取训练集正样本坐标（IoU&gt;=0.5），进一步提取IoU&gt;0.6的边界框    数据集保存在bbox_car目录下    &quot;&quot;&quot;    voc_car_train_dir = &#x27;../../data/voc_car/train&#x27;    # ground truth    gt_annotation_dir = os.path.join(voc_car_train_dir, &#x27;Annotations&#x27;)    jpeg_dir = os.path.join(voc_car_train_dir, &#x27;JPEGImages&#x27;)    classifier_car_train_dir = &#x27;../../data/finetune_car/train&#x27;    # positive    positive_annotation_dir = os.path.join(classifier_car_train_dir, &#x27;Annotations&#x27;)    dst_root_dir = &#x27;../../data/bbox_regression/&#x27;    dst_jpeg_dir = os.path.join(dst_root_dir, &#x27;JPEGImages&#x27;)    dst_bndbox_dir = os.path.join(dst_root_dir, &#x27;bndboxs&#x27;)    dst_positive_dir = os.path.join(dst_root_dir, &#x27;positive&#x27;)    util.check_dir(dst_root_dir)    util.check_dir(dst_jpeg_dir)    util.check_dir(dst_bndbox_dir)    util.check_dir(dst_positive_dir)    samples = util.parse_car_csv(voc_car_train_dir)    res_samples = list()    total_positive_num = 0    for sample_name in samples:        # 提取正样本边界框坐标（IoU&gt;=0.5）        positive_annotation_path = os.path.join(positive_annotation_dir, sample_name + &#x27;_1.csv&#x27;)        positive_bndboxes = np.loadtxt(positive_annotation_path, dtype=np.int, delimiter=&#x27; &#x27;)        # 提取标注边界框        gt_annotation_path = os.path.join(gt_annotation_dir, sample_name + &#x27;.xml&#x27;)        bndboxs = util.parse_xml(gt_annotation_path)        # 计算符合条件（IoU&gt;0.6）的候选建议        positive_list = list()        if len(positive_bndboxes.shape) == 1 and len(positive_bndboxes) != 0:            scores = util.iou(positive_bndboxes, bndboxs)            if np.max(scores) &gt; 0.6:                positive_list.append(positive_bndboxes)        elif len(positive_bndboxes.shape) == 2:            for positive_bndboxe in positive_bndboxes:                scores = util.iou(positive_bndboxe, bndboxs)                if np.max(scores) &gt; 0.6:                    positive_list.append(positive_bndboxe)        else:            pass        # 如果存在正样本边界框（IoU&gt;0.6），那么保存相应的图片以及标注边界框        if len(positive_list) &gt; 0:            # 保存图片            jpeg_path = os.path.join(jpeg_dir, sample_name + &quot;.jpg&quot;)            dst_jpeg_path = os.path.join(dst_jpeg_dir, sample_name + &quot;.jpg&quot;)            shutil.copyfile(jpeg_path, dst_jpeg_path)            # 保存标注边界框            dst_bndbox_path = os.path.join(dst_bndbox_dir, sample_name + &quot;.csv&quot;)            np.savetxt(dst_bndbox_path, bndboxs, fmt=&#x27;%s&#x27;, delimiter=&#x27; &#x27;)            # 保存正样本边界框            dst_positive_path = os.path.join(dst_positive_dir, sample_name + &quot;.csv&quot;)            np.savetxt(dst_positive_path, np.array(positive_list), fmt=&#x27;%s&#x27;, delimiter=&#x27; &#x27;)            total_positive_num += len(positive_list)            res_samples.append(sample_name)            print(&#x27;save &#123;&#125; done&#x27;.format(sample_name))        else:            print(&#x27;-------- &#123;&#125; 不符合条件&#x27;.format(sample_name))    dst_csv_path = os.path.join(dst_root_dir, &#x27;car.csv&#x27;)    np.savetxt(dst_csv_path, res_samples, fmt=&#x27;%s&#x27;, delimiter=&#x27; &#x27;)    print(&#x27;total positive num: &#123;&#125;&#x27;.format(total_positive_num))    print(&#x27;done&#x27;)\n\n"},{"title":"你当像鸟飞往你的山","url":"/2023/02/05/book_educated/","content":"在读这本书之前我对它已经有了一个预期：一个女孩，怎么摆脱恶劣的家庭环境，由无知愚昧走向自我觉醒。但是我在读的时候，发现它并不是一个单纯的励志故事，在更多地方我体会到的是家庭对一个人难以磨灭的影响，以及降低或摆脱这些影响需要付出多么艰巨的努力。与我预期的不同的是，我觉得Tara从没有放弃过她的家庭，在她受到教育之后，她依然尝试着用自己的语言、行动去唤醒家人，但是他们的宗教信仰和观念根深蒂固，她的努力不过是杯水车薪。她对家庭的执着是我觉得非常感动的地方。\n　　Tara家里最大的障碍是父亲，父亲是愚昧、偏执、疯狂，可是他也爱着自己的女儿。写父亲送女儿去机场的时候：That image of my father will always stay with me:that look on his face,of love and fear and loss.读到这里的时候我的心像被针扎了一下，父亲担心的是女儿远离自己，无法得到照顾，更怕她成为“魔鬼”，和自己的信仰相悖。而Tara在多次争斗之后，对父亲的感觉也依然是眷恋：But in this moment,I realized how much I’d been counting on that conflict coming to an end,how deeply I believed in a future in which we would be a father and daughter at peace.这个家充满暴力、愚昧和偏见，还有爱。而有些爱以病态的方式表达了出来。\n总结：每次读都有不同的感受，即使身处逆境也要去努力提升自己，即使在困难也不要放弃。\n","categories":["<知>世界"]},{"title":"小狗钱钱","url":"/2023/02/01/book_%E5%B0%8F%E7%8B%97%E9%92%B1%E9%92%B1/","content":"这是一本小孩读的书，但挺有意思的。\n小狗钱钱这本书开始吸引我的是那只会说话的白色的拉不拉多猎狗，我觉得应该很有趣。\n读完这本书后，我明白了是通过这只会说话的小狗来教小朋友应该怎样花钱和赚钱。吉娅的家庭并不富有，还欠银行很多钱。可是她并不在乎这些，每月的零花钱都会用光。后来通过钱钱的劝告和帮助，吉娅成了一个会理财的小女孩，她有了一定的储蓄还帮助爸妈还清了债务，让她的家庭更幸福了。同时她也感觉到了钱给她带来的乐趣也变得更自信了。\n总结：我也要向她学习，不乱花钱要把钱花在该花的地方，做事有计划性，目标更明确\n","categories":["<知>世界"]},{"title":"cppandc","url":"/2023/01/18/cppandc/","content":"c++ primer plus引言OPP面向对象的编程\n汇编语言可移植性差，不能跨平台\n数据和算法的区别：数据是程序使用和处理的信息，算法是程序使用的方法。\nC语言强调的是算法，C++强调的是数据，也就是通过类来对数据进行相应的操作。这也就决定了C只擅长做底层硬件的访问，而C++由于其更高级的抽象，且因C++是C的超集（所有的C程序都能在C++环境下运行），故C++可以对底层硬件进行访问，又能对上层各种数据操作的抽象类进行操作。\n类：把所有的数据、操作（方法）抽象的封装在一块。\n对类进行实例化 ，可以创建一个或多个对象。\nc++的方便之处是可以调用大厂、或者开源的公开包，里面实现了各种各样的操作。泛型编程： 泛型编程强调的是独立于特定数据类型。例如想要实现一个数据类型转换的函数，只需要写一个就行了，这样有泛型编程的思想就可以实现所有不同数据类型之间的转换。\n对象和类类实际上和结构体是比较像的，传统的结构体中是各种数据类型类是既有数据又有函数（数据操作的方法）的。 类是一种将抽象转换为用户定义类型的C++工具，它将数据表示和操纵数据的方法组合称一个整洁的包。\nc++ primers第一章初始输入输出：c++语言并未定义任何输入输出语句，取而代之，包含了一个全面的标准库（standard library）来提供IO机制（以及很多其他设备）。书中很多例子用iostream库，术语“流”想要表达的是，随着时间的推移，字符是顺序生成或消耗的。标准输入输出对象：标准库定义了四个IO对象，分别是 cin(发音see-in) 、cout、cerr、clogfor循环和while 循环（迭代）的优缺点： 一般确定循环次数的情况下，倾向于用for循环；当不确定循环次数，但知道循环条件时，倾向于用while循环。类  ：   int a，其中int 相当于 类，a相当于对象 \n第二章cpu擅长逻辑运算而不擅长逻辑运算float 和double都是浮点类型且二者 占用的资源是差不多的一般情况下，更推荐用double数值在计算机中存储都是以补码的形式。源码：最高位表示符号位：1表示负数，0表示正数。反码：除了符号位，其余位全部取反。补码：为反码加一有符号类型和无符号类型运算时会将有符号的转换为无符号类型。指针本身是一个对象，它又可以指向另外一个对象。因此，指针本身是不是常量以及指针所指的对象是不是常量就是两个相互独立的问题。用 顶层const 表示指针本身是个常量，  用底层const表示指针所指的对象是一个常量。常量指针p1 ,指针常量 p2\nint i &#x3D; 0;int *const p1 &#x3D; &amp;i;  &#x2F;&#x2F;这里p1是一个顶层const ,不能改变p1的值const int c1 &#x3D;42;const int *p2 &#x3D; &amp;c1;&#x2F;&#x2F; p2是一个底层const， 允许改变p2的值。\n字面值常量 :每个字面值常量都对应一种数据类型，字面值常量的形式和值决定了它的数据类型。 指定字面值的类型字符和字符串字面值:\n\n\n\n前缀\n含义\n类型\n\n\n\nu\nUnicode 16 字符\nchar16_t\n\n\nU\nUnicode 32 字符\nchar32_t\n\n\nL\n宽字符\nwchar_t\n\n\nu8\nUTF-8(仅用于字符串字面常量)\nchar\n\n\n整形字面值：\n\n\n\n后缀\n最小匹配类型\n\n\n\nu or U\nunsigned\n\n\nl or L\nlong\n\n\nll or LL\nlong long\n\n\n浮点型字面值：\n\n\n\n后缀\n类型\n\n\n\nf or F\nfloat\n\n\nl or L\nlong float\n\n\n** 变量**变量提供一个具名的、可供程序员操作的存储空间。对C++程序员来说变量和对象一般可以互换使用。通常情况下对象指的是一块能存储数据并具有某种数据类型的内存空间。初始化并不是赋值，初始化的含义是创建变量时赋予其一个初始值，而赋值的含义是把对象的当前值擦除，而以一个新值来替代。@@@@建议初始化每一个内置类型的变量。C++是一种静态类型语言，其含义是在编译阶段检查类型。对象的类型决定对象所能参与的计算过程。引用必须初始化。引用和const一样在定义的时候就要初始化，且不支持二次修改。引用的初始值必须是一个对象，而不能是一个数字或者字符。指针实现了对其它对象的间接访问。指针与引用的不同：1、指针本身就是一个对象，允许对指针赋值和拷贝，而且在指针的生命周期内它可以先后指向几个不同的对象。2、指针无须在定义时赋初值。和其他内置类型一样，在块作用域内定义的指针如果没有被初始化，也将拥有一个不确定的值。为p赋值实际上是为p所指的对象赋值。  若指针p指向一个对象，则允许使用解引用符（）来访问该对象，p存放的是对象地址，*p存放的是对象。引用本身并非一个对象。一旦定义了引用，就无法令其绑定到另一个对象。\n顶层const和底层const ：顶层const 表示指针本身是一个常量，而底层const表示指针所指的对象是一个常量。常量表达式：指不会改变并且在编译过程就能得到计算结果的表达式。constexper变量 ：在一个复杂系统中，很难分辨一个初始值到底是不是常量表达式，constexper 变量可以认为设定初始值是常量表达式，当编译时发现其不是常量表达式会报错。若用const 则不会报错。auto 和 decltype类型指示符的区别：decltype可以从表达式的类型推断出要定义的类型，但是不用表达式的值初始化变量。编译器分析表达式的类型，却不实际计算表达式的值。decltype（*p） c; c的类型是引用。若想定义一个指针用  decltype(p) c;如果给变量加上一层或多层括号，编译器就会把他当成表达式。\n","categories":["编程"],"tags":["c++ primer"]},{"title":"datastruct","url":"/2023/04/01/datastruct/","content":" 数据结构与算法\n\n\n\n概述从线性非线性分类：  线性（线性表、栈、队列）    树\n从存储形式分类：顺序存储（arr[]）、链式存储(*p)\n线性表1.顺序存储线性表  arr[]\n2.链式存储线性表\n单向链表\n单向循环链表\n单向不循环链表\n\n\n双向链表\n双向循环链表\n双向不循环链表\n\n\n\n单向链表双向链表栈和队列的应用","categories":["编程"],"tags":["Linux","数据结构"]},{"title":"通过master和source分支管理博客网站","url":"/2023/04/15/git2originofsource/","content":"这里主要介绍一下通过master 和source 两个分支来管理自己的博客。 \n分支有 master   \n和    source  （默认）\nmaster 分支用来存放个人的博客部署文件  ，source用来存放个人的博客源文件\n对于master 分支的  上传及更新 请参考另外一篇 博客 ，这里主要说一下关于source分支的设置过程。\n3、 git remote add origin https://github.com/bigflya/bigflya.github.io.git\n\n若报错如上 执行       git remote rm origin\n4、git add .\n5、 git commit -m ‘hexo source files’\n6、 git push origin source\n\ngit branch -m source\n若报错如下图可执行步骤7\n\n7、获取token  并绑定此仓库\n之后用自己生成的token登录，把上面生成的token粘贴到输入密码的位置，然后成功push代码！\n也可以 把token直接添加远程仓库链接中，这样就可以避免同一个仓库每次提交代码都要输入token了：\ngit remote set-url origin https:&#x2F;&#x2F;@github.com&#x2F;&#x2F;.git\n：换成你自己得到的token：是你自己github的用户名：是你的仓库名称\ntoken 的获取可以点击传送门参考我的另一篇文章。\ngit remote set-url origin https://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@github.com/bigflya/bigflya.github.io.git\n8、上传source 分支       git push origin source\n这里如果报错直接强行上传命令如下：\n git push origin +source\n拉取 远程源文件 流程 \n  git clone https://github.com/bigflya/bigflya.github.io\n每次提交流程\n二、提交代码\n1、git add .（添加文件到暂存区）2、git commit -m “提交描述信息”（提交暂存区到本地仓库）3、git push origin source（上传远程代码并合并\n参考\n(19条消息) Git时出现“error: 源引用表达式 main 没有匹配 error: 推送一些引用到 ‘https://github.com/***.git‘ 失败”的错误提示_源引用规格 main 没有匹配_songyuc的博客-CSDN博客\n使用git分支保存hexo博客源码到github | 小冰的个人博客 (yangbing.club)\n[(19条消息) git问题error: remote origin already exists._myydan的博客-CSDN博客](https://blog.csdn.net/myydan/article/details/129259615?ops_request_misc=%7B%22request%5Fid%22%3A%22168061482516800192217379%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=168061482516800192217379&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-2-129259615-null-null.142^v81^insert_down1,201^v4^add_ask,239^v2^insert_chatgpt&amp;utm_term=error%3A 远程 origin 已经存在。&amp;spm&#x3D;1018.2226.3001.4187)\n(19条消息) Git时出现“error: 源引用表达式 main 没有匹配 error: 推送一些引用到 ‘https://github.com/***.git‘ 失败”的错误提示_源引用规格 main 没有匹配_songyuc的博客-CSDN博客\n","tags":["git"]},{"title":"gitlocal2online","url":"/2023/03/19/gitlocal2online/","content":"介绍一下git仓库的代码管理功能一、首先去github创建一个仓库\n\n注意在新建仓库时 请不要在创建Initialize this repository with a README前打勾，Add .gitignore和Add a license处请选择None。\n二、本地相关设置\n我这里建立一个rcnn文件夹 并在里面放了一个test文件  在此文件夹下打开终端，运行\n$ git init  \n\n此时，我们仅作了一个初始化的操作，你的项目文件还未被跟踪。\n\n\n通过git add 来实现对指定文件的跟踪，然后执行git commit提交:\n$ git add .$ git commit -m &quot;initial commit&quot;\n\n设置 username 和 email\n$ git config --global user.name &quot;your name&quot;$ git config --global user.email &quot;your_email@youremail.com&quot;\n\n\n\n\n\n\n\n首先在本地创建 ssh key：           ssh-keygen -t rsa -C “&#121;&#x6f;&#x75;&#114;&#95;&#101;&#109;&#97;&#x69;&#x6c;&#x40;&#x79;&#x6f;&#117;&#114;&#101;&#109;&#97;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;“\n会在home&#x2F;用户名&#x2F;.ssh文件夹下生成如下文件， 需要输入三个  回车 \n\n回到之前我们创建GitHub仓库完成的页面，复制远程仓库链接，在终端输入:\n$ git remote add origin &lt;远程仓库链接&gt;\n\n\n\n你可以通过git remote -v来验证你的链接是否正确。\n验证完毕，确认准确无误后，用以下指令推送本地仓库内容至GitHub\n第一次使用git时$ git push -u origin master\n此时还会提示要 .ssh文件夹缺少一个文件,输入yes即可 自动生成相关的文件\n第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。\n之后使用git 时候  就直接  用   $ git push origin master\n最终的效果就是下面这张图\n\n","tags":["学习经验"]},{"title":"linux学习经验","url":"/2023/02/28/linux%E4%BF%AE%E7%82%BC%E6%89%8B%E5%86%8C/","content":"\n\n\n\n\nC语言基础linux编程预科：编译器：gcc，make\n\nc编译过程编译过程: 流程：源文件–1预处理–3编译–4汇编–5链接–可执行文件（.c –&gt;  .out）\n1.   预处理:  gcc -E hello.c\n\n保存预处理文件  gcc -E hello.c &gt; hello.i\n\n编译：   gcc -S hello.i\n\n汇编：  gcc -c hello.s\n\n链接并指定生成文件为hello： gcc hello.o -o hell\n\n对上面过程进行包装：  gcc hello.c  即可在当前目录生成可执行文件,也可以用make 进行编译  make hello (make操作不用带后缀)\n\n\n测试编译后的文件 ：  .&#x2F;hello\n\nvim 编辑器的使用技巧：运行 vim  &#x2F;etc&#x2F;vimrc    对vim编辑器进行修改建议  cp &#x2F;etc&#x2F;vimrc ~&#x2F;.vimrc   复制一份在自己的家目录，这样 这个vim只对当前用户有效，而不会修改所有用户的vim\n 想查看 函数原型 直接在vim 中光标放在函数上 按shift+k\n\ngcc编译器的使用技巧：gcc hello.c -Wall 编译并打印所有警告\necho $? 打印上一行命令的输出状态\n\nshell的使用技巧：ls -l  可以用  ll  代替\n编程的基本要求：\n头文件要正确包含\n以函数为单位进行程序的编写\n声明部分+实现部分\nreturn 0;\n空格、注释、对齐的中要求\n算法：解决问题的方法（用流程图、ns图、有限状态机FSM进行算法逻辑设计）\n\nc语言：（TYPE NAME &#x3D;VALUE）c语言注释技巧：直接在 通过预编译跳过的形式注释：\n#if 0func()&#123;            &#125;#endif\n\n\n\n代码块注释：\n/* * * * 这样也可以*/\n\n基本数据类型：记住整型int 是占一个机器字长就可以，在32位机器上int 是32位的，其余的 双精度 单精度 的字长都是以int 为基础进行放缩的，例如 在32位机器上double 占64位、float 占32位、short 是16、char占8位。\n不能抛开是多少位机器，谈论 不同数据类型所占 位数长度，\n有符号和无符号只是 表示的数值范围不同，二者所占的字节数是一样的。\n变量的类型及生命周期和作用范围：auto  默认，会随机给初值 （分配空间），自动收回空间\nregister   （建议型）寄存器类型，只能定义局部变量\nstatic   静态型 禁止函数的外部拓展，初值位0，或空\nextern  说明性，不能改变被说明的变量的值或类型\n逻辑运算符:这部分比较简单随用随查\n输入输出（I&#x2F;O）:\n格式化输入输出函数： scanf 、printf\nint printf(const char *format, …)\nformat: “%[修饰符] 格式字符”，动态实参\n变参 、和定参的区分方法\n小知识：printf也是有返回值的\nprintf(&quot;[%s:%d]before while().\\n&quot;,__FUNCTION__,__LINE__);//可以打印此句话所在的函数和行号function()printf(&quot;[%s:%d]after while().\\n&quot;,__FUNCTION__,__LINE__);//可以打印此句话所在的函数和行号\n\nformat: 抑制符 * \n%s 的使用是比较危险的，因为不知道存储空间的大小 \nscanf 放在循环结构中要注意能否接收到正常的有效内容\n\n字符输入输出函数：getchar、putchar\n\n字符串输入输出函数：gets(!)、puts\n\n\n​\t  gets 是十分危险的函数，可以用 fgets 或者getline来代替\n流程控制（三大结构 –顺序、选择、循环）：选择： if-else switch-case\n  小知识：   else 只与离他最近的if相嵌套\n​                     case 中只能放常量或常量表达式 \n​\t\t\t\t\t \n循环： while    do-while for  if-goto\n​        while 和do while 的区别，要了解到do -while 可以多执行一次 \n​\t\tif-goto(慎用，goto实现的是无条件跳转，且不能跨越函数跳转)\n辅助控制： continue       break  \n  break 跳出本层循环 ，continue 跳出本次循环\n数组数组的特点 ：在内存中连续存放\n数组名本身就是表示地址的常量 所以调用数组的时候不用在 数组名前面写取地址符号。\n一维数组：\n 初始化 ： 部分初始化  全部初始化  不初始化  static  \n数组名：  是表示地址的常量，也是数组的起始位置，\n数组越界：只能靠程序员的经验来检查，IED不会报错，因为越界是通过指针偏移来找对应的内存地址的，即使那一块不属于数组的范围，但内存中只要存在 就不会报错。\n排序方法： 冒泡法 、选择法、快速排序法\n删除法求质数\n二维数组：\n二维数组行号可以省略\n字符数组：\n  数组是不能直接复制的 ，用strcpy()来 赋值，还可以用strncpy()来拷贝给字符数组相应的值，可以防止越界现象。\nstring.h的头文件里面还有好多函数可以可以设置类似的strncat  strcat   strcmp  strncmp等  ，其中strcmp比较的是相应位置的ascii码\nsizeof(str)算末尾的&#x2F;0  ，strlen(str)不算末尾的&#x2F;0\nprintf(“%s—&gt;%d\\n”，__ FUNCTION__ ,sizeof(a)) 这句话中 __ FUNCTION__会打印当前行所在函数名。\n指针已知：  int  *p&#x3D;a              （其中a为一维数组）  可以推出下面的两行结论\na[i]&#x3D;*(a+i)&#x3D; * (p+i)&#x3D;p[i]\n&amp;a[i]&#x3D;a+i  &#x3D;p+i&#x3D;&amp;p[i]                                   注意数组名存放的是数组的起始地址(见解：我个人理解数组本身也是一个指针)\n指针可以节省传参的资源开销\n一个指针变量在内存中占4个字节（32位机器），若是64位机器则占8个字节。\n变量与地址： \n指针与指针变量：  \n直接访问与间接访问：\n空指针与野指针：  \n空类型：void  ，不太确定指针的类型的时候就用void 类型\n指针运算：  *   &amp;   比较地址\n指针与数组：  涉及到指针与数组的一些相关知识，\nconst与指针：\n\n   常量指针：  \n​             定义： 又叫 常指针，通俗理解 就是这是个指针但是这个指针指向常量。这个常量是指指针的值（地址），而不是地址指向的值。  形式 int const* p  ; const int* p\n​            关键点：常量指针指向的对象不能通过这个指针来修改，但仍然可以通过原来的定义来修改。（错误示范  *p &#x3D;10），函数传入参数如果不希望被误改 可以指定传入参数为常量指针\n​                          常量指针可以被赋值为变量的地址，之所以叫常量指针，是为了限制通过这个指针修改变量。\n​                         指针还可以指向别处，因为指针本身是个变量，可以指向任意地址\n\n  指针常量：\n​                定义 ： 本质是个常量，而用指针修饰它。指针常量的值是指针，因为这个值是常量，所以不能被赋值。 形式  int const* p; const int* p;\n​           关键点：\n​                      指针常量是  一个   常量\n​                     指针所保存的地址可以改变，然而指针所指的值却不可以改变\n​                     指针本身是常量，指向的地址不可以改变即p 不能改变。但是指向的地址所对应的内容可以变化。即 *P可以发生改变。（错误示范  p &#x3D;&amp;t）\n\n指针数组与数组指针：\n// 指针数组 ：#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void print_arr(int p[],int n)&#123;        int i;        printf(&quot;%s:%d\\n&quot;,__FUNCTION__,sizeof(p));        for(i = 0; i&lt;n; i++)                printf(&quot;%d&quot;,*(p+i));        printf(&quot;\\n&quot;);&#125;int main()&#123;        int a[] = &#123;1,3,5,7,9&#125;;        printf(&quot;%s:%d\\n&quot;,__FUNCTION__,sizeof(a));        print_arr(a,sizeof(a)/sizeof(*a));&#125;\n\n​               int  * arr[3]\n​\t数组指针：\n​          int(*p)[3]\n多级指针：\n函数#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;//定义一个函数int main(int argc,char *argv[])&#123;    int i;    printf(&quot;argc = %d\\n&quot;,argc);    for(i =0;i&lt;argc; i++)        puts(argv[i]);    return 0;&#125;\n\n函数传参:\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void swap(int *p, int *q)&#123;        int tmp;    tmp = *p;    *p = *q;    *q = tmp;    &#125;int main()&#123;\tint i = 3,j = 5;    int tmp;    swap(&amp;i,&amp;j);    printf(&quot;i=%d\\nj = %d\\n&quot;,i,j);        &#125;\n\n值传递：\n地址传递：  比较重要 ，核心理解 点就是  ，指针的内涵\n全局变量：\n函数的调用（递归和嵌套）：\n递归是嵌套的一个特例 \n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int max(int a,int b,int c)&#123;    int tmp;    tmp = a&gt;b?a:b;    return tmp&gt;c?tmp:c;        &#125;int min(int a,int b,int c)&#123;    int tmp;    tmp = a&lt;b?a:b;    return tmp&lt;c?tmp:c;    &#125;int dist(int a,int b,int c)&#123;        return max(a,b,c)-min(a,b,c);&#125;int main()&#123;    int a = 3,b = 5,c = 10;    int res;    res = dist(a,b,c);    printf(&quot;res = %d\\n&quot;,res);    return 0;        &#125;\n\n\n\n函数与一维数组：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;//以前的做法int main()&#123;\t    int i;    int a[] = &#123;1,3,5,7,9&#125;;    for(i=0;i&lt;sizeof(a)/sizeof(*a);i++)        printf(&quot;%d\\n&quot;,a[i]);    exit(0);        &#125;\n\n\n小知识：不同位数操作系统下不同的变量类型所占字节数如下，指针是随操作系统位数变的，而int 还有其他类型基本不咋变化。\n\n\n\nc类型\n32\n64\n\n\n\nchar\n1\n1\n\n\nshort int\n2\n2\n\n\nint\n4\n4\n\n\nlong int\n4\n8\n\n\nlong long int\n8\n8\n\n\nchar*\n4\n8\n\n\nfloat\n4\n4\n\n\ndouble\n8\n8\n\n\n\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;//现在的做法int print_arr(int *a)//这里并不知道指针a 的大小，即不知道指针能访问的空间大小，要想精确访问需要再传进来一个参数  int n ,然后利用 for 循环来准确访问a中所有的值 ，也可以将 int *a写成 int p[], 在形参中一个[]相当于 一个*  例如  char **argv   就等价于char *argv[]&#123;    int i;    i = sizeof(a);    printf(&quot;%d&quot;,i);//形参a 作为一个指针 占8个字节，因为系统是64位所以是8若是32位则是4&#125;int main()&#123;    int a[] = &#123;1,3,5,7,9&#125;;//32位系统一个int占4个字节    printf(&quot;%ld\\n&quot;,sizeof(a));//4x5 =20    print_arr(a);    exit(0);&#125;//运行结果  // 20 8\n\n\n\n一维数组，传参时的实参与形参对应表实参: a\t*a\ta[0]\t&amp;a[3]\tp[i]\tp\t*p\tp+1形参：int*\tint\tint\t\tint*\tint\t\tint*\tint\t\tint*\n\n\n\n函数与二维数组：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define M 3#define N 4void print_arr(int *p,int n)//这种方法相当于把二维数组当成一维数组来处理注意第一个形参类型，思考为什么可以这样&#123;\t\t    \tint i;\t    for(i = 0;i&lt;n;i++)        &#123;            printf(&quot;%d&quot;,p[i]);                    &#125;        \tprintf(&quot;\\n&quot;);&#125;int main()&#123;\tint a[M][N]=&#123;1,2,3,4,5,6,7,8,9,10,11,12&#125;;\tprint_arr(&amp;a[0][0],M*N); // *a  a[0]  *(a+0)  这几种是等价的都是相当于把行指针转换为列指针    \texit(0);&#125;\n\n/*//上面代码的第二种实现方式*/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define M 3#define N 4void print_arr1(int (*p)[N],int m ,int n)//第一个形参的本质其实是一个数组指针所以可以这样写  也可以写成 int p[][N]&#123;\t\t    \tint i,j;\t    for(i = 0;i&lt;m;i++)        &#123;            for(j=0;j&lt;n;j++)                printf(&quot;%4d&quot;,p[i][j]);//或者*(*(p+i)+j)            printf(&quot;\\n&quot;);                                &#125;        \t&#125;int main()&#123;\tint a[M][N]=&#123;1,2,3,4,5,6,7,8,9,10,11,12&#125;;\tprint_arr1(a,M,N);    \texit(0);&#125;\n\n\n\n二维数组，传参时的实参与形参对应表,核心就是判断是不是行指针 或者列指针/*p[i]相当于一级指针中的某个元素，p是指向一行的，相当于一个一维数组p[i]就是一维数组里面的元素*/int a[M][N]=&#123;......&#125;;int *p=*a;int (*q)[N]=a;实参: a[i][j]\t\t*(a+i)+j\ta[i]+j\tp[i]\t*p\t     q[i][j]\t  *q\t\t\tq\t  p+3\t q+1形参：int\t \t\tint *\t\tint *\tint\t\tint\t     int\t   int*  \tint (*)[N]    int *\t\tint(*)[N]\n\n\n\n二维数组名相当于是一个行指针\n二维数组相当于 一个 数组指针   int (*p)[N]  ，在写小函数形参的时候要写成这样\n指针函数： 返回值 如 int * fun(int)\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define M 3#define N 4int *find_num(int (*p)[N] ,int num)&#123;    if(num&gt;M-1)        return NULL;        return *(p+num);&#125;int main()&#123;    int i,j;    int a[M][N]=&#123;1,2,3,4,5,6,7,8,9,10,11,12&#125;;    int *res;    int num =0;    res = find_num(a,num);    if(res !=NULL)    &#123;        for(i=0;i&lt;N;i++)            printf(&quot;%d&quot;,res[i]);        printf(&quot;\\n&quot;);    &#125;    else    &#123;         printf(&quot;error! can not find\\n&quot;);    &#125;&#125;\n\n函数指针：  类型 如  int(*p)(int);\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int add(int a ,int b)&#123;        return a+b;&#125;int main()&#123;    int a=3,b=4;    int ret;    int (*p)(int,int);    p= add;    ret = p(a,b);    printf(&quot;%d\\n&quot;,ret);    &#125;\n\n函数指针数组：\n         类型 如  int (*arr[N])(int);\n\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int add(int a ,int b)&#123;        return a+b;&#125;int main()&#123;    int a=3,b=4,i;    int ret;    int (*funcp[2])(int,int);    funcp[0] = add;    //funcp[1] = sub?    for(i= 0;i&lt;1;i++)    &#123;        ret=funcp[i](a,b);         printf(&quot;%d\\n&quot;,ret);    &#125;           &#125;\n\n\n\n指向指针函数的函数指针数组：\n​\t形式  int *(*funcp[N])(int)\n\n构造类型：结构体\n产生及意义：把不同类型的数据，存放在连续的空间\n\n描述：   struct  结构体名\n​\t\t\t\t{\n​\t\t\t\t\t\t数据类型\t成员1；\n​\t\t\t\t\t\t数据类型\t成员2；\n​\t\t\t\t\t\t…………\n​\t\t\t\t};\n\n嵌套定义:\n​\t\t\n嵌套的结构体可以直接完整的嵌入内部，也可以在外面单独定义这个嵌套的小结构体，但要注意嵌套在内部要在结构体后面写上成员，嵌在里面的小结构体只是相当于一个 数据类型 。\n\n\n\n定义变量（变量、数组、指针），初始化及成员引用\n​\t\t\t\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define NAMESIZE\t32struct simp_st&#123;    int i;    float f;    char ch;&#125;;int main()&#123;    //TYPE NAME = VALUE    struct simp_st a=&#123;123,456.789,&#x27;w&#x27;&#125;;//结构体初始化。  TYPE 是struct simp_st    //对指定成员赋值 struct simp_st a=&#123;.i=147,.ch=&#x27;s&#x27;&#125;;    //指定成员赋值方法2 struct simp_st *p = &amp;a;  //引用方法 p-&gt;i  ,p-&gt;ch 等    //指定成员赋值方法3  struct simp_st arr[2]&#123;&#123;123,123.123,&#x27;c&#x27;&#125;,&#123;456,456.456,&#x27;b&#x27;&#125;&#125;   //使用方法p =&amp;arr[0];   for(;;i++,p++)注意p是结构体所以p++每次跳一个结构体大小，若p是整形p++一次跳4个字节，p是double则p跳 diuble类型所占字节数    a.i=2358784886;    printf(&quot;%d--%f--%c&quot;,a.i,a.f,a.ch);    exit(0);    &#125;\n\n\n\n结构体的对齐原则参考资料：从存储原理的角度来看这就是牺牲空间的原则来减少时间的消耗，具体就是跳过了其中一些空间来减少时间的消耗，结构体的总大小为其成员中所含最大类型的整数倍。 在一些网络传输过程中，要注意 对齐方式可能不一样。这时候就需要设置不对齐方法如下。\nstruct a&#123;    int i;    char ch;    float f;&#125;__attribute__((packed));\n\n\n\n函数传参： 方式（值，地址）  。值传参是临时深拷贝，开销非常大。通常会使用指针传参 开销比较小，只有一个指针大小的开销，比如32位操作系统开销是4个字节，64位操作系统是8个字节\n\n无头结构体：只能在声明的时候把变量定义好。\n​\t\t\t\t\n\n微型学生管理系统：\n​\t\t\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include&lt;string.h&gt;#include &lt;unistd.h&gt;#define NAMESIZE\t32struct student_st&#123;    int id;    char name[NAMESIZE];    int math;    int chinese;&#125;;void stu_set(struct student_st *p,const struct student_st *q)&#123;    //可以 p-&gt;id = q-&gt;id;    *p = *q;&#125;void stu_show(struct student_st *p)&#123;    printf(&quot;%d %s %d %d\\n&quot;,p-&gt;id,p-&gt;name,p-&gt;math,p-&gt;chinese);    &#125;void stu_changename(struct student_st *p,const char *newname)&#123;    //错误示范    p-&gt;name = newname   ,左边是常量。指针是变量但是指针所指的内容是常量，是不能直接这样赋值的。    strcpy(p-&gt;name,newname);    &#125;void menu(void)&#123;    printf(&quot;\\n1 set\\n2 change name\\n3 show\\n&quot;);    printf(&quot;Please enter the num of you want to choice(q for quit):\\n&quot;);&#125;int main()&#123;    struct student_st stu,tmp;    char newname[NAMESIZE];    int choice;    int ret;    do&#123;        menu();        ret = scanf(&quot;%d&quot;,&amp;choice);//按理来说每个scanf和printf都有可能出错，要进行校验，要设置出错推出选项        if(ret !=1)            break;        switch(choice)            &#123;                case 1:                    printf(&quot;Please enter for the stu[id name math math chinese]:\\n&quot;);                    scanf(&quot;%d%s%d%d&quot;,&amp;tmp.id,tmp.name,&amp;tmp.math,&amp;tmp.chinese);                    stu_set(&amp;stu,&amp;tmp);                    break;                case 2:                    printf(&quot;Please enter the new name: &quot;);                    scanf(&quot;%s&quot;,newname);                    stu_changename(&amp;stu,newname);                    break;                case 3:                    stu_show(&amp;stu);                \tbreak;                default:                    exit(1);            &#125;        \tsleep(1);//#include &lt;unistd.h&gt;                            \t&#125;while(1);        exit(0);&#125;\n\n共用体：\n产生及意义：相当于结构体中的成员有多个，但同时只能一种情况存在。多个成员公用一块空间，当在使用其中一个成员时，其他成员是不生效的。这点可以从内存占用反应出来。\n\n类型描述：\n​\t \nunion 共用体名&#123;    数据类型 成员名1；    数据类型 成员名2；        .......&#125;;\n\n\n\n嵌套定义： 与结构体差不多，且共用体可以嵌套结构体，结构体也能嵌套共用体\n\n定义变量（变量、指针、数组），初始化及成员引用：\n\n成员引用：   第一种  变量名.成员名      第二种   指针名-&gt;成员名\n\n\n占用内存大小：  公用体的大小是根据它里面最大的那个成员 来分配的。\n\n函数传参（值、地址）：  记住一点 地址传参开销小。\n\n实现高四位加上低四位的例子:\n\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdint.h&gt;//方法一：传统方法依靠位运算int main()&#123;\tuint32_t i = 0x11223344;\tprintf(&quot;%x\\n&quot;,(i&gt;&gt;16)+i&amp;0xFFFF);&#125;/*//方法二：共用体和结构体嵌套union&#123;\tstruct\t&#123;\t\tuint16_t i;//占两个字节\t\tuint16_t j;//占两个字节\t&#125;x;//占四个字节\tuint32_t y;//占四个字节&#125;a;//占四个字节int main()&#123;a.y = 0x11223344;printf(&quot;%x\\n&quot;,a.x.i+a.x.j);&#125;*/\n\n位域： 没有实际开发使用的意义 ，但也是一个知识点。存放变量不是以字节为单位而是以位为单位。\n​\t\t\t\t\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;union&#123;\tstruct\t&#123;\t\tchar a:1;//占一个位\t\tchar b:2;\t\tchar c:1;\t&#125;x;//总共占4位\tchar y;//8位&#125;w;//总共占8位int main()&#123;\t&#125;\n\n\n大端和小端的概念：大端指数据存储时，数据的高位保存在低地址中，数据的低位保存在高地址中。  常用的x86体系结构，多数都是小端  。c51是非常典型的大端。很多arm  和dsp都是小端结构。\n\n​\n\n\n\t\n枚举：\n相对比较简单，这里用一个例子说明,把枚举当宏来使用，方便查错，预处理之后报错 报的是名，而不是宏的值： 1 2 3。但是它不能当成函数传参来使用，而宏可以。\n#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;enum&#123;    STATE_RUNNING = 1,    STATE_CANCELED,//默认是2    STATE_OVER //最后一句不需要逗号，这里默认是3    &#125;；struct job_st&#123;    int id;    int state;    time_t start ,end;&#125;;int main()&#123;    struct job_st job1;    /*获取任务状态*/    switch(job1.state)    &#123;        case STATE_OVER:            break;\t        case STATE_CANCELED:            break;        case STATE_OVER:            break;        default:            abort();    &#125;    &#125;\n\n动态内存管理：\n几个相关函数：\n\nmalloc     void *malloc(size_t size);  申请指定大小的内存空间\ncalloc          \nrealloc(已经用了一部分内存，想再申请一部分，若用掉的部分内存后面的位置被占用了，则找一大块相应的连续内存 将此任务已经用掉的部分内存内容剪切过去，相当于重新分配了一块连续的大内存)\nfree  void free(void *ptr)  释放内存  ，free之后把指针设置为空指针 ，这样可以避免野指针的出现\n\n\n原则：谁申请谁释放\n重构学生管理系统的例子：(主要对名字的最大占用空间做了改变)\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include&lt;string.h&gt;#include &lt;unistd.h&gt;#define NAMEMAX\t1024struct student_st&#123;    int id;    char *name;    int math;    int chinese;&#125;;void stu_set(struct student_st *p,const struct student_st *q)&#123;    p-&gt;id = q-&gt;id;    p-&gt;name = malloc(strlen(q-&gt;name)+1);//加1是预留一个尾0    if(p-&gt;name ==NULL)        exit(1);    strcpy(p-&gt;name, q-&gt;name);    p-&gt;math = q-&gt;math;    p-&gt;chinese = q-&gt;chinese;&#125;void stu_show(struct student_st *p)&#123;    printf(&quot;%d %s %d %d\\n&quot;,p-&gt;id,p-&gt;name,p-&gt;math,p-&gt;chinese);    &#125;void stu_changename(struct student_st *p,const char *newname)&#123;    free(p-&gt;name);    p-&gt;name = malloc(strlen(newname)+1);    strcpy(p-&gt;name,newname);    &#125;void menu(void)&#123;    printf(&quot;\\n1 set\\n2 change name\\n3 show\\n&quot;);    printf(&quot;Please enter the num of you want to choice(q for quit):\\n&quot;);&#125;int main()&#123;    struct student_st stu,tmp;    char newname[NAMEMAX];    int choice;    int ret;    do&#123;        menu();        ret = scanf(&quot;%d&quot;,&amp;choice);//按理来说每个scanf和printf都有可能出错，要进行校验，要设置出错推出选项        if(ret !=1)            break;        switch(choice)            &#123;                case 1:                \ttmp.name = malloc(NAMEMAX);                    printf(&quot;Please enter for the stu[id name math math chinese]:\\n&quot;);                    scanf(&quot;%d%s%d%d&quot;,&amp;tmp.id,tmp.name,&amp;tmp.math,&amp;tmp.chinese);                    stu_set(&amp;stu,&amp;tmp);                \tfree(tmp.name);//释放掉临时名存放的空间，做到谁申请谁释放                    break;                case 2:                    printf(&quot;Please enter the new name: &quot;);                    scanf(&quot;%s&quot;,newname);                    stu_changename(&amp;stu,newname);                    break;                case 3:                    stu_show(&amp;stu);                \tbreak;                default:                    exit(1);            &#125;        \tsleep(1);//#include &lt;unistd.h&gt;                            \t&#125;while(1);        exit(0);&#125;\n\n\n补充知识：\n一个典型的typedef:\n\n类型：   typedef  已有的数据类型  新名字：\n\n作用：1、为已有的数据类型改名，  2、对数据类型做重定义 这样就可以在程序从32位机器 转到64位机器上运行时可以快速对数据类型进行修改\n#define IP int *IP p,q;-----&gt; int *p,q;typedef int *IP;IP p,q;------&gt;int *p,*q;typedefy int ARR[6];  //本质是 int [6]-&gt;ARRARR a;------&gt;int a[6]struct node_st&#123;\tint i;\tfloat f;&#125;;typedef struct node_st  NODE;NODE a;--------&gt; struct node_st a;typedef struct node_st *NODEP;NODEP p;----&gt;struct node_st *p;//还可以简单点typedef struct&#123;\tint i;\tfloat f;&#125;NODE,*NODEP; //直接对无名的结构体改名 既可改成NODE ,也可改成 *NODEPtypedef int FUNC(int);FUNC f;----&gt;int f(int);//  int *(*p)(int); 指向函数指针的指针函数\n\n\nmakefile工程文件\n\nmake定义：  make是一个集成的工程管理器，\n\nmakefile定义：  make执行的一个脚本，程序员一般写一个大写的MAKEFILE 在里面对编译过程进行说明，\n\n.h文件不参与编译 ，makefile中写的是依赖关系\n\n\n\n\n数据结构​    \n","categories":["编程"],"tags":["学习经验"]},{"title":"main传参的两种形式","url":"/2023/11/03/main%E4%BC%A0%E5%8F%82%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%BD%A2%E5%BC%8F/","content":"c语言中main函数传参有两种形式，分别如下所示：\n\n第一种：\n\nmain(int argc, char *argv[])\n\n\n第二种：\n\nmain(int argc, char **argv)\n\n这两种传参方式有什么区别呢？刚开始对二级指针不太熟悉的时候，笔者不太理解第二种方法，但常见的编码风格使用第二种情况是比较多，且当了解这两种传参方式之后会发现第二种传参方式有很多优点。但对初学者属实有点不知所云。笔者根据自己的理解来阐述一下这两者的区别：\n区别如下：\n\n第一种argv是一个char类型的指针数组\n第二种argv是一个指向char类型指针的指针\n\n这两种都能通过argv[i]拿到第(i)个值，这一点对于第一种char *argv[]不难理解，因为原型就是一个字符指针数组，本质就是数组，所以可以通过下标来访问；第二种char * *argv，这种为什么可以通过argv[i]来访问第(i)个值？可以这样理解：例如想要访问第一个元素可以用 *argv +0  即先拿到 **argv 的起始地址，然后再加上偏移地址。使用argv[0]的原理与上面的类似就相当于是argv是数组起始地址，下标[0]表示偏移地址。\n\n总结：\n\n看到第二种方式不由的让我想起二级指针传参相较于一级指针传参的优点，其次是第二种方式在为arcv分配内存的时候可以分配不连续的内存空间，而第一种是数组本身就要求要分配连续的内存空间，但我个人认为内存分配是操作系统做的事情，分配的也不是实际物理意义上的连续内存空间，而是操作系统虚拟出来的内存映射表。\n","tags":["C语言"]},{"title":"matlab","url":"/2023/01/18/matlab/","content":""},{"title":"手势操控虚拟计算器","url":"/2023/04/01/mediapipehand/","content":"在过去的2022卡塔尔世界杯中，我们可以看到其用到了各种先进的技术，其中有一项是比较吸引我的，那就是半自动越位技术。这项技术的其中的一个分支就是我今天要说的内容。如下图所示。球员身上的关键点检测技术就是今天要说的内容。\n\n\n\n\n\n\n\n\n\n\n\n二、关键点检测的分类及应用除了我们看到足球比赛中所用的半自动越位识别技术(SAOT)，还有其他的关键点检测技术,大致可以划分为三类：pose、face、hand。\n下面是在Google提供的开源工具箱MediaPie[2]中找到的相关资料，大家有兴趣可以自行去查看相关内容。\n\n从这里我们不难看出，球员身上的检测是基于Pose，也就是姿态的检测。那基于Pose 的关键点检测还有哪些应用？ \n笔者给出以下应用场景：运动指导、深度学习摔倒检查、基于深度学习的犯罪嫌疑人行为预测等方面。\n基于脸部的关键点检测应用场景主要有：表情识别、情绪分析、脸部定位等。\n由于今天主要讲解手部关键点检测所以对姿态和脸部的关键点检测介绍就到这里，感兴趣的话可以去查询相关资料文献。\n这里给大家展示手部关键点检测在华为Mate40手机中的应用。\n \n\n\n\n\n三、手部关键点检测原理\n这里的展示的手部关键点检测时基于Google的开源项目进行讲解，用到的方法是检测手部21个关键点，从而确定手部轮廓，达到手部关键点检测的目的。\n\n如上图所示手部关键点检测可以分为两步，第一步就是定位到手部的位置，这一部分相对较简单，使用主流的深度学习框架，通过有监督学习是很容易训练出一个精确度还不错的模型。第二步就是对第一步提取到的手部区域进行21个关键点检测，若此部分按照之前的方法进行有监督学习训练出一个模型来检测，效果是非常差的,为什么呢？因为摄像头所得到的信息是二维的，而我们手掌是三维的，且手几乎是人体最灵活的部位之一，倘若只通过简单的有监督学习进行检测是无法达到想要的效果，好在我们的脚下有巨人，早在2020年Google在计算机视觉顶会提出过一个模型GHUM[3]这里做了相关的一些工作，大概意思就是谷歌通过拍摄人体三维信息来构建一个模型，让模型能适应二维图像。\n下面分别是第一步和第二步模型的一些相关参数。\n\nPDM模型相关参数：\nDETECTOR MODEL SPECIFICATIONS\nModel Type\n● Convolutional Neural Network\nModel Architecture\n● Single-shot detector model\nInputs\n● A frame of video or an image, represented as a\n192 x 192 x 3 tensor. Channels order: RGB with\nvalues in [0.0, 1.0].\nOutput(s)\n● A float tensor 2016 x 18 of predicted\nembeddings representing anchors\ntransformation which are further used in Non\nMaximum Suppression algorithm.\nHLM模型相关参数：\nTRACKER MODEL SPECIFICATIONS\nModel Type\n● Convolutional Neural Network\nModel Architecture\n● Regression model\nInputs\n● A crop of a frame of video or an image,\nrepresented as a 224 x 224 x 3 tensor. Channels\norder: RGB with values in [0.0, 1.0].\nOutput(s)\n● A float scalar represents the presence of a hand\nin the given input image.\n● 21 3-dimensional screen landmarks represented\nas a 1 x 63 tensor and normalized by image size.\nThis output should only be considered valid\nwhen the presence score is higher than a\nthreshold.\n● A float scalar represents the handedness of the\npredicted hand. This output should only be\nconsidered valid when the presence score is\nhigher than a threshold.\n● 21 3-dimensional metric scale world landmarks\nrepresented as a 1 x 63 tensor. Predictions are\nbased on the GHUM hand model. This output\nshould only be considered valid when the\npresence score is higher than a threshold.\n\nPDM +HLM  就可以实现从原图的输入到下图手掌关键点检测的效果。下一步，下一步就可以开始虚拟计算器设计了。\n\n四、基于关键点检测的手势虚拟计算器这里给出手部关键点检测的设计流程，其中第一步是检测手部信息，包括手部定位和手部关键点检测，这两步完成后就可以进行虚拟计算器界面的设计，这里用的是python进行设计，相对较简单，源码也贴在下面，感兴趣的小伙伴可以去动手尝试一下。最后一步也是最关键的一步就是将手部的运动状态和计算器的操作逻辑进行绑定，从而实现手势操控计算器的目的。\n\n python源码展示[4]\nimport cv2from cvzone.HandTrackingModule import HandDetectorimport mediapipe as mpimport time  # 创建按键类class Button:    # 初始化，传入pos按键位置，每个矩形框的宽高，矩形框上的数字value    def __init__(self, pos, width, height, value):          # 初始化在while循环之前完成        self.pos = pos        self.width = width        self.height = height        self.value = value            # 绘图方法在while循环之后完成    def draw(self, img):         # 绘制计算器轮廓,img画板,起点坐标,终点坐标,颜色填充        cv2.rectangle(img, self.pos, (self.pos[0]+self.width, self.pos[1]+self.height),                       (225,225,225), cv2.FILLED)                # 给计算器添加边框        cv2.rectangle(img, self.pos, (self.pos[0]+self.width, self.pos[1]+self.height),                      (50,50,50), 3)                # 按键添加文本,img画板,文本内容,坐标,字体,字体大小,字体颜色,线条宽度        cv2.putText(img, self.value, (self.pos[0]+30,self.pos[1]+70),                    cv2.FONT_HERSHEY_COMPLEX, 2, (50,50,50), 2)            # 点击按钮    def checkClick(self, x, y): #传入食指尖坐标                # 检查食指x坐标在哪一个按钮框内，x1 &lt; x &lt; x1 + width ，控制一列        # 检查食指y坐标在哪一个按钮框内，y1 &lt; y &lt; y1 + height ，控制一行        if self.pos[0] &lt; x &lt; self.pos[0] + self.width and \\            self.pos[1] &lt; y &lt; self.pos[1] + self.height:  # &#x27;\\&#x27;用来换行             # 如果点击按钮就改变按钮颜色            cv2.rectangle(img, self.pos, (self.pos[0]+self.width, self.pos[1]+self.height),                           (0,255,0), cv2.FILLED)                            # 边框还是原来的不变            cv2.rectangle(img, self.pos, (self.pos[0]+self.width, self.pos[1]+self.height),                          (50,50,50), 3)                            # 按键文本变颜色，面积变化            cv2.putText(img, self.value, (self.pos[0]+30, self.pos[1]+70),                        cv2.FONT_HERSHEY_COMPLEX, 2, (0,0,255), 5)                    # 如果成功点击按钮就返回True            return True                else:            return False             #（1）捕获摄像头cap = cv2.VideoCapture(0)cap.set(3, 1280)  # 显示框的宽1280cap.set(4, 720)   # 显示框的高720 pTime = 0  # 设置第一帧开始处理的起始时间 # ==1== 手部检测方法，置信度为0.8，最多检测一只手detector = HandDetector(detectionCon=0.8, maxHands=1)   # ==2== 创建计算器按键# 创建按钮内容列表buttonListvalues = [[&#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;*&#x27;],                    [&#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;-&#x27;],                    [&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;+&#x27;],                    [&#x27;0&#x27;, &#x27;/&#x27;, &#x27;.&#x27;, &#x27;=&#x27;]] buttonList = []  #存放每个按键的信息 # 创建4*4个按键for x in range(4): # 四列    for y in range(4): # 四行        xpos = x * 100 + 800  #得到四块宽为100的矩形的起点x坐标，从x=800开始        ypos = y * 100 + 150  #起点y坐标                # 传入起点坐标及宽高        button1 = Button((xpos,ypos), 100, 100, buttonListvalues[y][x])        buttonList.append(button1)  # 将确定坐标的矩形框信息存入列表中 # ==3== 初始化结果显示框myEquation = &#x27;&#x27;# eval(&#x27;5&#x27;+&#x27;5&#x27;) ==&gt; 10，eval()函数将数字字符串转换成数字计算delayCounter = 0  #添加计数器，一次点击触发一次按钮，避免重复  #（2）处理每一帧图像while True:        # 接收图片是否导入成功、帧图像    success, img = cap.read()        # 翻转图像，保证摄像机画面和人的动作是镜像    img = cv2.flip(img, flipCode=1)  #0竖直翻转，1水平翻转            #（3）检测手部关键点，返回所有绘制后的图像    hands, img = detector.findHands(img, flipType=False)            #（4）绘制计算器    # 绘制计算器显示结果的部分，四个按键的宽合起来是400    cv2.rectangle(img, (800, 50), (800+400, 70+100), (225,225,225), cv2.FILLED)        # 结果框轮廓    cv2.rectangle(img, (800, 50), (800+400, 70+100), (50,50,50), 3)        # 遍历列表，调用类中的draw方法，绘制每个按键    for button in buttonList:            button.draw(img)                    #（5）检测手按了哪个键    if hands:  #如果手部关键点返回的列表不为空，证明检测到了手            # 0代表第一只手，由于我们设置了只检测一只手，所以0就代表检测到的那只        lmlist = hands[0][&#x27;lmList&#x27;]                 # 获取食指和中指的指尖距离并绘制连线        # 返回指尖连线长度，线条信息，绘制后的图像        length, _, img = detector.findDistance(lmlist[8], lmlist[12], img)        # print(length)                x, y = lmlist[8] # 获取食指坐标        # 如果指尖距离小于50，找到按下了哪个键        if length &lt; 50:             for i, button in enumerate(buttonList):  # 遍历所有按键，找到食指尖在哪个按键内                            # 点击按键，按键颜色面积发生变化，返回True。并且延时器为0才能运行                if button.checkClick(x,y) and delayCounter==0:                       #（6）数值计算                    # 找到点击的按钮的编号i，i是0-15，                    # 如&quot;4&quot;，索引为4，位置[1][0]，等同于[i%4][i//4]                    # print(buttonListvalues[i%4][i//4])                    myValue = buttonListvalues[i%4][i//4]                                        # 如果点的是&#x27;=&#x27;号                    if myValue == &#x27;=&#x27;:                        # eval()使字符串数字和符号直接做计算, eval(&#x27;5 * 6 - 2&#x27;)                        myEquation = str(eval(myEquation))  #eval返回一个数值                                        else:                        # 第一次点击&quot;5&quot;，第二次点击&quot;6&quot;，需要显示的是56                        myEquation += myValue  # 字符串直接相加                                        # 避免重复，方法一，不推荐：                     # time.sleep(0.2)                                        delayCounter = 1  # 启动计数器，一次运行点击了一个键                                #（7）避免点一次出现多个相同数，方法二：    # 点击一个按钮之后，delayCounter=1，20帧后才能点击下一个    if delayCounter != 0:        delayCounter += 1 # 延迟一帧        if delayCounter &gt; 50:  # 10帧过去了才能再点击            delayCounter = 0      #（8）绘制显示的计算表达式    cv2.putText(img, myEquation, (800+10,100+20), cv2.FONT_HERSHEY_PLAIN,                3, (50,50,50), 3)         # 查看FPS    cTime = time.time() #处理完一帧图像的时间    fps = 1/(cTime-pTime)    pTime = cTime  #重置起始时间        # 在视频上显示fps信息，先转换成整数再变成字符串形式，文本显示坐标，文本字体，文本大小    cv2.putText(img, str(int(fps)), (70,50), cv2.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)          # 显示图像，输入窗口名及图像数据    cv2.imshow(&#x27;image&#x27;, img)     # 每帧滞留时间    key = cv2.waitKey(1)        # 清空计算器框    if key == ord(&#x27;c&#x27;):        myEquation = &#x27;&#x27;            # 退出显示    if key &amp; 0xFF==27:  #每帧滞留20毫秒后消失，ESC键退出        break # 释放视频资源cap.release()cv2.destroyAllWindows()\n\n\n\n五、Demo展示最后一部分就是一个小Demo。\n \n\n\n\n参考文献1.卡塔尔世界杯半自动越位系统的技术介绍 ↩2.MediaPipe的官网地址 ↩3.Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6184-6193, 2020 ↩4.机器视觉案例 ↩"},{"title":"2024年个人目标（测试）","url":"/2023/02/25/myago24/","content":"\n\n\n Doocs开源社区\n 掘墓人的小铲子\n 全网重点\n 爱码士的内心独白\n 乐玩nodejs npm工具库\n 简静慢\n 0加1\n 编程图解\n\n\n\n 码云Gitee\n 好酸一柠檬\n 不知所云Hub\n 会泽百家\n 平凡而诗意\n 治恒说说\n 柯宁申的叙事屋\n 我的 Beta 世界\n\n\n ApachePulsar\n 生化环材\n 秀宇笔记\n IT王小二\n 小二来碗饭\n 青年技术宅\n 路引科研\n 凯文有事找你\n\n\n 软件部落库\n 网文小密圈\n 潇洒哥和黑大帅\n 云原生指北\n 全栈民工\n 睡不醒的鲤鱼\n Dmego\n 红岸\n\n\n HelloCoder\n 前端黑板报\n\n\n\n\n\n\n\n\n注：如果你使用了本 Markdown 编辑器进行文章排版，并且希望在本项目 README 中展示你的公众号，请到 #5 留言。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","categories":["年度目标"],"tags":["目标"]},{"title":"openvino在ubuntu20上的安装部署","url":"/2023/06/03/openvino%20%E5%9C%A8ubuntu20%E4%B8%8A%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"先决条件：ubuntu20.04\nopenvino runtime2022.04\nQT creater&#x2F;vs code\ncmake\nopencv\n第一步：工具的安装1.首先当然是安装系统，笔者这里已经安装好ubuntu20.04.6LTS的系统。\n2.接下来的应用安装顺序没有要求，笔者这里首先安装openvino runtime2022.04点击这里可以直达下载地址。这里的环境选择运行时（openvino runtime）操作系统选择Linux，版本选择最新的LTS版本，也就是2022.3，这里通过归档文件的方式进行安装。大家也可以点击此链接看官方的安装步骤\n\n选择好后依次执行以下命令即可安装：\nsudo apt install curlsudo mkdir /opt/intelcd ~/Downloadscurl -L https://storage.openvinotoolkit.org/repositories/openvino/packages/2022.3/linux/l_openvino_toolkit_ubuntu20_2022.3.0.9052.9752fafe8eb_x86_64.tgz --output openvino_2022.3.0.tgztar -xf openvino_2022.3.0.tgzsudo mv l_openvino_toolkit_ubuntu20_2022.3.0.9052.9752fafe8eb_x86_64 /opt/intel/openvino_2022.3.0cd /opt/intel/openvino_2022.3.0sudo -E ./install_dependencies/install_openvino_dependencies.shcd /opt/intelsudo ln -s openvino_2022.3.0 openvino_2022\n\n至此openvino runtime 安装完成，我们可以通过如下命令来验证以下是否安装成功。\nsource /opt/intel/openvino_2022/setupvars.sh\n\n若出现如下图所示的输出，恭喜你已经成功安装openvino runtime\n\n注意要想正确使用openvino runtime 每次启动时都要输入上面的一条命令。那官方也给出了一劳永益的方法;\n\n具体的做法如下所示：\n更新环境变量，编辑.&#x2F;bashrc文件：\nsudo gedit ~/.bashrc\n\n添加下面这条语句，然后 ctrl +s 保存。\nsource /opt/intel/openvino_2022/setupvars.sh \n\n保存后别忘了执行下面这条语句来更新一下：\nsource ~/.bashre\n\n这样每次新打开一个新终端都会出现OpenVINO™ environment initialized.  从而达到一劳永益的目的。\n3.安装QT这里我们也是通过归档的方式来进行安装。\n选择5.12.9版本进行安装链接为https://download.qt.io/archive/qt/5.12/5.12.9/ 注意你可以安装其他版本，但这里建议不要安装过高版本，因为笔者也踩了几次坑。不希望大家把过多的经历花费在软件安装配置上面。\n接下俩选择qt-opensource-linux-x64-5.12.9.run即可进行下载。\n\n下载完成后断开互联网（否则要填写qt帐号验证），然后执行下面的三条命令进行安装。\ncd ~/Downloadssudo chmod +x qt-opensource-linux-x64-5.12.9.runsudo ./qt-opensource-linux-x64-5.12.9.run\n\n注意在下图所示界面勾选所有的内容。\n最后点击完成即可，如下图所示。\n\n为了方便我们我们可以创建桌面图标。\n创建桌面图标需要执行如下操作：\nsudo gedit /usr/share/applications/QtCreator.desktop\n\n然后在弹出的文本编辑器中输入以下内容。\n[Desktop Entry]Type=ApplicationName=QtCreatorGenericName=QtCreatorExec=/opt/Qt5.12.9/Tools/QtCreator/bin/qtcreatorIcon=/opt/Qt5.12.9/Tools/QtCreator/share/qtcreator/qbs/share/qbs/examples/cocoa-application/CocoaApplication/CocoaApplication.xcassets/AppIcon.appiconset/icon_512x512.pngTerminal=falseCategories=Development;Qt;\n\n\n最后安装一些包\nsudo apt-get install build-essentialsudo apt-get install libqt4-dev\n\n\n\n4.安装opencv这里用的版本是3.4版本。\n可以去Github下载，这里同样给出下载链接https://github.com/opencv/opencv/tree/3.4\n下载完成后进行解压，并给权限。\ncd ~/Downloadsunzip opencv-3.4.zipsudo mv opencv-3.4 /opt/opencv-3.4cd /opt/opencv-3.4mkdir buildapt-get install build-essentialsudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-devcd buildcmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..makesudo make installgedit /etc/ld.so.conf.d/opencv.conf \n整个make的过程有点长，请耐心等待，完成后会出现下图所示。\n\n打开文本编辑器后输入如下内容 /user/local/lib\n\nsudo ldconfigsudo gedit ~/.bashrc\n\n在打开的文档中输入如下内容PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfigexport PKG_CONFIG_PATH\n\nsource ~/.bashrc\n\n输入  pkg-config opencv --modversion   查看版本\n\n\n显示如上信息表示正常。\n5.测试环境接下来笔者用自己之前的一个项目测试一下，是否可以正常工作。\n这是一个通过openvino来推理yolov5训练出来的一个数字识别项目。项目结构如下图所示。\n\n.&#x2F;configFiles目录下方的是一些模型文件和类别文件。\n.&#x2F;data&#x2F;test_data目录下放置一些测试图片，.&#x2F;data&#x2F;save_data目录下用来存放检测结果图片。\n.&#x2F;include目录下放置头文件。\n.&#x2F;src目录下放置源文件。\n\n\n我们可以在根目录下执行以下命令来编译运行此工程。\nmkdir buildcmake ..make\n\n\n执行完上述命令,编译成功后会在build文件夹下生成可执行的mnist 二进制文件。\n此时可以直接 在终端输入 .&#x2F;mnist 来运行此二进制文件。\n\n运行结束后即可看到在.&#x2F;data&#x2F;save_data  目录下生成结果文件。如下图所示：包括一个result.csv文件和一些图片文件。\n\n下面打开其中两张张来作为结果展示。\n\n\n 效果还算非常不错的。至此软件安装 以及测试环节就讲解完毕。\n参考资料：\n[1] https://docs.openvino.ai/2023.0/home.html\n[2]https://blog.csdn.net/xjcwzp/article/details/88861813?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=20:13:55:%20Could%20not%20start%20proc&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-88861813.142\n[3]https://blog.csdn.net/jiugeshao/article/details/124288250?spm=1001.2014.3001.5502\n[4]https://blog.csdn.net/itliyang/article/details/126259796\n[5]https://blog.csdn.net/gLare_nijianwei/article/details/128972547?ops_request_misc=&amp;request_id=&amp;biz_id=&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~koosearch~default-6-128972547-null-null.142\n[6]https://blog.csdn.net/qq_36373500/article/details/128078092?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168511979016800184166857%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168511979016800184166857&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-128078092-null-null.142\nOther:之后我会完善此部分，分享如何通过openvino进行模型的优化，以及如何通过异步流水线来实现更高的帧率和其他一些模型部署相关的知识。\n声明：时间仓促，很多参考过的资料也无法溯源，在此对开源大佬，以及提供帮助的伙们表示深深的敬意。最后附上我非常喜欢的一句话：看见光，追随光，成为光，发散光。\n","tags":["openvino"]},{"title":"2023年个人目标","url":"/2023/01/17/myago/","content":"\n\n\n2023年\n第一季度（1月-3月）\n2023年第二季度（4月-6月）\n2023年第三季度（7月-9月）\n2023年第四季度（10月-12月）\n\n\n\n目标&#x2F;计划&#x2F;任务\n- 完成RCNN论文复现- 春节游玩- Linux编程（c\\c++）学习总结- 考试复习- 完成傅里叶笔记的博客同步- 读一本想读的课外书并做笔记- 总结RCNN的相关代码和博客\n- 完成数据结构的复习 - 完成C++的复习- 完成嵌入式C语言的自我修养- 完成赵卫东老师机器学习的学习- 加速完成mooc上tf的学习\n- 完成C++的复习- 准备开题报告\n\n\n\n大事件&amp;完成度\n完成了RCNN论文复现大年初一和朋友跑步17km到县城学习了linux的c语言编程，和数据结构相关知识并总结至博客和父母和姐一块去西安吃顿饭，并西安市城隍庙门口拍了五年前的相同照片（父母合照），春节前夕体验了送外卖，赚了点零花钱向父母许诺以后不向他们要钱。从3月1日开始跑步每天5公里，希望以后能一直坚持下去2月25日，开学啦，有点不舍，但又习惯了的感觉。\n完成了数据结构的复习完成了嵌入式c的学习\n\n\n\n\n总结\n蹭 邵红老师的深度学习课程，上学期修了老师的数字图像处理感觉老师讲的挺好，在很短的学时老师抛砖引玉，给我指明了学习的方法，希望自己能坚持听完这门课，坚持下去。日语学习下点功夫。又考六级了，也许考的次数多了人都麻木了，每次都报名，而又不好好准备\n伴随着课程的结束，各种考试接踵而至。所以很多事情未能完成，在此期间我也二阳，耽误一周。\n\n\n\n\n","categories":["年度目标"],"tags":["目标"]},{"title":"python","url":"/2023/01/18/python/","content":"this page to show python code modules\n\n\nmatplotlab绘制损失&amp;精度图# plt 读取权重文件绘制图形# 权重文件.txt 形式如下# &#123;&quot;train_lr&quot;: 7.806273333612983e-07, &quot;train_min_lr&quot;: 7.806273333612983e-07, &quot;train_loss&quot;: 6.33559472168852, &quot;train_loss_scale&quot;: 8240.107382550335, &quot;train_weight_decay&quot;: 0.049999999999998955, &quot;train_grad_norm&quot;: Infinity, &quot;val_loss&quot;: 4.888336278969729, &quot;val_acc1&quot;: 1.480306729733424, &quot;val_acc5&quot;: 7.903780453929251, &quot;epoch&quot;: 0, &quot;n_parameters&quot;: 133832650&#125;# 读代码如下 jupyter 读取文件并绘制图形代码如下：%matplotlib inlineimport matplotlib.pyplot as pltimport jsonimport numpy as npfile = open(&#x27;data.txt&#x27;)  # 打开文档data = file.readlines()  # 读取文档数据def pluck(lst, key):    return [x.get(key) for x in lst]d = []for i in data : #str to dict    c = json.loads(i)    d.append(c)    print(type(data[0]))print(type(d[0]))  fig = plt.figure(figsize = (7,5))       #figsize是图片的大小ax1 = fig.add_subplot(1, 1, 1) # ax1是子图的名字# “-”代表画的曲线是实线，可自行选择，label代表的是图例的名称，一般要在名称前面加一个u，如果名称是中文，会显示不出来，目前还不知道怎么解决。train_loss_line = plt.plot(pluck(d, &#x27;epoch&#x27;),pluck(d, &#x27;train_loss&#x27;),&#x27;r-&#x27;, label = u&#x27;train_loss&#x27;)#显示图例val_loss_line = plt.plot(pluck(d, &#x27;epoch&#x27;),pluck(d, &#x27;val_loss&#x27;), &#x27;b-&#x27;, label = u&#x27;val_loss&#x27;)plt.legend()plt.xlabel(u&#x27;epoch&#x27;)plt.ylabel(u&#x27;loss&#x27;)plt.title(&#x27;Compare loss for different epoch in training&#x27;)plt.show()  fig = plt.figure(figsize = (7,5))       #figsize是图片的大小ax2 = fig.add_subplot(1, 1, 1) # ax2是子图的名字p2 = plt.plot(pluck(d, &#x27;epoch&#x27;),pluck(d, &#x27;val_acc1&#x27;),&#x27;r-&#x27;, label = u&#x27;Top-1&#x27;)p3 = plt.plot(pluck(d, &#x27;epoch&#x27;),pluck(d, &#x27;val_acc5&#x27;), &#x27;b-&#x27;, label = u&#x27;Top-5&#x27;)plt.legend()plt.xlabel(u&#x27;epoch&#x27;)plt.ylabel(u&#x27;accuracy&#x27;)plt.title(&#x27;Compare acc of Top-1 and Top-5&#x27;)plt.show()\n\n批量视频数据提取帧import os.pathimport cv2# 参数：#   path：  要操作文件的根目录#   list:   默认给 [] 即可# 功能：#   将path路径下的所有文件夹名称存入列表，并返回def traversalDir_FirstDir(path, list):    if (os.path.exists(path)):        files = os.listdir(path)        for file in files:            m = os.path.join(path, file)            if (os.path.isdir(m)):                h = os.path.split(m)                list.append(h[1])    return list#   一个测试函数def test_traversalDir_FirstDir():    dir = &quot;C:\\\\Users\\\\Bigfly\\\\Desktop\\\\frame\\\\test&quot;    list = traversalDir_FirstDir(dir, [])    print(list)# 参数：#   timerate: 视频截帧间隔#   rootdir：  想要操作文件的根目录#   video_subname:  视频文件的后缀名  例如  ‘.mp4’# 函数功能：# 通过时间间隔截取视频帧def video2frame(timerate, rootdir, video_subname):    n = 0    path = os.path.dirname(rootdir)  # 拿到视频所在文件夹的上一层文件夹    # print(path)    # if not os.path.join(path,&quot;save_frame&quot;):    os.mkdir(os.path.join(path, &quot;save_frame&quot;))    save_frame_rootdir = os.path.join(path, &quot;save_frame&quot;)  # 创建一个保存帧的文件夹    # print(save_frame_rootdir)    dirlist = traversalDir_FirstDir(rootdir, [])  # 得到视频所在文件夹下，eg 第n组        for i in range(0, len(dirlist)):        # if not os.path.join(save_frame_rootdir,dirlist[i]):        os.mkdir(os.path.join(save_frame_rootdir, dirlist[i]))        save_frame_subdir_i = os.path.join(save_frame_rootdir, dirlist[i])  # 保存帧的子文件夹  eg 第n组        for root, dirs, names in os.walk(os.path.join(rootdir, dirlist[i])):  # 开始在视频文件夹处理视频            for name in names:                pre_name = os.path.splitext(name)[0]                ext = os.path.splitext(name)[1]                # if not os.path.join(save_frame_subdir_i, pre_name):                os.mkdir(os.path.join(save_frame_subdir_i, pre_name))                save_frame_dir = os.path.join(save_frame_subdir_i, pre_name)                # print(save_frame_dir)                if ext == video_subname:                    # print(ext)                    fromdir = os.path.join(root, name)  # .mp4的绝对路径                    # print(fromdir)                    cap = cv2.VideoCapture(fromdir)                    c = 1                    while (True):                        ret, frame = cap.read()                        FPS = cap.get(5)                        if ret:                            frameRate = int(FPS) * timerate                            # print(frameRate)                            if (c % frameRate == 0):                                # print(frameRate)                                # cv2.imshow(frame)                                st = save_frame_dir + str(&quot;\\\\&quot;) + str(n).zfill(6) + &#x27;.jpg&#x27;                                # print(st)                                cv2.imwrite(st, frame)                                n += 1                            c += 1                            cv2.waitKey(0)                        else:                            print(dirlist[i] + &quot;  &quot; + pre_name + &quot;照度处理完毕&quot;)                            break                    cap.release()if __name__ == &#x27;__main__&#x27;:            video2frame(2, &quot;C:\\\\Users\\\\Bigfly\\\\Desktop\\\\frame\\\\test&quot;, &#x27;.mp4&#x27;)\n\n","categories":["编程"]},{"title":"rcnn","url":"/2023/04/27/rcnn/","content":"\n"},{"title":"shell","url":"/2023/01/18/shell/","content":""},{"title":"最后一个免费版本Typora","url":"/2025/01/25/typora_free/","content":"git clone https://gitee.com/bigflya/typora_free.git\ncd typora_free\nsudo apt install .&#x2F;Typora_Linux_0.11.18_amd64.deb\ntypora\n","tags":["工具"]},{"title":"ubuntu安装openvino","url":"/2023/02/13/ubuntu%E5%AE%89%E8%A3%85openvino/","content":"一、安装环境:\n已有的环境\nubuntu18.04LTS\n\n准备安装的环境\n\n\n\n\n\n\n二、检查自己的python环境：18.04的ubuntu自带的python版本为3.59，而openvino对python版本有要求，因此我们需要将ubuntu的python进行更新具体操作如下：\nsudo add-apt-repository ppa:jonathonf/python-3.8sudo apt-get updatesudo apt-get install python3.8 sudo apt-get install python3-pipsudo pip3 install --upgrade pip\n\n执行以上命令可能会遇到的错误如下：\nupdate-alternatives: error: no alternatives for python  点击此处查看解决方法\n三、安装openvino\n更新pip镜像源方法参考\n\napt install python3.8-venv\npython3 -m venv openvino_env\nsource openvino_env/bin/activate\npython -m pip install --upgrade pip\n3. ```shell   pip install openvino-dev[caffe,pytorch,tensorflow2,ONNX]==2022.3.0 \n\n中括号中可以选择的模型[参考]([下载英特尔® 发行版 OpenVINO™ 工具套件 (intel.cn)](https://www.intel.cn/content/www/cn/zh/developer/tools/openvino-toolkit/download.html))中的框架部分\n\n\nmo -h #测试是否安装成功\n\n\n\n四、安装openvino_notebooks具体安装过程，可以参考[链接](Ubuntu · openvinotoolkit&#x2F;openvino_notebooks Wiki (github.com)),笔者在此不再赘述，此部分安装过程比较慢，耐心等待即可。\n五、官方demo测试这里给出笔者在官网找到的测试demo点击[链接](您好图像分类 — OpenVINO™ 文档 — 版本（最新）)即可进行相关验证学习。\n","categories":["经验分享"],"tags":["openvino","ubuntu"]},{"title":"含二阶畸变模型的世界坐标到像素坐标转换","url":"/2023/05/02/visualcoordinate/","content":"\n"},{"title":"二级指针传参修改地址","url":"/2023/07/01/%E4%BA%8C%E7%BA%A7%E6%8C%87%E9%92%88%E4%BC%A0%E5%8F%82%E4%BF%AE%E6%94%B9%E5%9C%B0%E5%9D%80/","content":"最近通过复习数据结构的相关知识对指针传参问题又有了更深的理解，在此记录以下\n指针传参遇到的问题：为什么有时候传参一级指针就可以，但有时候却需要二级指针？\n一级指针：是一个指针变量，指向一个普通变量，并保存该普通变量的地址; 二级指针：是一个指针变量，指向一个一级指针，并保存该一级指针的地址;\n\n\n\n#include &lt;stdio.h&gt; int array[4]=&#123;1,2,3,4&#125;; void test(int *t)&#123;\tt++;\tprintf(&quot;t=%p\\n&quot;,t);&#125; int main()&#123;\tint *p=array;\tprintf(&quot;p=%p\\n&quot;,p);\ttest(p);\tprintf(&quot;p=%p\\n&quot;,p); &#125;\n\n输出结果为：p=0x207030t=0x207034p=0x207030\n\n这里有两个点：\n\n一个指针占四个字节（32位机器）\n\n虽然在test中对t进行++ 操作，但是并不会改变main中p的地址，因为在test(p)中传入的是p 此时的p就是一个int 型，值位0x207030数，只有当但当用 形参 int *t去接受 p 在test函数中 0x207030 才会被当作地址。而且只是在test函数中被当作地址。所以在test()函数中 对传入的参数进行++操作并不会影响到main函数中指针p的地址。虽然无法改变p的地址，但可以改变p中存放的值。\n#include &lt;stdio.h&gt; int array[4]=&#123;1,2,3,4&#125;; void test(int *t)&#123;\t\t*t = 5;//改变传入地址中的值是一级指针传参的基本功能\t//t=0x114455;&#125; int main()&#123;\tint *p=array;\tprintf(&quot;p=%p\\n&quot;,p);\t\ttest(p);\tprintf(&quot;p=%p\\n&quot;,p);\t\tprintf(&quot;%d %d %d %d\\n&quot;,array[0],array[1],array[2],array[3]); &#125;\n\n遇到问题：\n​\t如果想要通过test()函数来修改p的地址应该如何操作呢？\n解决方法：\n​\t二级指针传参，不但可以改变一级指针所指的内容（如上代码中的作用），也可以改变一级指针的地址。\n​\t\n#include &lt;stdio.h&gt; int array[4]=&#123;1,2,3,4&#125;; void test(int **t)&#123;\t\t\t*t = 0x114455;//改变一级指针的地址\t//**t =5;//改变一级指针所指的对象&#125; int main()&#123;\tint *p=array;\tprintf(&quot;p=%p\\n&quot;,p);\t\ttest(&amp;p);\tprintf(&quot;p=%p\\n&quot;,p);\t\tprintf(&quot;%d %d %d %d\\n&quot;,array[0],array[1],array[2],array[3]); &#125;\n\n如上代码，在main() 传入的是指针的地址，所以形参要用二级指针接收，此时在test()函数中 *t相当于对 **t进行解引，而  * *t&#x3D;&amp;p（一级指针的地址给了二级指针）,解引相当于拿到二级指针  *  *t中的内容也就是&amp;p （p的地址），那么就可以通过 *t &#x3D; 0x114455;去改变p的地址，也可以通过  * *t去改变一级指针所指的对象。\n总结：​\t\t不能通过一级指针传参来修改传入指针的地址，因为传入的p相当于一个变量，而在test()对这个和地址长的一样的变量进行修改，并不会影响到main()中p的地址。二级指针传参能解决这一问题的本质就是二级指针传入的是一个地址 ，既然传入的是地址那就能在test()中对地址进行改变。\n","categories":["编程"],"tags":["C语言","指针"]},{"title":"关于APUE中多线程编程的条件变量相关内容","url":"/2023/12/10/%E5%85%B3%E4%BA%8EAPUE%E4%B8%AD%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9/","content":"LINUX环境下多线程编程肯定会遇到需要条件变量的情况，此时必然要使用pthread_cond_wait()和其他发信号的函数函数，然而在了解这部内容的过程中，有些疑惑。\n一、代码下面是笔者在学习APUE的过程中使用多线程相关知识实现对指定范围内的质数的筛选，并在屏幕上打印出找到的质数。\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include &lt;string.h&gt;// 通过池类算法，和 互斥量也就是锁相关的知识实现了，固定区间的质数的筛选。// 重点内容：质数筛选的方法，以及 临界区代码 的跳转存在的问题，// 查询法，降低cpu的占用率#define LEFT 30000000#define RIGHT 30000200#define THRNUM 4static int num = 0;static pthread_mutex_t mut_num = PTHREAD_MUTEX_INITIALIZER;static pthread_cond_t cond_num = PTHREAD_COND_INITIALIZER;static void *thr_prime(void *p);int main() // main线程&#123;    int err;    pthread_t tid[THRNUM];    for (size_t i = 0; i &lt; THRNUM; i++)    &#123;        err = pthread_create(tid + i, NULL, thr_prime, (void *)i); // NULL表示默认属性,thr_prime表示线程要做的事情        if (err)        &#123;            fprintf(stderr, &quot;pthread_create():%s\\n&quot;, strerror(err));            exit(EXIT_FAILURE);        &#125;    &#125;    // 下发任务    for (size_t i = LEFT; i &lt;= RIGHT; i++)    &#123;        pthread_mutex_lock(&amp;mut_num);        // 循环判断任务有没有被抢走        while (num != 0) // 任务没有被抢走，分配数的时候 ，三个池在抢，一旦抢走将其设置为0        &#123;            pthread_cond_wait(&amp;cond_num, &amp;mut_num);//期待num变为0，谁会把num变为0呢？                    &#125;        num = i; // 放任务        pthread_cond_signal(&amp;cond_num); // 叫醒 下游任何一个就行，而不是叫醒全部，这里叫醒任意一个闲的，若全部叫醒用broadcast                pthread_mutex_unlock(&amp;mut_num); // 解锁    &#125;    pthread_mutex_lock(&amp;mut_num);    //*** for循环完成后，当前线程若又接到调度，那么不加下面的while 将会使最后一个任务被覆盖掉    while (num != 0)    &#123;        pthread_mutex_unlock(&amp;mut_num);        sched_yield();        pthread_mutex_lock(&amp;mut_num);      &#125;    num = -1;// num =-1 说明没任务了，        pthread_cond_broadcast(&amp;cond_num);    pthread_mutex_unlock(&amp;mut_num); // 解锁    for (size_t i = 0; i &lt; THRNUM; i++)    &#123;        pthread_join(tid[i], NULL); // 收尸    &#125;    pthread_mutex_destroy(&amp;mut_num);    pthread_cond_destroy(&amp;cond_num);    exit(EXIT_SUCCESS);&#125;static void *thr_prime(void *p)&#123;    int j, mark, i;    while (1)    &#123; // 临界区        pthread_mutex_lock(&amp;mut_num);        while (num == 0)        &#123;            pthread_cond_wait(&amp;cond_num, &amp;mut_num); // 解锁等待num变成非零，谁会把num变为非零呢？这里是查询法，而不是一直循环                    &#125;        if (num == -1)        &#123;            // 临界区跳转，且跳转的目的地是临界区外，一定要先解锁再跳转。否则会出现死锁。            pthread_mutex_unlock(&amp;mut_num);            break; // 总任务完成        &#125;        i = num;        num = 0;        pthread_cond_broadcast(&amp;cond_num); // 将num设置为0 ，发送一个通知        pthread_mutex_unlock(&amp;mut_num);        mark = 1;        for (j = 2; j &lt; i / 2; ++j)        &#123;            if (i % j == 0)            &#123;                mark = 0;                break;            &#125;        &#125;        if (mark)            printf(&quot;[%d]%d is a primer\\n&quot;, (int)p, i);    &#125;    pthread_exit(NULL);&#125;\n\n\n\n\n\n二、疑惑点： pthread_cond_broadcast与pthread_mutex_unlock的先后顺序问题\nchatGPT给出的答案：\n\n在多线程编程中，pthread_mutex_unlock 和 pthread_cond_broadcast 的执行顺序通常是没有明确要求的，因为它们操作的是不同的同步原语：互斥锁和条件变量。\n\n网上大多数的代码给出的答案：\n\n先pthread_cond_broadcast再pthread_mutex_unlock\n\n笔者个人的思考总结：\n\n\n先pthread_cond_broadcast再pthread_mutex_unlock会出现的问题：这样做pthread_cond_broadcast处在临界区内，只有当pthread_mutex_unlock解锁之后，其他子线程才有机会加锁，加锁成功的线程才能cond_wait收到广播信号，倘若在pthread_cond_broadcast与pthread_mutex_unlock之间还有很多代码需要执行，那此刻pthread_cond_broadcast尽管发送了信号，但其也是阻塞状态，只有当unlock之后其他子线程才能抢锁然后cond_wait收到cond_broadcast发送的信号。\n先pthread_mutex_unlock 再pthread_cond_broadcast会出现的问题：通知时机问题： ( 如果先解锁再广播，有可能在解锁后，条件变量的等待线程还未来得及执行。这样，等待线程可能错过了通知，从而导致它们继续等待而不被唤醒。从而使程序出现不期望的结果)   竞态条件： (如果在解锁互斥锁后，调用 pthread_cond_broadcast 之前有其他线程抢占执行，并尝试获取互斥锁进行修改，那么这些修改可能与 pthread_cond_broadcast 同时发生，导致不一致的状态。意思就是，若存在刚解锁还没来得及broadcast时，当前线程被操作系统调度出CPU,而其他线程刚好被调度并尝试获取相同的互斥锁，此时线程就有机会在广播之前获取互斥锁并修改共享资源。接着，执行广播的线程再次获取互斥锁，执行广播，但但有线程已经修改了共享资源，这可能导致不一致的状态，产生竞态条件。)\n\n\n总结：\n\n先解锁再广播，虽然等待条件的线程能够尽早获得互斥锁然后cond_wait可以很快的收到广播信号，但是这种做法存在潜在的问题，可能会导致在广播发送信号的瞬间其他线程修改了共享资源，从而可能引起竞态条件或不一致性。而先再临界区内广播然后再解锁，这样可以避免以上潜在问题，代价就是速度变慢了，若在调用 pthread_cond_broadcast 之前，互斥锁已经被解锁。这样一来，虽然被唤醒的线程就可以尽快获得互斥锁，进入临界区执行，但是，若在调用pthread_cond_broadcast广播的时候其他线程瞬间修改共享资源，会出现错误。\n尽管先unlock 再broadcast，出现错误的概率可能很低，比中彩票的概率还低，但从逻辑分析，这种问题是存在的，所以为了避免这种不期望事情发生，一般采取先broadcast 然后再unlock。\n三、one more thing(求质数的巧妙方法)这里判断质数的方法是\nmark = 1;      for (j = 2; j &lt; i / 2; ++j)      &#123;          if (i % j == 0)          &#123;              mark = 0;              break;          &#125;      &#125;      if (mark)          printf(&quot;[%d]%d is a primer\\n&quot;, (int)p, i);\n\n其中i是待判断的数。\n质数的定义：只能分解为1和它本身两个因数\n上面的做法给i&#x2F;2是为了减少计算量，直接写i也没问题，但是为什么可以写i&#x2F;2呢？\n这是因为如果 i 有大于i/2的因子，那么它的另一个因子一定小于i/2，否则两个因子的乘积就会超过 i。因此，只需要判断 i 是否在2到i/2的范围内有因子即可。\n还有一种做法是，要判断到sqrt(i)即可，因为如果 i 有一个大于sqrt(i)的因子，那么它的另一个因子一定小于sqrt(i)，两个因子的乘积就会超过 i。因此，循环的条件可以改为 j &lt;= sqrt(i)。这样也可以减少不必要的循环次数，但由于要调用sqrt对应的函数库或者自己写相关的开平方函数，所以没有采用这种方法。\n","categories":["编程"],"tags":["Linux"]},{"title":"关于文件777权限(可读可写可执行)","url":"/2023/12/04/%E5%85%B3%E4%BA%8E%E6%96%87%E4%BB%B6777%E6%9D%83%E9%99%90(%E5%8F%AF%E8%AF%BB%E5%8F%AF%E5%86%99%E5%8F%AF%E6%89%A7%E8%A1%8C)/","content":"前言：在使用Linux的时候不知道大家是否使用过类似下面的命令:\nchmod -R 777 &lt;file_name&gt;\n\n这句命令的作用是改变file_name的文件可执行权限，但为何是777不是其他数字呢？777的含义是什么？777的底层原理是什么呢？不知道大家是否有过这样的疑问。\n\n\nLinux文件权限解释：Linux的三种操作对象：Linux&#x2F;Unix系统根据对象赋予文件相应的权限,具体对每个文件而言，有三种操作对象，分别是：owner、group、other。它表示文件所有者（owner）和同一组用户（group），以及其他用户（other）。  \n通常Linux&#x2F;Unix系统下每个文件的权限用类似”-rw-rw-r- -  “这样的方式表示：\n\n第一个rw- 表示所有者（owner）有读（r）和写（w）权限，但没有执行（x）权限。  后面的”-“是没有可执行权限。\n\n第二个rw- 表示表示同一组用户（group）也有读和写的权限，同样没有执行权限。  \n\n第三个r- - 表示表示其他用户（other）只有读权限，没有写和执行权限。\n\n\n\ntips：“-rw-rw-r- -  “开头的”-“ 表示这是一个普通文件（而不是目录或特殊文件）。\n\n文件权限的8进制表示:在Linux中，文件的权限被表示为一个三位数的八进制数，  如上面提到的”-rw-rw-r- -  “就可以用8进制664来表示，具体原理如下：\n\n第一个6表示所有者的权限，8进制的6对应的二进制是110，这里的110相当于是位图，表示：可读、可写、不可执行。\n同理第二个6表示同一组用户的权限，也是可读可写不可执行。\n第三个4表示其他用户的权限，8进制的4对应的二进制是100，即表示：可读、不可写、不可执行。\n\n文件权限777的解释：八进制的7对应的二进制为111，从笔者上面的解释可以推出其表示的含义是-rwx也就是可读可写可执行，三个7分别对应是三个操作对象的权限，即文件所有者权限、同意住用户权限和其他用户权限,可表示为：**-rwxrwxrwx**。\nchmod -R 777 &lt;file_name&gt;上面这行命令可以用下面的替换：chmod -R -rwxrwxrwx &lt;file_name&gt;\n\n\n\n\n\n","categories":["编程"],"tags":["Linux"]},{"title":"友元类使用的一些问题","url":"/2023/12/13/%E5%8F%8B%E5%85%83%E7%B1%BB%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/","content":"\n为什么会有友元类？\n\n与友元函数存在的功能类似 ，当两个或多个类之间不存在派生或者继承关系的时候，但又想在某一个类中调用另外一个类的方法，此时可以用 友元类。友元类的所有方法都可以访问原始类的私有成员和保护成员。\n循环依赖：\n这里创建两个类，一个是电视类、另外一个是遥控器类。并将遥控器类作为电视类的友元类。\n#ifndef __TV_H__#define __TV_H__#include &lt;iostream&gt;using namespace std;class Tv&#123;\tprivate:\t\tenum&#123;off, on&#125;;\t\tenum&#123;MinVal, MaxVal = 20&#125;;\t\tenum&#123;MinChan = 1, MaxChan = 100&#125;;\t\tenum&#123;TV, DVD&#125;;\t\tint state;\t\tint volume;\t\tint channel;\t\tint input;\tpublic:\t\tTv(int s = off) : state(s), volume(5), channel(2), input(TV)&#123;&#125;\t\tvoid onoff()&#123;state = (state == on) ? off : on;&#125;\t\tbool volup();\t\tbool voldown();\t\tvoid chanup();\t\tvoid chandown();\t\tvoid set_input()&#123;input = (input == TV) ? DVD : TV;&#125;\t\tvoid show_settings() const;\t\tfriend class Remote;&#125;;class Remote&#123;\tprivate:\t\tint mode;\tpublic:\t\tRemote(int m = Tv::TV) : mode(m)&#123;&#125;\t\tvoid onoff(Tv &amp;t)&#123;t.onoff();&#125;\t\tbool volup(Tv &amp;t)&#123;return t.volup();&#125;\t\tbool voldown(Tv &amp;t)&#123;return t.voldown();&#125;\t\tvoid chanup(Tv &amp;t)&#123;t.chanup();&#125;\t\tvoid chandown(Tv &amp;t)&#123;t.chandown();&#125;\t\tvoid set_channel(Tv &amp;t, int c)&#123;t.channel = c;&#125;\t\tvoid set_input(Tv &amp;t)&#123;t.set_input();&#125;&#125;;#endif\n\n\n\n\n\n\n\n上面这个类书写存在的一些问题：\n只在Remote的void set_channel(Tv &amp;t, int c){t.channel &#x3D; c;}中访问到了Tv类的私有成员channel ，其他的都是在调用Tv类的公有接口，那这样的话将Remote定义为友元类就大可不必，可用只将Remote中的set_channel设置为友元就可用，做法如下：\n#ifndef __TV_H__#define __TV_H__#include &lt;iostream&gt;using namespace std;class Tv&#123;\tprivate:\t\tenum&#123;off, on&#125;;\t\tenum&#123;MinVal, MaxVal = 20&#125;;\t\tenum&#123;MinChan = 1, MaxChan = 100&#125;;\t\tenum&#123;TV, DVD&#125;;\t\tint state;\t\tint volume;\t\tint channel;\t\tint input;\tpublic:\t\tTv(int s = off) : state(s), volume(5), channel(2), input(TV)&#123;&#125;\t\tvoid onoff()&#123;state = (state == on) ? off : on;&#125;\t\tbool volup();\t\tbool voldown();\t\tvoid chanup();\t\tvoid chandown();\t\tvoid set_input()&#123;input = (input == TV) ? DVD : TV;&#125;\t\tvoid show_settings() const;\t\tfriend void Remote::set_channel(Tv &amp;t, int c);&#125;;class Remote&#123;\tprivate:\t\tint mode;\tpublic:\t\tRemote(int m = Tv::TV) : mode(m)&#123;&#125;\t\tvoid onoff(Tv &amp;t)&#123;t.onoff();&#125;\t\tbool volup(Tv &amp;t)&#123;return t.volup();&#125;\t\tbool voldown(Tv &amp;t)&#123;return t.voldown();&#125;\t\tvoid chanup(Tv &amp;t)&#123;t.chanup();&#125;\t\tvoid chandown(Tv &amp;t)&#123;t.chandown();&#125;\t\tvoid set_channel(Tv &amp;t, int c)&#123;t.channel = c;&#125;\t\tvoid set_input(Tv &amp;t)&#123;t.set_input();&#125;&#125;;#endif\n\n\n\n\n\n\n上面程序存在的问题？\n\n存在的问题是循环依赖，解决方法是前向声明。\n\n循环依赖解释？\n\n类Tv在编译的时候会调用friend void Remote::set_channel(Tv &amp;t, int c);而此时不知道，Remote是什么也不知道其中的set_channel方法是什么。\n\n倘若将两个类交换顺序能否解决问题？\n\n#ifndef __TV_H__#define __TV_H__#include &lt;iostream&gt;using namespace std;class Tv;class Remote&#123;\tprivate:\t\tint mode;\tpublic:\t\tRemote(int m = Tv::TV) : mode(m)&#123;&#125;\t\tvoid onoff(Tv &amp;t)&#123;t.onoff();&#125;\t\tbool volup(Tv &amp;t)&#123;return t.volup();&#125;\t\tbool voldown(Tv &amp;t)&#123;return t.voldown();&#125;\t\tvoid chanup(Tv &amp;t)&#123;t.chanup();&#125;\t\tvoid chandown(Tv &amp;t)&#123;t.chandown();&#125;\t\tvoid set_channel(Tv &amp;t, int c)&#123;t.channel = c;&#125;\t\tvoid set_input(Tv &amp;t)&#123;t.set_input();&#125;&#125;;class Tv&#123;\tprivate:\t\tenum&#123;off, on&#125;;\t\tenum&#123;MinVal, MaxVal = 20&#125;;\t\tenum&#123;MinChan = 1, MaxChan = 100&#125;;\t\tenum&#123;TV, DVD&#125;;\t\tint state;\t\tint volume;\t\tint channel;\t\tint input;\tpublic:\t\tTv(int s = off) : state(s), volume(5), channel(2), input(TV)&#123;&#125;\t\tvoid onoff()&#123;state = (state == on) ? off : on;&#125;\t\tbool volup();\t\tbool voldown();\t\tvoid chanup();\t\tvoid chandown();\t\tvoid set_input()&#123;input = (input == TV) ? DVD : TV;&#125;\t\tvoid show_settings() const;\t\tfriend void Remote::set_channel(Tv &amp;t, int c);&#125;;#endif\n\n\n\n\n即使交换顺序并且加上class Tv声明能解决问题吗？\n\n答案是否定的因为Remote类中的构造函数 用到了  Tv::TV 即便前面声明了Tv是类，但是此时也无法知道Tv中又什么成员变量(即无法知道TV是什么)\n\n解决办法 将Tv类中的枚举类型在 Remote类中也来一份，并且使用Remote自己的枚举成员\n\n#ifndef __TV_H__#define __TV_H__#include &lt;iostream&gt;using namespace std;class Tv;class Remote&#123;\tprivate:\t\tint mode;\t\tenum&#123;off, on&#125;;\t\tenum&#123;MinVal, MaxVal = 20&#125;;\t\tenum&#123;MinChan = 1, MaxChan = 100&#125;;\t\tenum&#123;TV, DVD&#125;;\tpublic:\t\tRemote(int m = TV) : mode(m)&#123;&#125;    \tvoid onoff(Tv &amp;t)&#123;t.onoff();&#125;\t\tbool volup(Tv &amp;t)&#123;return t.volup();&#125;\t\tbool voldown(Tv &amp;t)&#123;return t.voldown();&#125;\t\tvoid chanup(Tv &amp;t)&#123;t.chanup();&#125;\t\tvoid chandown(Tv &amp;t)&#123;t.chandown();&#125;\t\tvoid set_channel(Tv &amp;t, int c)&#123;t.channel = c;&#125;\t\tvoid set_input(Tv &amp;t)&#123;t.set_input();&#125;&#125;;class Tv&#123;\tprivate:\t\tenum&#123;off, on&#125;;\t\tenum&#123;MinVal, MaxVal = 20&#125;;\t\tenum&#123;MinChan = 1, MaxChan = 100&#125;;\t\tenum&#123;TV, DVD&#125;;\t\tint state;\t\tint volume;\t\tint channel;\t\tint input;\tpublic:\t\tTv(int s = off) : state(s), volume(5), channel(2), input(TV)&#123;&#125;\t\tvoid onoff()&#123;state = (state == on) ? off : on;&#125;\t\tbool volup();\t\tbool voldown();\t\tvoid chanup();\t\tvoid chandown();\t\tvoid set_input()&#123;input = (input == TV) ? DVD : TV;&#125;\t\tvoid show_settings() const;\t\tfriend void Remote::set_channel(Tv &amp;t, int c);&#125;;#endif\n\n\n\n\n 上面这样写就没事了吗？\n\n答案是否定的，存在问题，类Remote中成员函数实现中，调用了Tv类的方法，而此时Tv类没有编译，所以会报错。正确做法是，将Remote中接口的实现定义在类外面也就是 类Tv的后面。如下\n#ifndef __TV_H__#define __TV_H__#include &lt;iostream&gt;using namespace std;class Tv;class Remote&#123;\tprivate:\t\tint mode;\t\tenum&#123;off, on&#125;;\t\tenum&#123;MinVal, MaxVal = 20&#125;;\t\tenum&#123;MinChan = 1, MaxChan = 100&#125;;\t\tenum&#123;TV, DVD&#125;;\tpublic:\t\tRemote(int m = TV) : mode(m)&#123;&#125;\t\tvoid onoff(Tv &amp;t);\t\tbool volup(Tv &amp;t);\t\tbool voldown(Tv &amp;t);\t\tvoid chanup(Tv &amp;t);\t\tvoid chandown(Tv &amp;t);\t\tvoid set_channel(Tv &amp;t, int c);\t\tvoid set_input(Tv &amp;t);&#125;;class Tv&#123;\tprivate:\t\tenum&#123;off, on&#125;;\t\tenum&#123;MinVal, MaxVal = 20&#125;;\t\tenum&#123;MinChan = 1, MaxChan = 100&#125;;\t\tenum&#123;TV, DVD&#125;;\t\tint state;\t\tint volume;\t\tint channel;\t\tint input;\tpublic:\t\tTv(int s = off) : state(s), volume(5), channel(2), input(TV)&#123;&#125;\t\tvoid onoff()&#123;state = (state == on) ? off : on;&#125;\t\tbool volup();\t\tbool voldown();\t\tvoid chanup();\t\tvoid chandown();\t\tvoid set_input()&#123;input = (input == TV) ? DVD : TV;&#125;\t\tvoid show_settings() const;\t\tfriend void Remote::set_channel(Tv &amp;t, int c);&#125;;inline void Remote::onoff(Tv &amp;t)&#123;t.onoff();&#125;inline bool Remote::volup(Tv &amp;t)&#123;return t.volup();&#125;inline bool Remote::voldown(Tv &amp;t)&#123;return t.voldown();&#125;inline void Remote::chanup(Tv &amp;t)&#123;t.chanup();&#125;inline void Remote::chandown(Tv &amp;t)&#123;t.chandown();&#125;inline void Remote::set_channel(Tv &amp;t, int c)&#123;t.channel = c;&#125;inline void Remote::set_input(Tv &amp;t)&#123;t.set_input();&#125;#endif\n\n\n\n\n\n\n总结：\n\n以上就是友元类，产生循环依赖的解决办法。思想来源c++primer plus 15章\n\n以上是Remote 对Tv 做出一些控制 ，用的方法是将Remote声明为Tv的友元，且由于只有其中一个方法调用了Tv的私有成员，其余都是调用公有接口，那为了封装的安全性，只将Remote中调用Tv类中私有成员的方法声明为友元即可。而实际有可能存在互为友元的情况，即遥控器对电视做出控制，电视并给一个反馈到遥控器，这样就要求两个类互相为友元。\n\n\n补充：\n\n共同友元 ！ 要使用友元的另一种情况是，函数需要访问两个类的私有数据。从逻辑上说，这样的函数是两个类的成员函数，但这是不可能的。做法就是共同友元。\n应用场景：\n有关类A是某可用编程的测量设备 ，B是某分析仪器，要求两者有共同的时钟，这样就可用声明两个友元函数，类A中将B 的成员函数声明为友元，类B中将A 的成员函数声明为友元，\n","categories":["编程"],"tags":["cpp"]},{"title":"博客源码的拉回与推送","url":"/2023/04/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E7%9A%84%E6%8B%89%E5%9B%9E%E4%B8%8E%E6%8E%A8%E9%80%81/","content":"克隆私有仓库源码到本地建一个文件夹\ngit init \ngit clone https://user:TOKEN@ghproxy.com/https://github.com/xxxx/xxxx\ngit clone https://user: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@ghproxy.com/https://github.com/bigflya/blog-source.git\n对文件夹授权 777 \n然后整理一下 ,修改该修改的文件\n然后 部署   npm run deploy\n上传源文件  文件文件夹中包括 mode_modules  scaffolds source themes config.yml package.json   package-lock.json  README.md\n我这里执行        git remote add origin https://github.com/bigflya/blog-source.git\n先将配置文件  config.yml的token 复制以下 然后将其改动如下格式\ngit remote set-url origin https://TOKEN@github.com/bigflya/blog-source.git\n执行 git initgit add .\ngit commit -m ‘addcomments’               # 单引号中的内容为我本次更新的内容说明\ngit branch -m mastergit remote add origin https://github.com/bigflya/blog-source.gitgit remote set-url origin https://TOKEN@github.com/bigflya/blog-source.git\ngit push origin +master\n"},{"title":"将运算符定义为成员函数或者非成员函数的准则","url":"/2023/09/13/%E5%B0%86%E8%BF%90%E7%AE%97%E7%AC%A6%E5%AE%9A%E4%B9%89%E4%B8%BA%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E6%88%96%E8%80%85%E9%9D%9E%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E7%9A%84%E5%87%86%E5%88%99/","content":"\n赋值(-)、下标([])、调用(())和成员访问箭头(-&gt;)运算符必须是成员。\n符合赋值运算符一般来说是成员、但并非必须、这一点与赋值运算符略有不同。\n改变对象状态的运算符或者与给定类型密切相关的运算符，如递增、递减和解引用运算符，通常应该是成员。\n具有对称性的运算符可以转换为任意一端的运算对象、例如算数、相等性、关系和位运算符等。因此他们通常应该是普通的非成员函数。\n\n","categories":["编程"],"tags":["c++ primer"]},{"title":"小于号运算符重载函数","url":"/2023/09/10/%E5%B0%8F%E4%BA%8E%E5%8F%B7%E8%BF%90%E7%AE%97%E7%AC%A6%E9%87%8D%E8%BD%BD%E5%87%BD%E6%95%B0/","content":"什么时候会调用小于号运算符重载函数？\n\n在C++中，小于号运算符（&lt;）的重载函数通常在需要比较两个自定义类型的值时被调用。例如，如果你定义了一个自定义的类或结构体，并希望能够使用小于号运算符来比较该类的对象，那么你需要重载小于号运算符。\n\n#include &lt;iostream&gt;class MyClass &#123;public:    int value;    MyClass(int val) : value(val) &#123;&#125;    // 重载小于号运算符    bool operator&lt;(const MyClass&amp; other) const &#123;        return value &lt; other.value;    &#125;&#125;;int main() &#123;    MyClass obj1(5);    MyClass obj2(10);    if (obj1 &lt; obj2) &#123;        std::cout &lt;&lt; &quot;obj1 is less than obj2&quot; &lt;&lt; std::endl;    &#125; else &#123;        std::cout &lt;&lt; &quot;obj1 is not less than obj2&quot; &lt;&lt; std::endl;    &#125;    return 0;&#125;\n\n在上述示例中，定义了一个名为MyClass的类，它包含一个整数值value。然后，重载了小于号运算符，使其能够根据value的值来比较两个MyClass对象。在main()函数中，创建了两个MyClass对象，并使用小于号运算符进行比较。当obj1的value小于obj2的value时，输出为”obj1 is less than obj2”。否则，输出为”obj1 is not less than obj2”。\n","categories":["编程"],"tags":["c++ primer"]},{"title":"拷贝赋值运算符调用拷贝构造函数","url":"/2024/01/05/%E6%8B%B7%E8%B4%9D%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97%E7%AC%A6%E8%B0%83%E7%94%A8%E6%8B%B7%E8%B4%9D%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/","content":"在C++中，拷贝赋值运算符和拷贝构造函数是两种不同的操作，用于对象的复制。了解这两者之间的区别以及它们的正确用法对于避免潜在的问题至关重要。\n一、拷贝赋值运算符拷贝赋值运算符（operator=）用于将一个对象的内容复制到另一个已经存在的对象中。\nclass MyClass &#123;public:    MyClass&amp; operator=(const MyClass&amp; other) &#123;        if (this == &amp;other) return *this;  // 处理自赋值        // 释放当前对象的资源（如果有的话）        // 复制other对象的资源        return *this;    &#125;&#125;;\n\n\n\n\n\n二、拷贝构造函数拷贝构造函数用于创建一个新对象，并用已有对象初始化它。\nclass MyClass &#123;public:    MyClass(const MyClass&amp; other) &#123;        // 用other对象初始化新对象的资源    &#125;&#125;;\n\n\n\n\n\n\n\n\n\n三、经验令拷贝赋值操作符调用拷贝构造函数是不合理的，因为这就像试图构造一个已经存在的对象。\n#include &lt;iostream&gt;#include &lt;algorithm&gt;class MyClass &#123;private:    int* data;    size_t size;public:    // 默认构造函数    MyClass(size_t s = 0) : size(s), data(s ? new int[s] : nullptr) &#123;        std::cout &lt;&lt; &quot;Default constructor&quot; &lt;&lt; std::endl;    &#125;    // 拷贝构造函数    MyClass(const MyClass&amp; other) : size(other.size), data(other.size ? new int[other.size] : nullptr) &#123;        std::copy(other.data, other.data + other.size, data);        std::cout &lt;&lt; &quot;Copy constructor&quot; &lt;&lt; std::endl;    &#125;    // 错误的拷贝赋值运算符实现    MyClass&amp; operator=(const MyClass&amp; other) &#123;        if (this != &amp;other) &#123;            // 错误地调用拷贝构造函数            MyClass temp(other);//给新对象调用的是构造函数            std::swap(size, temp.size);            std::swap(data, temp.data);        &#125;        std::cout &lt;&lt; &quot;Copy assignment operator&quot; &lt;&lt; std::endl;        return *this;    &#125;            //正确的实现    MyClass&amp; operator=(const MyClass&amp; other) &#123;        if (this == &amp;other) return *this;  // 处理自赋值        delete[] data;  // 释放当前对象的资源        data = new int[other.size];  // 分配新资源并复制        std::copy(other.data, other.data + other.size, data);        return *this;    &#125;        // 析构函数    ~MyClass() &#123;        delete[] data;    &#125;&#125;;int main() &#123;    MyClass a(5);         // 调用默认构造函数    MyClass b;            // 调用默认构造函数    b = a;                // 调用拷贝赋值运算符（错误实现）    return 0;&#125;\n\n\n\n\n上述错误的拷贝赋值运算符分析\n\n1 错误的实现：\n资源管理：在处理非自赋值情况时，它创建了一个临时对象 temp，然后交换了当前对象和临时对象的资源。但是，在自赋值情况下，这种实现会导致当前对象的资源被删除，然后尝试使用被删除的资源，这会导致未定义行为。\n\n2 正确的实现：\n资源管理： 对于非自赋值情况，该实现删除当前对象的资源，然后重新分配内存，并复制来自 other 对象的数据。这确保了当前对象与 other 对象的数据相同，但是不共享内存。这样的实现在处理自赋值和非自赋值情况时都是安全的。\n\n3总结在错误的实现中，自赋值情况下会导致当前对象的资源被删除，是因为它创建了一个临时对象 temp，然后交换了当前对象和临时对象的资源。具体地说，以下是发生的情况：\n\n当发生自赋值时，拷贝赋值运算符首先创建了一个临时对象 temp，该临时对象的数据与 other 对象相同。\n然后，拷贝赋值运算符尝试交换当前对象和临时对象的资源。这意味着当前对象 this 的资源会被释放，而临时对象 temp 的资源会成为当前对象的资源。\n但是，在自赋值的情况下，当前对象和临时对象都是同一个对象，即它们的地址相同。因此，交换操作实际上是将当前对象的资源指针（data）与自己交换，导致了问题。\n由于临时对象 temp 和当前对象 this 是同一个对象，因此在交换后，当前对象的资源指针 data 实际上指向了一个已经被释放的内存空间，这会导致未定义行为，通常是内存错误、段错误或其他程序崩溃。\n\n因此，这种错误的实现在自赋值情况下会导致当前对象的资源被删除，并尝试使用被删除的资源，从而导致了未定义行为。\n","tags":["cpp"]},{"title":"拷贝赋值运算符重载函数和拷贝构造函数的区别","url":"/2023/09/09/%E6%8B%B7%E8%B4%9D%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97%E7%AC%A6%E9%87%8D%E8%BD%BD%E5%87%BD%E6%95%B0%E5%92%8C%E6%8B%B7%E8%B4%9D%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"\n区别：\n\n拷贝构造函数使用传入对象的值生成一个新的对象的实例，而拷贝赋值运算符是将对象的值复制给一个已经存在的实例。调用的是拷贝构造函数还是赋值运算符重载函数，主要是看是否有新的对象实例产生。 如果产生了新的对象实例，那调用的是拷贝构造函数，如果没有新的对象的实例产生那调用的是拷贝赋值运算符重载函数。\n\n拷贝构造函数调用的主要场景：\n\n\n对象作为函数的参数，以传递的方式传给函数；\n对象作为函数的返回值，以值的方式从函数返回\n使用一个对象给另一个对象初始化。\n\n\n为什么要有拷贝构造函数，他和构造函数有什么区别？\n\n拷贝构造函数本身也是构造函数，只不过其传入的形参是自身类型的对象的引用。如果类里面没有指针成员（该指针成员指向动态申请的内存空间），是没有必要编写拷贝构造函数的。举个例子： 如果有一个类CObj,它已经产生了一个对象ObjA,现在想要创建另外一个对象ObjB,如果程序中使用ObjB&#x3D;ObjA,也就是说直接使用ObjA的数据给ObjB赋值。对于一般的类，这样操作没有问题，但如果CObj里面有个成员char *pStr,用来存放动态申请的字符串的地址，那么此时如果使用 ** ObjB&#x3D;ObjA **那么就会出现ObjA.pStr与ObjB.pStr指向同一块内存空间，这样就会导致这块空间由谁来释放的问题，如果释放两次就会出现段错误，使用拷贝构造函数就能解决此问题，因为拷贝构造函数是new出一块新的动态内存空间ObjB.pStr 来存放ObjA.pStr中的内容。所以说这里的“拷贝”拷贝的是动态申请的空间的内容，而不是类本身的数据，对于c++内置类型 int char double 等类型会直接拷贝，而对于动态内存开辟的类型要执行拷贝构造函数。\n\n拷贝构造函数的参数是自身对象类型的引用，而不是对象指针，或者值 的原因是什么?\n\n如果不是引用 ，那么在传入参数的时候是 以pass-by-value 的方式进行值传递的，那么就是触发拷贝构造函数的调用条件，执行拷贝构造函数，因为拷贝构造函数是值传递，从而造成无穷递归的调用拷贝构造函数，直到栈溢出或者程序崩溃。\n","categories":["编程"],"tags":["c++ primer"]},{"title":"机器视觉检测系统","url":"/2023/04/22/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/","content":"一、视觉检测系统概述1、系统组成\n1.1光源\n光源的功能是为目标照明， 便于相机成像。  \n光源可以是日光和人造光源。\n日光只有在白天日光能够辐射的地方存在， 并且在辐射的强度、 角度方面具有随机性， 通常不能满足相机成像对于目标照明的需求。\n人造光源包括白炽灯、 日光灯、 卤素灯等， 但是， 用在机器视觉检测系统照明用的光源几乎都是LED光源。\n根据目标成像的不同需求， LED光源有不同的结构、 尺寸、 颜色等。\n\n1.2镜头\n镜头的功能是将目标景物汇聚到相机的图像传感器靶面。  \n根据目标成像的不同需求， 镜头有工业镜头、 远心镜头、 内窥镜等类。 \n每一种镜头有不同的规格， 包括焦距、 最小工作距离、 成像圆尺寸、光圈范围等。\n\n1.3相机\n相机的功能是将镜头汇聚的影像转换成数字图像。  \n根据目标成像的不同需求， 相机有线阵相机、 面阵相机、 3D相机、 接触式图像传感器等种类。\n每一种相机有不同的规格， 包括图像传感器靶面尺寸、 像元尺寸、 帧率、 行频、 曝光时间、光谱范围、 图像尺寸、 颜色、 数据传输接口种类等。\n\n1.4图像抓拍图像抓拍的功能主要包括以下两部分：\n\n在目标到来的时候， 启动光源照明， 触发相机拍摄目标图像。  \n在相机拍摄结束的时候， 关闭光源照明。\n\n1.5图像处理图像处理的功能包括以下三个部分：\n\n针对相机采集的目标图像，标记目标的轮廓。\n根据标记的目标轮廓， 计算目标的特征参数， 主要包括形状、 尺寸、 纹理、 颜色等。\n根据目标的特征参数， 确定目标的属性， 主要包括表面划痕、 凹坑、 凸起、 麻点、 污渍、 气泡、 裂纹等  。\n\n图像处理系统主要包括以下四个部分：\n\n图像处理硬件， 主要指的是计算机系统， 包括CPU、 GPU、 内存、 主板等。  \n图像处理软件， 主要指的是图像采集软件、 图像处理软件、 人机交互界面、 控制软件（光源控制、 相机抓拍控制、 物料分选控制等） 。\n图像处理语言， 主要采用C++、 C#等。  \n图像处理算法， 主要指的是实现图像处理功能的方法。 例如： Halcon机器视觉算法库。\n\n1.6执行机构执行机构的功能是，根据图像处理的输出结果，在生产线上完成如下任务：\n\n筛选不合格产品， 不需要区分缺陷的类型 。\n分选不合格产品， 需要区分缺陷的类型。 例如： 划伤， 压痕等。 \n分选产品等级。 例如： 优品， 良品， 合格品， 不合格品。\n\n2、机器视觉与人类视觉的比较2.1观察速度高速运动图像，例如：\n\n生产线的传输速度可以达到每秒1-2米， 产品质量监测。\n运动员百米赛跑的速度可以达到每秒10米， 成绩排名。\n\n低速运动图像， 例如：  \n\n植物生长过程监测。\n\n间歇运动图像， 例如 ：\n\n水坝决口监测、 山体滑坡监测。\n\n2.2空间分辨能力这里展示出电子显微镜、光学显微镜、人眼的空间分辨率：\n\n电子显微镜的空间分辨力为0.2nm。  \n光学显微镜的空间分辨力为0.2um， 血细胞尺寸6-9.5um。  \n人眼的空间分辨力为0.1mm。\n\n\n思考：是不是分辨率越高越好？   \n\n答：并不是，分辨率越高，意味着对硬件的要求更高，比如处理器的处理速度，镜头的畸变参数和制造工艺、信号调理电路的可靠性（会不会丢数据） 等，选择相机分辨能力的标准主要的原则是在能满足对象检测要求的条件下留一定的裕量即可，而不是一味的追求高参数。\n2.3 亮度分辨能力（色深）\n如果将亮度转化为图像中的256个灰度级的话， 人类视觉通常只能够分辨十几个灰度级。  \n而机器视觉目前至少可以将亮度转化为4096个灰度级， 并能够清楚地分辨每一个灰度级 。\n\n2.4光谱范围机器视觉除了在可见光环境下观测景物， 还可以在非可见光环境下观测景物， 并实现自动检测， 主要应用如下：\n\n利用红外成像技术， 在医学方面实现人体成像， 获取人体体表温度分布， 用于疾病诊断。 在军事上用于夜间观察敌人的行踪。 在工业上用于观测钢水温度分布等。 例如： 热成像仪。\n利用X光成像技术， 在医学方面实现人体内脏器官、 骨骼成像， 用于疾病诊断。 在安检方面， 用于包括危险品的检查。 在产品质量检测方面， 用于轮胎内部帘线的缺陷检测。\n利用超声波成像技术， 在医学方面实现人体内脏器官成像， 用于疾病诊断。 在工业应用方面， 用于工件内部缺陷检测。\n利用微波成像技术， 在遥感方面， 通过卫星上安装的微波成像仪实现地球表面和云层的成像， 用于农作物受灾面积评估、 洪水受灾面积评估、 军事设施侦查、 测绘制图、 天气预报等。\n\n\n\n人类视觉只能在可见光条件下观测景物  。\n\n\n2.5 观测距离\n今天的技术已经能够将相机发送到包括月球在内的任何可以到达的星球， 并将相机拍摄的图像传回到月球。 这意味着， 机器视觉的工作距离没有限制。\n而人类视觉只能够观测有限距离的目标。\n\n2.6 观测环境\n机器视觉可以工作在对人体有害的环境。  \n主要包括毒气环境， 易爆环境， 粉尘环境， 有害辐射环境， 高温或者低温环境， 火灾环境等。\n在上述环境下， 可以利用机器视觉代替人类视觉。\n典型应用于机器人视觉。\n\n2.7 观测结果量化\n人类视觉只能定性描述所观察目标的属性， 例如： 形状、 大小等。 \n机器视觉能够定量描述所观测目标的属性。\n\n2.8 观测结果可靠性​\t\t正常情况下， 人类视觉能够定性描述所观测目标的属性。但是， 由于情绪、 疲劳、 责任心等因素， 可能导致描述结果错误， 将不合格产品判别为合格产品， 这通常称为漏检。 例如： 将手机外壳上的划痕当做合格品。\n​\t\t机器视觉按照规则处理图像， 可以避免人为因素的影响， 检测结果的可靠性远远高于人类视觉。\n3、机器视觉与非电量电测系统的比较机器视觉检测系统可以理解为是非电量电测系统的一种。 例如：  \n\n相机的核心是图像传感器。 对于可见光相机， 图像传感器的核心是光电传感器， 而光电传感器则是非电量电测系统中众多传感器中的一种。  \n超声波图像传感器的核心是压电晶体传感器， 而压电晶体传感器也是非电量电测系统中的一种传感器。\n\n与非电量电测系统比较， 机器视觉系统具有如下一些特点：\n\n关于数据类型， 如果非电量电测系统描述的对象为一维数据的话， 机器视觉检测系统描述的对象为二维数据， 或者三维数据。\n关于数据量， 图像传感器实际上是光电传感器阵列， 可以由数千万个光电传感器所组成。 例如： 大恒图像MER-2000-19U3M/C-L面阵相机， 分辨率为2千万像素， 或用字节表示为20Mb。 每个像素为一个字节， 每个字节为8位或者12位二级制数。\n关于数据传输速率， 工业生产线的在线检测需要实时性。例如： 大恒图像MER-2000-19U3M/C-L面阵相机， 分辨率为2千万个像素， 帧率为19.6帧/秒，则相机传输速率为20Mb× 19.6fps=392Mb/s， 即每秒传输大约4亿个字节的数据。这需要特殊的数据传输方式， 例如千兆网、 USB3.0、 cameralink等。\n关于器件的工作频率：以内存为例， DDR4型内存的主流主频2400MHz， 最高可达4000MHz。以CPU为例， 最高主频可达3.0GHz。\n一体化 （集成化）：指的是相机、 镜头、 光源、 图像处理器封装在一个壳体内， 输出的是图像处理结果。\n\n4、关于机器视觉编程语言\n在图像处理方面， 有图像处理算法库， 或者机器视觉算法库。  \n开源软件主要是Intel公司的Open CV。  \n商用软件主要是德国MVtec公司的HALCON， 美国COGNEX公司的Vision Pro等。 图像处理算法库的应用大大缩减的开发周期， 这是绝大多数机器视觉公司采用的方案。\n特别是这些商用软件可以直接驱动目前国际上流行的工业相机用来采集图像， 并且自带人机交互界面。 对于一些简单的应用场合， 不需要自己编写人机交互界面。\n\n\n二、LED光源1、能级与能带学习目的： 掌握半导体的概念， LED的材料是半导体。  \n学习内容：\n\n原子的能级；\n固体的能带；\n\n1.1原子的能级（基本概念）\n原子核外电子只能在特定的、 分立的轨道上运动， 各个轨道上的电子具有分立的能量， 这些能量值即为能级。\n在离原子核最近的地方旋转的电子的能级最低， 如图E1的能级最低。\n\n\n 原子结构图\n\n\n原子能级图\n\n1.1.1 原子的定态、 基态、 激发态\n在量子力学中， 定态是微观粒子所处状态中的一种类型的状态。 处于定态的微观粒子在空间各处出现的几率不随时间变化， 而且具有确定的能量。\n在正常状态下， 电子处于最低能级， 电子在离核最近的轨道上运动的定态称为基态。 处于基态的电子称为基态电子。\n电子吸收能量后从基态跃迁到较高能级， 电子在较远的轨道上运动的定态称为激发态。 高于基态的状态依次称为第一、 第二激发态， 处于激发态的电子称为激发电子。\n\n1.1.2 原子的能级跃迁\n低能级的电子获取两个能级差的能量（电场、 热或光） 后可以跃迁至高能级。\n高能级的电子短暂停留之后， 再次回落到低能级并释放两个能级差的能量（热或光） 。\n两个能级间的能量差随着远离原子核而减小， 因此， 激发电子跃迁的能量随之减小。\n当电子被激发至最高能级时， 即能量E=0eV， 将不受原子核引力的束缚。\n\n1.2 固体的能带1.2.1 能带的形成\n能带图\n\n\n能带理论是用量子力学的方法研究固体内部电子运动的理论。  \n在孤立原子中， 每个轨道上的电子都有一定的能级。\n固体是由原子排列组成， 原子之间的电子受邻近原子核的作用， 每个原子轨道上的电子能级被分裂成能级相近的轨道能带。\n能级越高， 能带越宽。  \n能带之间的空间称为带隙或能隙。 \n电子不能存在于带隙中。\n\n1.2.2 能带的类型价带：\n\n原子模型图\n\n\n价电子， 原子最外层轨道上的电子。  \n价带由价电子组成， 为原子最外层电子轨道， 也是电子的最高能带。\n价带电子数为1到8个之间。\n当价带电子为8个时， 表示原子达到稳定状态。\n\n导带 ：\n\n价带导带能隙的相对位置图\n\n\n导带， 不受原子核引力的电子组成的能带， 也是电子的最高能带。  \n价带能量低于导带。 \n价带中的电子被热或者光激发时， 可以跃入导带。\n\n1.2.3 能带的重要性\n如果价带与导带之间存在较多的重叠， 意味着材料中存在大量的自由电子， 因此，该材料为良好的==导电体==。\n如果价带与导带之间存在较多的间隙， 意味着导带缺乏电子， 从而使材料无法导电， 因此，该材料为==绝缘体==。\n如果价带与导带之间存在轻微的分离， 通过提供少量的能量就可以使价带中的电子占据导带。 这意味着， 尽管这些材料通常是绝缘体， 但通过外部激励， 它们可以转化为导体。 因此这些材料被称为==半导体==。\n\n1.2.4 不同材料的能带\n导体：\n\n导体的价带和导带之间无带隙， 存在重叠。 \n室温下可用的自由电子数量很大。 \n特点： 导电性能好， 具有很高的导电率。 \n实例： 导体主要指金属， 例如金、 铝、 银、 铜等。\n\n半导体：\n\n半导体的价带与导带之间存在较小的带隙。\n锗的带隙为 0.72eV  ；硅的带隙为 1.1eV  ；\n价带电子在较小的外部激发下可以跃迁到导带。\n\n绝缘体：\n\n绝缘体的价带与导带之间存在很大的带隙。 \n金刚石的带隙为 6-7eV。 \n难以通过外部激发使价带中的电子跃迁到导带。 \n特点： 不导电， 具有极低的导电率。 \n实例： 玻璃、 橡胶等。\n\n1.2.5 固体能带小结\n导电体， 价带与导带之间无带隙；\n半导体， 价带与导带之间存在较小的带隙； ==LED为半导体器件。== \n绝缘体， 价带与导带之间存在较大的带隙。\n\n2、 辐射吸收、 自发辐射、 受激辐射\n学习目的： 掌握半导体自发辐射的概念， LED的发光机理是自发辐射。\n\n学习内容：\n\n​\t光子的概念  \n​\t辐射或光的吸收  \n​    自发辐射\n​    受激辐射\n\n\n\n2.1光子\n光子（photon）,组成光束的基本粒子，光子的能量为 E =hv  ;其中h为普朗克常量，v为光的频率\n光子的概念由爱因斯坦提出。\n光子静止质量为零。\n光子以光速运动，具有能量、动量、质量。\n\n2.2辐射或光的吸收​\t\n​\t\n\n吸收光子能量的过程称为辐射吸收。  \n电子吸收足够的光子能量， 从较低的能级跳到较高的能级。\n当电子吸收的能量等于两个能级的能量之差时， 电子从较低能级跃迁到较高能级。\n处于较高能级的电子称为激发电子。\n\n2.3 自发辐射概念：被激发的电子在短时间停留之后， 以光的形式释放能量， 回到较低能级或基态， 这个过程称为自发辐射。\n特性：自发辐射发射的光子并不完全沿着入射光子的方向流动， 具有随机性。自发辐射发射的光子能量与材料的能隙成正比。  \n分类：\n\n初始能量由光子提供， 称为光致发光， 例如黑暗中发光的材料。\n初始能量由化学反应提供， 称为化学发光， 例如发光棒。\n初始能量由电压提供， 称为电致发光， 例如LED。\n初始能量由声波引起， 称为声致发光。\n初始能量由加速电子击中目标， 称为阴极发光。\n初始能量由活的有机体引入， 如萤火虫， 称为生物发光。\n\n2.4 受激辐射概念：处于激发态的电子被激发而发射光子， 同时下降到基态或较低能态的过程称为受激发射。\n特性：\n\n受激辐射不是一个自然过程， 而是一个人工过程。  \n入射光子迫使受激电子发射光子， 并落入较低能态或基态。\n入射光子的能量必须等于两个电子壳层之间的能量差。\n在受激发射过程中， 每个入射光子产生两个光子。\n在受激发射过程中发射的光子将沿着入射光子的相同方向传播。\n产生光的方法很多， 但受激发射是已知的唯一产生相干光（具有相同频率的光子束） 的方法。\n\n3、PN结的发光原理学习目的：掌握PN结的发光原理。\n学习内容：本征半导体、N型半导体、P型半导体、半导体的PN结、半导体的带隙、PN结的发光原理。\n3.1 本征半导体概念：本征半导体指的是完全不含杂质且无晶格缺陷的纯净半导体。  \n特性：\n\n在本征半导体中掺入某些微量元素作为杂质， 可使半导体的导电性发生显著变化。 掺入的杂质主要是三价或五价元素。\n掺入杂质的本征半导体称为杂质半导体 。\n最常用的半导体基础材料是硅， 硅原子的最外层有四个价电子。\n原子最外层电子数为8的时候， 性能最稳定， 这也是电子饱和状态。\n硅原子的最外层价电子与邻近的硅原子共享， 形成了八个电子的完整轨道， 称为共价键。\n\n\n硅原子的结构\n\n3.2 N型半导体构成：在本征半导体硅中掺入五价原子， 与四个硅原子形成共价键， 留下一个自由电子， 因此，五价原子称为施主（Donor）。\n特性：\n\n在室温下，原子中的外层电子在热激发下也会脱离壳层，成为自由电子，从而形成空穴，但是很快被其它自由电子填充。\n由于掺杂半导体中的自由电子数量远远大于空穴的数量， 称这种掺杂半导体为N型半导体（Negative, N）。\n五价原子主要包括： 砷( As )、 锑（Sb） 或磷（P） 等。  \n以锑原子作为掺杂原子为例，最外电子层有5个电子。 \n在硅原子中掺杂锑原子之后， 1个锑原子与4个硅原子形成共价键，并贡献1个电子进入导带成为自由电子。\n\n\n硅原子Si中掺杂锑原子Sb\n\n3.3 P型半导体构成：在本征半导体硅中掺入三价原子， 与四个硅原子形成共价键， 留下一个空穴， 需要电子填充才能够保持共价键稳定，因此，三价原子称为受主（Acceptor）。\n特性：\n\n在硅半导体中掺入三价原子后， 存在许多空穴， 其空穴的数量与掺杂三价原子数量有关。 \n由于掺入三价原子之后， 空穴称为半导体中的多数载流子， 空穴呈现正电子特征， 因此称这种掺杂半导体为P型半导体（Positive, P）。\n三价原子主要包括：铝（Al）、硼（B）或镓（Ga）等。\n以硼原子作为掺杂原子为例，最外电子层有3个电子。\n在硅原子中掺杂硼原子之后， 1个硼原子与4个硅原子形成共价键， 并留下1个空穴。\n\n\n硅原子Si中掺杂硼原子B\n\n3.4 半导体的PN结\nN区| PN结 | P区\n\n构成：在硅材料中掺入三价原子形成P型区域， 掺入五价原子形成N型区域。在P型区域和N型区域的交界面，称为PN结。\n特性：\n\nN区中的多数载流子电子向P区扩散， 在PN结的P区一侧形成较高浓度的电子， 在PN结的N区一侧失去电子形成较高浓度的空穴， 形成内部电场。\n内部电场阻止电子从N区域向P区域进一步的扩散。\n当扩散终止， 在PN结形成势垒区， 或称耗尽层。\n\n内部电场的电位差（零偏结电压  ）:\n\nVT为室温下26mV的热电压\nND为N区域掺杂五价原子的浓度 \nNA为P区域掺杂三价原子的浓度 \nnj为半导体中本征原子的浓度\n\n通常在室温下：硅耗尽层的结电压约为 0.6-0.7 伏 ;锗耗尽层的结电压约为0.3-0.35 伏。  \n3.5 半导体的带隙\n导带中的最小能量态和价带中的最大能量态在布里渊区分别用一定的晶体动量（k矢量）来表征。\n半导体的直接带隙 :\n\n导带最小值与价带最大值在波矢k空间中处于同一位置，如图k=0。\n被激发的价带电子垂直跃迁到导带，只需要吸收能量， 动量不变。\n导带电子瞬间停留后回落到价带，动量也不变，并直接发出光子。\n直接带隙半导体的最佳例子是砷化镓GaAs、 砷化铟InAs、 锑化铟InSb、 氮化镓GaN、氮化铟InN、 氧化锌ZnO、 硒化镉CdSe、 硫化锌ZnS。\n\n​\t\t\t结论： 直接带隙半导体可以作为发光器件的材料。\n半导体的间接带隙:\n\n导带最小值和价带最大值在波矢k空间中处于不同位置。\n被激发的价带电子在跃迁过程中将能量释放给晶格，转化为声子，变成热能释放掉。\n间接带隙半导体的最佳例子是硅Si， 锗Ge， 碳C（金刚石），磷化镓GaP。\n\n​\t\t\t结论： 间接带隙半导体不能作为发光器件的材料。\n3.6 PN结的发光原理\nPN结发光原理图\n\n\n如果在PN结外施加一个电压，使得在PN结内所形成的电场与PN结势垒电场方向相反， 从而使内部电子扩散平衡被打破，电子将继续扩散。\n电子从导带回落到价带，必须要耗散一部分能量，这种能量以光和热的形式散发。\n基于硅衬底的PN结， 属于间接带隙半导体， 回落电子通过发热来耗散能量。 \n基于磷砷化镓(GaAsP)或磷化镓(GaP)衬底的PN结，属于直接带隙半导体，回落电子通过发射光子来耗散能量。\n\n​\t\t\t结论：直接带隙半导体材料是PN结发光的必要条件。  \n4、 LED发光二极管学习目的：了解LED芯片结构和LED结构，掌握LED的指向性和颜色。\n学习内容：GaN基材料；LED芯片结构；LED结构；LED的指向性； LED的颜色； 白色LED；LED的供电。\n4.1 GaN基材料氮化镓GaN基材料，属第三代半导体材料，具有禁带宽度大、热导率高、耐高温、 抗辐射、耐酸碱、 高强度和高硬度等特性，是现在世界上人们最感兴趣的半导体材料之一。GaN基材料在高亮度蓝、绿、紫和白光二极管，蓝、紫色激光器以及抗辐射、高温大功率微波器件等领域有着广泛的应用潜力和良好的市场前景。\nGaN基材料的衍生主要包括GaN 及其与氮化铟InN、氮化铝AlN 的合金，其禁带宽度覆盖整个可见光及紫外光谱范围，使得基于GaN基材料的LED 成为主流。\n4.2 LED芯片结构\n蓝光LED芯片结构示意图， 1993年\n\n蓝光LED芯片基本组成：p-氮化镓GaN层、有源层、 n-氮化镓GaN层、成核层、衬底\n4.2.1 衬底功能LED芯片是在衬底的基础上，通过外延生长形成的。\n\n\n衬底是外延层生长的基板。\n衬底起到支撑和固定外延层的作用。\n衬底与外延层的特性配合要求严格， 直接影响外延层的生长乃至芯片的品质。\n衬底材料主要有蓝宝石α-Al2O3、硅Si、碳化硅SiC，较常用的是蓝宝石。\n蓝宝石衬底 Sapphire Substrate\n\n4.2.2 衬底材料蓝宝石Al2O3，最早用于GaN外延的衬底材料、工艺最成熟。缺点是晶格失配导致位错密度高，大功率LED存在散热问题。蓝宝石占据了*90%*以上的衬底市场份额， 是目前市场上的主流技术路线。\n碳化硅SiC衬底，导热性良好，且其与GaN间的晶格失配和热失配也较小，非常适合于制造高温、高频、大功率电子器。SiC衬底的价格昂贵， 因其性能优异，占据着高端市场。  \n硅Si衬底，生长工艺成熟、导致成本低，导电性和导热性好。缺点：在Si衬底上制备GaN单晶薄膜质量不如蓝宝石，以此制造高质量LED面临许多难题。剑桥大学C. J. Humphreys教授是国际上Si基LED器件研究的先驱之一。\n4.2.3 成核层成核层是用来阻断来自衬底的缺陷沿着生长方向向上传播，从而提高后续生长的结晶质量。因此，成核层也称缓冲层Buffer Layer。\n\n成核层生长过程金属有机化学气相沉积法MOCVD\n\n成核层是在衬底表面生长而成，材料是氮化镓GaN；厚度在100nm左右；温度约为550° C。\n4.2.4 n-GaN层\nn-GaN 层有如下作用：\n\n与p-GaN组成PN结外层，并以此形成引出线；\n起到缓冲层的作用，提高后续生长质量；\n向有源区提供充足的电子；\nn-GaN层掺入的杂质为Si  ，厚度约为1-2 um ，生长温度约为1050° C\n\n4.2.5有源层\n有源层是辐射光子的区域。是氮化铟镓InGaN/氮化铝镓AlGaN双异质结。\n较窄的带隙材料InGaN被两个较宽的带隙材料AlGaN所夹，形成量子阱。\n双异质结构设计有助于最大限度地提高LED器件的发光效率。  \n异质结由两层以上不同的半导体材料薄膜依次沉积在同一基座上形成\n这些材料具有不同的能带隙。异质结构的二极管特性非常接近理想二极管。调节各个材料层的厚度和能带隙， 能够改善LED性能。\n\n4.2.6 p-GaN层p-GaN层有如下作用：\n\n与n-GaN层组成PN结外层， 并以此形成引出线；  \n向有源层提供空穴。\n\nn-GaN层掺杂技术比较简单，主要掺杂Si，由于存在氮空位, 使得N型本底载流子浓度范围较高。p-GaN层要实现对应于n-GaN层的高浓度掺杂非常困难。\n4.3 LED结构4.3.1 圆顶型LED\n圆顶型LED结构示意图\n\nLED芯片固定在LED阴极的一个小反射腔（Reflective cavity）中。LED芯片的阳极通过连接线（Bond wire）连接到LED的阳极。圆顶形壳体由塑料或环氧树脂制成，将所有部件固定在一起。LED芯片发出的光通过反射腔， 反射到LED的上半部分，通过圆顶内腔聚焦， 并通过壳体辐射到LED的前方。\n\n圆顶型LED出光分布图\n\n如上图所示，左上结构图；右上光照图片；左下亮度径向分布；右下亮度三维分布。\n结论：在中心出光区域之外还有一个环形出光区域， 其亮度较弱。\n4.3.2 贴片型\n贴片型LED结构示意图\n\n贴片式（surface mounted device， SMD）该结构直接粘贴在印刷线路板上。外壳可以作为散热片。结构紧凑。荧光层 Phosphor layer。\n4.3.3 COB型\n板上芯片型LED结构示意图\n\n板上芯片（chip on board， COB）用热粘接剂直接连接LED芯片到印刷电路板上。由于半导体和电路板之间直接接触， 因此比使用贴片式LED的电路板可以更好地耗散功耗。\n4.3.4 三种类型比较\n如上图所示，在10×10mm线路板上可以布置LED的数量比较。圆顶型LED： 9个贴片型LED：40个板上芯片型LED：342个  。\n4.4 LED的指向性下图表示普通LED光出射强度分布。指向性指的是LED光出射角度。𝒑𝒆表示光出射强度峰值对应的角度；\n\n下图给出了日本日亚化学工业株式会社（NiChia） 生产的NF2W757HT-F1型贴片式LED光出射强度分布与指向角的关系， 可以看出\n\n4.5 LED的颜色\nLED发出光的颜色是由波长决定的。\n光的波长取决于PN结处半导体材料的带隙宽度。\n带隙的宽度与复合材料的化合物有关。\n光的强度取决于通过二极管施加的功率。\n\n\n4.6 白色LEDLED不能直接发出白光， 而是通过某些技术产生白光， 主要技术有以下三种：波长转换、颜色混合、同质外延硒化锌。\n4.6.1 波长转换（1）蓝色LED和黄色荧光粉：  \nLED发出蓝色辐射激发黄色荧光粉。蓝光和黄光的混合呈现出近似的白光。这种方法是产生白光最便宜的方法。\n\n\n（a） 传统的球冠型涂层结构 （b） 平面保形荧光粉层结构\n（c） 悬空荧光粉涂层结构 （d） 自适应荧光粉涂层结构 \n\n（2）蓝色LED和多色荧光粉：\nLED发出蓝色辐射激发多种颜色荧光粉。蓝光和多种颜色的光混合呈现出近似的白光， 效果优于前一种。成本偏高。\n（3）紫外LED和RGB荧光粉：\nLED发出紫外光。紫外光激发红色、 绿色、 蓝色荧光粉发出红光、 绿光和蓝光。红光、 绿光和蓝光的混合呈现近似白光， 效果优于前两种。\n（3）蓝色LED和量子点  ：\nLED发出蓝光。蓝光激发LED顶部的量子点产生白光。 量子点的材料为镉或硒。其光谱与紫光激发RGB荧光粉的光谱近似。\n4.6.2 彩色LED混合将发出红光、绿光和蓝光的LED装在一个壳体内，通过调节每个LED发出光的强度， 来获得混合色。也可以采用红光、绿光、蓝光和黄光进行混合。\n4.6.3同质外延硒化锌通过在硒化锌（ZnSe） 衬底上生长蓝色LED外延层而产生。在有源区发出483nm的蓝光。在衬底发出595nm的黄光。蓝光和黄光合成为白光。\n4.7 LED的供电普通硅或锗二极管的管压降差异性不大， 而LED的管压降差异很大； LED的工作电流差异性很大。 LED正向压降VF取决于半导体化合物和正向偏压LED电流。 准确的电压降当然取决于制造商， 因为使用了不同的掺杂材料和波长。\nLED不可以直接与电源连接， 必须通过串联一个电阻， 以免因过流而烧坏。串联的LED必须统一规格，以确保发光亮度一致。通过LED的电流不允许超过额定电流。\n\n如上图所示PWM驱动是目前调整LED光源亮度的主要方式。调整光源亮度的设备称为光源控制器。\n5 、光源相关术语5.1 黑体概念：黑体是一个理想化的物体， 能够吸收全部电磁辐射， 没有反射和透射。  黑体对于任何波长的电磁波的吸收系数为1， 透射系数为0。  \n普朗克黑体电磁波辐射定律， 黑体辐射率与波长的关系为：\nk： 波尔茨曼常数， 焦耳/开尔文（J/K）  \nT： 黑体温度， 开尔文（K）  \nh： 普朗克常数， 焦耳∙秒（J∙s）  \nc： 光速， 米/秒（m/s）  \n辐射率是指衡量物体表面以辐射的形式释放能量相对强弱的能力。物体的辐射率等于物体在一定温度下辐射的能量与同一温度下黑体辐射能量之比。黑体的辐射率等于1， 其他物体的辐射率介于0和1之间。\n\n不同温度下黑体辐射率与波长的关系\n\n5.2 色温色温是以温度的数值来表示光源的颜色特征。加热标准黑体， 其表面颜色变化顺序为深红、浅红、橙色、白色、蓝色。  当某种光源的色度与某一温度下黑体的色度相同时，将该色度下黑体的绝对温度作为该光源的色温。色温的单位为开尔文（K） \n\n5.3 显色指数显色指数（CRI 或Ra） 表示物体或其周围环境的颜色在特定光源下呈现的自然程度。借助于显色指数， 可以比较不同光源的光质。显色指数的值介于1和100之间， 没有单位。显色指数与光谱有关， 光谱越宽， 颜色越真实。自然光的CRI为100。 白炽灯和卤素灯的最大显色指数也为100。 LED的CRI为60-98节能灯为80-89， 荧光灯为60-90， 汞蒸气灯45-50， 钠蒸汽灯30-40。\n\n不同显色指数的成像效果比较\n\n\n\n不同光源的光谱分布\n\n5.4 色度色度（chromaticity） 反映的是色调和饱和度， 与亮度无关。人眼锥细胞由三个细胞组成， 分别感受波长为420-440nm、 530-540nm、 560-580nm的可见光。三个波段的可见光近似对应于蓝光、 绿光和红光，其合成反映了色度。国际照明委员会 CIE 建立了与人眼对应的标准观察者颜色匹配函数， 用来描述色度。\n色度图包含了一般人眼可见的所有颜色。舌形图的外边界线被称为光谱轨迹， 是用纳米波长度量的单色光， 这些光是饱和度最大的颜色。饱和度最小的颜色位于舌形图的中心， 表现为白色。如果在色度图上选择任何两个颜色点， 则可以通过混合这两个颜色来形成两点之间直线上的所有颜色。色度图中的任何一点颜色可以用坐标（x， y） 来表示。\n\nCIE 1931颜色空间色度图\n\n\n\n不同显色指数的白色LED色度坐标与电流的关系（色温5000-6500K）\n\n5.5 光谱发光效率光谱发光效率（Spectral luminous efficiency）是指人眼对不同频率光的反应灵敏度。实验表明： 正常视力的观察者， 明视觉时对频率550nm绿色光最敏感， 其发光效率定义为1，其它可见光的光谱发光效率小于1； 暗视觉时对490nm青蓝光最为敏感。 相对光谱发光效率， 某频率光的光谱发光效率与550nm绿光的光谱发光效率的比值。\n5.6 光谱密度光谱密度（spectral concentration），表示单位波长区间内辐射能的大小。其中为光的辐射能，为光的波长\n5.7 辐射通量辐射通量（Radiant flux），单位时间内通过某一截面的辐射能。辐射形式包括发射、传播，或接收。 辐射功率的单位是瓦特(W)\n5.8 光通量光通量（luminous flux） 指人眼所能感觉到的辐射通量， 单位为流明\n其中为光谱发光效率最大值，等于\n为规定的标准光谱发光效率函数；\n为辐射通量的光谱密度；\n5.9 发光强度发光强度（Luminous Intensity） 是光在某个方向上传播的量， 以坎德拉（cd）为单位。例如， 太阳发出的光遍布整个星系， 但我们可能只对照射在我们周围的光感兴趣。\n5.10 照度、亮度照度（Illuminance） 是光线照射到物体上的程度， 以勒克斯（lux）为单位。亮（Luminance）是指物体或场景反射或发射的光的量，单位为坎德拉每平方米（cd/m²）。亮度可以测量被拍摄对象或场景的亮度， 也可以测量最终打印照片的亮度。\n5.11 发光效率发光效率指的是光源的光通量与功率的比值。此功率可以指光源输出的辐射通量， 因此称为辐射发光效率； 也可以指提供光源的能， 因此称为电源发光效率。60W的白炽灯可以发出900流明的光， 其发光效率为 15 lm/W。LED发出900流明的光， 其功耗远低于10W， 其发光效率为 90 lm/W。LED的发光效率高于白炽灯。\n5.12 小结\n黑体对于任何波长的电磁波的吸收系数为1， 透射系数为0\n显色指数是评价光源光质的技术指标。\n色度图是显示光源颜色的标准图。\n光通量指人眼所能感觉到的光源辐射通量。\n发光效率指的是光源的光通量与功率的比值。\n\n"},{"title":"面向对象的本质","url":"/2024/03/05/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%9C%AC%E8%B4%A8/","content":"面向对象的本质是设计并扩展自己的数据类型。\nc++的内置类型分为两种，一种是基本数据类型，另一种是复合类型。\n基本数据类型：整形、浮点型——-char型本质还是一个整形\n复合数据类型：数组 、字符串、结构体、枚举类型\n\n climits头文件包含了各种内置数据类型一些宏，可以看 常见数据类型的位数和最大值最小值\n\n\n sizeof(int) 、 sizeof n_short   查看类型一定要加上括号，查看变量 可以不用加括号\n\n","tags":["cpp"]}]